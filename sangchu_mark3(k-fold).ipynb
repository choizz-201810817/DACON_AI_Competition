{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU 사용 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17215458311383449239\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5732564992\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11272837690942580336\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <정량평가>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, AveragePooling1D, MaxPooling1D, Dropout, LeakyReLU\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, MaxPooling2D, ConvLSTM2D, Input, Reshape\n",
    "from tensorflow.keras import Model, Sequential, optimizers, regularizers\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import shap\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAT</th>\n",
       "      <th>obs_time</th>\n",
       "      <th>내부온도관측치</th>\n",
       "      <th>내부습도관측치</th>\n",
       "      <th>co2관측치</th>\n",
       "      <th>ec관측치</th>\n",
       "      <th>시간당분무량</th>\n",
       "      <th>일간누적분무량</th>\n",
       "      <th>시간당백색광량</th>\n",
       "      <th>일간누적백색광량</th>\n",
       "      <th>시간당적색광량</th>\n",
       "      <th>일간누적적색광량</th>\n",
       "      <th>시간당청색광량</th>\n",
       "      <th>일간누적청색광량</th>\n",
       "      <th>시간당총광량</th>\n",
       "      <th>일간누적총광량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>00:00</td>\n",
       "      <td>25.300000</td>\n",
       "      <td>81.835000</td>\n",
       "      <td>536.016667</td>\n",
       "      <td>1.407439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>01:00</td>\n",
       "      <td>25.680357</td>\n",
       "      <td>81.264286</td>\n",
       "      <td>528.696429</td>\n",
       "      <td>1.409003</td>\n",
       "      <td>126.0</td>\n",
       "      <td>126.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>02:00</td>\n",
       "      <td>25.273333</td>\n",
       "      <td>81.471666</td>\n",
       "      <td>532.833333</td>\n",
       "      <td>1.406913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>03:00</td>\n",
       "      <td>25.355000</td>\n",
       "      <td>81.398334</td>\n",
       "      <td>545.566667</td>\n",
       "      <td>1.406689</td>\n",
       "      <td>126.0</td>\n",
       "      <td>252.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>04:00</td>\n",
       "      <td>25.391667</td>\n",
       "      <td>81.483333</td>\n",
       "      <td>558.583333</td>\n",
       "      <td>1.411070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18811</th>\n",
       "      <td>27</td>\n",
       "      <td>19:00</td>\n",
       "      <td>26.030000</td>\n",
       "      <td>58.736667</td>\n",
       "      <td>448.500000</td>\n",
       "      <td>1.195415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2543.12</td>\n",
       "      <td>12.3764</td>\n",
       "      <td>146722.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22253.7504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10462.6535</td>\n",
       "      <td>12.3764</td>\n",
       "      <td>179438.6259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18812</th>\n",
       "      <td>27</td>\n",
       "      <td>20:00</td>\n",
       "      <td>27.341666</td>\n",
       "      <td>58.373334</td>\n",
       "      <td>449.183333</td>\n",
       "      <td>1.190780</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2669.12</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>146722.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22253.7504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10462.6535</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>179438.6259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18813</th>\n",
       "      <td>27</td>\n",
       "      <td>21:00</td>\n",
       "      <td>27.785000</td>\n",
       "      <td>58.711667</td>\n",
       "      <td>441.933333</td>\n",
       "      <td>1.185593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2669.12</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>146722.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22253.7504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10462.6535</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>179438.6259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18814</th>\n",
       "      <td>27</td>\n",
       "      <td>22:00</td>\n",
       "      <td>28.480000</td>\n",
       "      <td>58.121667</td>\n",
       "      <td>437.600000</td>\n",
       "      <td>1.179664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2669.12</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>146722.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22253.7504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10462.6535</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>179438.6259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18815</th>\n",
       "      <td>27</td>\n",
       "      <td>23:00</td>\n",
       "      <td>28.595000</td>\n",
       "      <td>58.598333</td>\n",
       "      <td>430.266667</td>\n",
       "      <td>1.175694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2669.12</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>146722.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22253.7504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10462.6535</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>179438.6259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18816 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DAT obs_time    내부온도관측치    내부습도관측치      co2관측치     ec관측치  시간당분무량  \\\n",
       "0        0    00:00  25.300000  81.835000  536.016667  1.407439     0.0   \n",
       "1        0    01:00  25.680357  81.264286  528.696429  1.409003   126.0   \n",
       "2        0    02:00  25.273333  81.471666  532.833333  1.406913     0.0   \n",
       "3        0    03:00  25.355000  81.398334  545.566667  1.406689   126.0   \n",
       "4        0    04:00  25.391667  81.483333  558.583333  1.411070     0.0   \n",
       "...    ...      ...        ...        ...         ...       ...     ...   \n",
       "18811   27    19:00  26.030000  58.736667  448.500000  1.195415     0.0   \n",
       "18812   27    20:00  27.341666  58.373334  449.183333  1.190780   126.0   \n",
       "18813   27    21:00  27.785000  58.711667  441.933333  1.185593     0.0   \n",
       "18814   27    22:00  28.480000  58.121667  437.600000  1.179664     0.0   \n",
       "18815   27    23:00  28.595000  58.598333  430.266667  1.175694     0.0   \n",
       "\n",
       "       일간누적분무량  시간당백색광량    일간누적백색광량  시간당적색광량    일간누적적색광량  시간당청색광량    일간누적청색광량  \\\n",
       "0         0.00   0.0000       0.000      0.0      0.0000      0.0      0.0000   \n",
       "1       126.00   0.0000       0.000      0.0      0.0000      0.0      0.0000   \n",
       "2       126.00   0.0000       0.000      0.0      0.0000      0.0      0.0000   \n",
       "3       252.00   0.0000       0.000      0.0      0.0000      0.0      0.0000   \n",
       "4       252.00   0.0000       0.000      0.0      0.0000      0.0      0.0000   \n",
       "...        ...      ...         ...      ...         ...      ...         ...   \n",
       "18811  2543.12  12.3764  146722.222      0.0  22253.7504      0.0  10462.6535   \n",
       "18812  2669.12   0.0000  146722.222      0.0  22253.7504      0.0  10462.6535   \n",
       "18813  2669.12   0.0000  146722.222      0.0  22253.7504      0.0  10462.6535   \n",
       "18814  2669.12   0.0000  146722.222      0.0  22253.7504      0.0  10462.6535   \n",
       "18815  2669.12   0.0000  146722.222      0.0  22253.7504      0.0  10462.6535   \n",
       "\n",
       "        시간당총광량      일간누적총광량  \n",
       "0       0.0000       0.0000  \n",
       "1       0.0000       0.0000  \n",
       "2       0.0000       0.0000  \n",
       "3       0.0000       0.0000  \n",
       "4       0.0000       0.0000  \n",
       "...        ...          ...  \n",
       "18811  12.3764  179438.6259  \n",
       "18812   0.0000  179438.6259  \n",
       "18813   0.0000  179438.6259  \n",
       "18814   0.0000  179438.6259  \n",
       "18815   0.0000  179438.6259  \n",
       "\n",
       "[18816 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('./train_input/')\n",
    "path = './train_input/'\n",
    "\n",
    "train_df_list = []\n",
    "\n",
    "for file in files:\n",
    "    if 'CASE' in file:\n",
    "        df = pd.read_csv(path + file)\n",
    "        train_df_list.append(df)\n",
    "\n",
    "df = pd.concat(train_df_list).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAT</th>\n",
       "      <th>obs_time</th>\n",
       "      <th>내부온도관측치</th>\n",
       "      <th>내부습도관측치</th>\n",
       "      <th>co2관측치</th>\n",
       "      <th>ec관측치</th>\n",
       "      <th>시간당분무량</th>\n",
       "      <th>일간누적분무량</th>\n",
       "      <th>시간당백색광량</th>\n",
       "      <th>일간누적백색광량</th>\n",
       "      <th>시간당적색광량</th>\n",
       "      <th>일간누적적색광량</th>\n",
       "      <th>시간당청색광량</th>\n",
       "      <th>일간누적청색광량</th>\n",
       "      <th>시간당총광량</th>\n",
       "      <th>일간누적총광량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>00:00</td>\n",
       "      <td>25.300000</td>\n",
       "      <td>81.835000</td>\n",
       "      <td>536.016667</td>\n",
       "      <td>1.407439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>01:00</td>\n",
       "      <td>25.680357</td>\n",
       "      <td>81.264286</td>\n",
       "      <td>528.696429</td>\n",
       "      <td>1.409003</td>\n",
       "      <td>126.0</td>\n",
       "      <td>126.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>02:00</td>\n",
       "      <td>25.273333</td>\n",
       "      <td>81.471666</td>\n",
       "      <td>532.833333</td>\n",
       "      <td>1.406913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>03:00</td>\n",
       "      <td>25.355000</td>\n",
       "      <td>81.398334</td>\n",
       "      <td>545.566667</td>\n",
       "      <td>1.406689</td>\n",
       "      <td>126.0</td>\n",
       "      <td>252.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>04:00</td>\n",
       "      <td>25.391667</td>\n",
       "      <td>81.483333</td>\n",
       "      <td>558.583333</td>\n",
       "      <td>1.411070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18811</th>\n",
       "      <td>27</td>\n",
       "      <td>19:00</td>\n",
       "      <td>26.030000</td>\n",
       "      <td>58.736667</td>\n",
       "      <td>448.500000</td>\n",
       "      <td>1.195415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2543.12</td>\n",
       "      <td>12.3764</td>\n",
       "      <td>146722.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22253.7504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10462.6535</td>\n",
       "      <td>12.3764</td>\n",
       "      <td>179438.6259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18812</th>\n",
       "      <td>27</td>\n",
       "      <td>20:00</td>\n",
       "      <td>27.341666</td>\n",
       "      <td>58.373334</td>\n",
       "      <td>449.183333</td>\n",
       "      <td>1.190780</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2669.12</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>146722.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22253.7504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10462.6535</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>179438.6259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18813</th>\n",
       "      <td>27</td>\n",
       "      <td>21:00</td>\n",
       "      <td>27.785000</td>\n",
       "      <td>58.711667</td>\n",
       "      <td>441.933333</td>\n",
       "      <td>1.185593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2669.12</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>146722.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22253.7504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10462.6535</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>179438.6259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18814</th>\n",
       "      <td>27</td>\n",
       "      <td>22:00</td>\n",
       "      <td>28.480000</td>\n",
       "      <td>58.121667</td>\n",
       "      <td>437.600000</td>\n",
       "      <td>1.179664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2669.12</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>146722.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22253.7504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10462.6535</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>179438.6259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18815</th>\n",
       "      <td>27</td>\n",
       "      <td>23:00</td>\n",
       "      <td>28.595000</td>\n",
       "      <td>58.598333</td>\n",
       "      <td>430.266667</td>\n",
       "      <td>1.175694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2669.12</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>146722.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22253.7504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10462.6535</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>179438.6259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18816 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DAT obs_time    내부온도관측치    내부습도관측치      co2관측치     ec관측치  시간당분무량  \\\n",
       "0        0    00:00  25.300000  81.835000  536.016667  1.407439     0.0   \n",
       "1        0    01:00  25.680357  81.264286  528.696429  1.409003   126.0   \n",
       "2        0    02:00  25.273333  81.471666  532.833333  1.406913     0.0   \n",
       "3        0    03:00  25.355000  81.398334  545.566667  1.406689   126.0   \n",
       "4        0    04:00  25.391667  81.483333  558.583333  1.411070     0.0   \n",
       "...    ...      ...        ...        ...         ...       ...     ...   \n",
       "18811   27    19:00  26.030000  58.736667  448.500000  1.195415     0.0   \n",
       "18812   27    20:00  27.341666  58.373334  449.183333  1.190780   126.0   \n",
       "18813   27    21:00  27.785000  58.711667  441.933333  1.185593     0.0   \n",
       "18814   27    22:00  28.480000  58.121667  437.600000  1.179664     0.0   \n",
       "18815   27    23:00  28.595000  58.598333  430.266667  1.175694     0.0   \n",
       "\n",
       "       일간누적분무량  시간당백색광량    일간누적백색광량  시간당적색광량    일간누적적색광량  시간당청색광량    일간누적청색광량  \\\n",
       "0         0.00   0.0000       0.000      0.0      0.0000      0.0      0.0000   \n",
       "1       126.00   0.0000       0.000      0.0      0.0000      0.0      0.0000   \n",
       "2       126.00   0.0000       0.000      0.0      0.0000      0.0      0.0000   \n",
       "3       252.00   0.0000       0.000      0.0      0.0000      0.0      0.0000   \n",
       "4       252.00   0.0000       0.000      0.0      0.0000      0.0      0.0000   \n",
       "...        ...      ...         ...      ...         ...      ...         ...   \n",
       "18811  2543.12  12.3764  146722.222      0.0  22253.7504      0.0  10462.6535   \n",
       "18812  2669.12   0.0000  146722.222      0.0  22253.7504      0.0  10462.6535   \n",
       "18813  2669.12   0.0000  146722.222      0.0  22253.7504      0.0  10462.6535   \n",
       "18814  2669.12   0.0000  146722.222      0.0  22253.7504      0.0  10462.6535   \n",
       "18815  2669.12   0.0000  146722.222      0.0  22253.7504      0.0  10462.6535   \n",
       "\n",
       "        시간당총광량      일간누적총광량  \n",
       "0       0.0000       0.0000  \n",
       "1       0.0000       0.0000  \n",
       "2       0.0000       0.0000  \n",
       "3       0.0000       0.0000  \n",
       "4       0.0000       0.0000  \n",
       "...        ...          ...  \n",
       "18811  12.3764  179438.6259  \n",
       "18812   0.0000  179438.6259  \n",
       "18813   0.0000  179438.6259  \n",
       "18814   0.0000  179438.6259  \n",
       "18815   0.0000  179438.6259  \n",
       "\n",
       "[18816 rows x 16 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시간이 다르게 표기된 부분 통일\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '02:00:00.' if x=='01:59:59.' else x)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '03:00:00.' if x=='02:59:59.' else x)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '04:00:00.' if x=='03:59:59.' else x)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '05:00:00.' if x=='04:59:59.' else x)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '06:00:00.' if x=='05:59:59.' else x)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '07:00:00.' if x=='06:59:59.' else x)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '08:00:00.' if x=='07:59:59.' else x)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '09:00:00.' if x=='08:59:59.' else x)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '10:00:00.' if x=='09:59:59.' else x)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '11:00:00.' if x=='10:59:59.' else x)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '12:00:00.' if x=='11:59:59.' else x)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '13:00:00.' if x=='12:59:59.' else x)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '14:00:00.' if x=='13:59:59.' else x)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '15:00:00.' if x=='14:59:59.' else x)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '16:00:00.' if x=='15:59:59.' else x)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '17:00:00.' if x=='16:59:59.' else x)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '18:00:00.' if x=='17:59:59.' else x)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '19:00:00.' if x=='18:59:59.' else x)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '20:00:00.' if x=='19:59:59.' else x)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '21:00:00.' if x=='20:59:59.' else x)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '22:00:00.' if x=='21:59:59.' else x)\n",
    "df['obs_time'] = df['obs_time'].apply(lambda x: '23:00:00.' if x=='22:59:59.' else x)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음의 값 -> 양수로..\n",
    "# 독립 변수들의 단위가 크게 다르기 때문에 정규화 진행\n",
    "\n",
    "def prepro(df):\n",
    "    df.obs_time = df.obs_time.apply(lambda x: x[:2]).astype('int')\n",
    "    df = df.abs()\n",
    "    \n",
    "    mm_sc = MinMaxScaler()\n",
    "    mm_array = mm_sc.fit_transform(df)\n",
    "    mm_df = pd.DataFrame(mm_array, columns=df.columns.tolist())\n",
    "    \n",
    "    return mm_df\n",
    "\n",
    "df1 = prepro(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAT</th>\n",
       "      <th>내부온도관측치</th>\n",
       "      <th>내부습도관측치</th>\n",
       "      <th>co2관측치</th>\n",
       "      <th>ec관측치</th>\n",
       "      <th>시간당분무량</th>\n",
       "      <th>시간당백색광량</th>\n",
       "      <th>시간당적색광량</th>\n",
       "      <th>시간당청색광량</th>\n",
       "      <th>시간당총광량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.593293</td>\n",
       "      <td>0.876647</td>\n",
       "      <td>0.287477</td>\n",
       "      <td>0.257663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.602213</td>\n",
       "      <td>0.870533</td>\n",
       "      <td>0.283053</td>\n",
       "      <td>0.257949</td>\n",
       "      <td>0.040075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.592668</td>\n",
       "      <td>0.872755</td>\n",
       "      <td>0.285553</td>\n",
       "      <td>0.257567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.594583</td>\n",
       "      <td>0.871969</td>\n",
       "      <td>0.293250</td>\n",
       "      <td>0.257526</td>\n",
       "      <td>0.040075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.595443</td>\n",
       "      <td>0.872880</td>\n",
       "      <td>0.301117</td>\n",
       "      <td>0.258328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18811</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.610412</td>\n",
       "      <td>0.629209</td>\n",
       "      <td>0.234579</td>\n",
       "      <td>0.218847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18812</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641171</td>\n",
       "      <td>0.625317</td>\n",
       "      <td>0.234992</td>\n",
       "      <td>0.217999</td>\n",
       "      <td>0.040075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18813</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.651567</td>\n",
       "      <td>0.628941</td>\n",
       "      <td>0.230610</td>\n",
       "      <td>0.217049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18814</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667865</td>\n",
       "      <td>0.622621</td>\n",
       "      <td>0.227991</td>\n",
       "      <td>0.215964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18815</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.670562</td>\n",
       "      <td>0.627727</td>\n",
       "      <td>0.223559</td>\n",
       "      <td>0.215237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18816 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DAT   내부온도관측치   내부습도관측치    co2관측치     ec관측치    시간당분무량   시간당백색광량  \\\n",
       "0      0.0  0.593293  0.876647  0.287477  0.257663  0.000000  0.000000   \n",
       "1      0.0  0.602213  0.870533  0.283053  0.257949  0.040075  0.000000   \n",
       "2      0.0  0.592668  0.872755  0.285553  0.257567  0.000000  0.000000   \n",
       "3      0.0  0.594583  0.871969  0.293250  0.257526  0.040075  0.000000   \n",
       "4      0.0  0.595443  0.872880  0.301117  0.258328  0.000000  0.000000   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "18811  1.0  0.610412  0.629209  0.234579  0.218847  0.000000  0.000089   \n",
       "18812  1.0  0.641171  0.625317  0.234992  0.217999  0.040075  0.000000   \n",
       "18813  1.0  0.651567  0.628941  0.230610  0.217049  0.000000  0.000000   \n",
       "18814  1.0  0.667865  0.622621  0.227991  0.215964  0.000000  0.000000   \n",
       "18815  1.0  0.670562  0.627727  0.223559  0.215237  0.000000  0.000000   \n",
       "\n",
       "       시간당적색광량  시간당청색광량    시간당총광량  \n",
       "0          0.0      0.0  0.000000  \n",
       "1          0.0      0.0  0.000000  \n",
       "2          0.0      0.0  0.000000  \n",
       "3          0.0      0.0  0.000000  \n",
       "4          0.0      0.0  0.000000  \n",
       "...        ...      ...       ...  \n",
       "18811      0.0      0.0  0.000075  \n",
       "18812      0.0      0.0  0.000000  \n",
       "18813      0.0      0.0  0.000000  \n",
       "18814      0.0      0.0  0.000000  \n",
       "18815      0.0      0.0  0.000000  \n",
       "\n",
       "[18816 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 시간당 관측값과 누적값은 서로 파생변수가 될 수 있는 관계로\n",
    "## 모두 사용할 경우 독립변수들 간의 상관관계가 높아 복잡도만 높아질 뿐, 학습에 악영향을 끼칠 것으로 판단.\n",
    "## 두 종류의 feature들 중에 하나만 사용..\n",
    "\n",
    "## 일간누적\n",
    "# df2 = df1.iloc[:,[0,2,3,4,5,7,9,11,13,15]]\n",
    "\n",
    "## 시간당\n",
    "df2 = df1.iloc[:,[0,2,3,4,5,6,8,10,12,14]]\n",
    "\n",
    "## 전부 사용\n",
    "# df2 = df1.drop(['obs_time'], axis=1)\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 24, 10, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target값의 shape과 맞추기 위한 feature data set 정의..\n",
    "# feature data는 시간별 data인 반면에 target data는 일별 data이기 때문에 feature data를 24시간 간격으로 자름\n",
    "def slice_24(df):\n",
    "    array_list = []\n",
    "    \n",
    "    for i in range(int(len(df)/24)):\n",
    "        one_day_array = df.iloc[i*24:(i+1)*24,:].to_numpy()\n",
    "        array_list.append(one_day_array)\n",
    "    \n",
    "    return array_list\n",
    "\n",
    "\n",
    "sliced_array_list = slice_24(df2)\n",
    "\n",
    "input_data = np.array(sliced_array_list)\n",
    "input_data = input_data.reshape(784,24,10,1)\n",
    "input_data.shape\n",
    "\n",
    "# reshape 끝에 1을 찍어주는 이유는 Conv2D의 input shape과 맞춰주기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.167719\n",
      "1       0.181787\n",
      "2       0.265921\n",
      "3       0.423650\n",
      "4       0.475272\n",
      "         ...    \n",
      "779    64.875499\n",
      "780    74.002614\n",
      "781    76.342275\n",
      "782    82.621245\n",
      "783    86.591508\n",
      "Name: predicted_weight_g, Length: 784, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 target data set 불러오기..\n",
    "path = './train_target/'\n",
    "files = os.listdir(path)\n",
    "\n",
    "target_df_list = []\n",
    "\n",
    "for file in files:\n",
    "    if 'csv' in file:\n",
    "        df2 = pd.read_csv(path+file)\n",
    "        target_df_list.append(df2)\n",
    "\n",
    "# target dataㅂ 정의\n",
    "target_df = pd.concat(target_df_list)['predicted_weight_g'].reset_index(drop=True)\n",
    "print(target_df)\n",
    "\n",
    "targets = target_df.values\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KFold없이 진행시 train, test split\n",
    "\n",
    "# ## train, validation split\n",
    "# # 672> 24째 CASE까지\n",
    "# X_train = input_data[:672]\n",
    "# X_val = input_data[672:]\n",
    "# y_train = targets[:672]\n",
    "# y_val = targets[672:]\n",
    "\n",
    "                \n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)\n",
    "\n",
    "\n",
    "# train_dataset = [X_train, y_train]\n",
    "# val_dataset = [X_val, y_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 정의 및 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "Total params = recurrent_weights + input_weights + biases\n",
    "\n",
    "= (num_units*num_units)+(num_features*num_units) + (1*num_units)\n",
    "\n",
    "= (num_features + num_units)* num_units + num_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse 함수 정의\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모델 정의 - 2D CNN + LSTM MODEL\n",
    "def CnnLstmModel(X_train, y_train, X_val, y_val, BATCH_SIZE, EPOCHS, hidden_units, opti, NORM, early_stopping, checkpoint):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(hidden_units,\n",
    "                     kernel_size=3,\n",
    "                     input_shape=(X_train.shape[1:]),\n",
    "                     kernel_regularizer=NORM,\n",
    "                     activation='elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "    model.add(Reshape((7, 2*360)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(180,\n",
    "                   activation='tanh', # elu 사용시 기울기 폭주함\n",
    "                   kernel_regularizer=NORM,\n",
    "                   return_sequences=False))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "\n",
    "    \n",
    "    model.summary()\n",
    "    model.compile(optimizer=opti, loss=rmse)\n",
    "    model.fit(X_train, \n",
    "              y_train, \n",
    "              validation_data=[X_val, y_val], \n",
    "              batch_size=BATCH_SIZE, \n",
    "              epochs=EPOCHS, \n",
    "              verbose=1,\n",
    "              callbacks=[early_stopping, checkpoint])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfold 학습 함수 정의\n",
    "def kFoldModelFit(input_data, targets, BATCH_SIZE, EPOCHS, hidden_units, NORM):\n",
    "    kfold = KFold(n_splits=7, shuffle=False)\n",
    "\n",
    "    # 학습 후 그래프 그리기 위한 리스트\n",
    "    X_val_list = []\n",
    "    y_val_list = []\n",
    "\n",
    "    # KFold Cross Validation으로 모델 학습\n",
    "    for i, (train_idx, val_idx) in enumerate(kfold.split(input_data, targets)):\n",
    "        print('\\n', '-'*10, i, '-'*10, '\\n')\n",
    "        \n",
    "        X_train, X_val = input_data[train_idx], input_data[val_idx]\n",
    "        y_train, y_val = targets[train_idx], targets[val_idx]\n",
    "\n",
    "        X_val_list.append(input_data[val_idx])\n",
    "        y_val_list.append(targets[val_idx])\n",
    "\n",
    "        opti = optimizers.Adam(learning_rate=0.0003)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=500, mode='min')\n",
    "\n",
    "        save_path = './model_save/'+f'{i+1}_fold_'+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "        checkpoint = ModelCheckpoint(filepath=save_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "\n",
    "        model = CnnLstmModel(X_train, y_train, X_val, y_val, BATCH_SIZE, EPOCHS, hidden_units, opti, NORM, early_stopping, checkpoint)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ---------- 0 ---------- \n",
      "\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_7 (Conv2D)           (None, 22, 8, 360)        3600      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 7, 2, 360)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " reshape_7 (Reshape)         (None, 7, 720)            0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 7, 720)            0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 180)               648720    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 180)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 181       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 652,501\n",
      "Trainable params: 652,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 50.7145\n",
      "Epoch 1: val_loss improved from inf to 26.30247, saving model to ./model_save\\1_fold_001-26.3025.hdf5\n",
      "84/84 [==============================] - 2s 11ms/step - loss: 50.6925 - val_loss: 26.3025\n",
      "Epoch 2/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 44.8006\n",
      "Epoch 2: val_loss improved from 26.30247 to 25.19413, saving model to ./model_save\\1_fold_002-25.1941.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 44.4174 - val_loss: 25.1941\n",
      "Epoch 3/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 41.1960\n",
      "Epoch 3: val_loss did not improve from 25.19413\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 41.7344 - val_loss: 25.2860\n",
      "Epoch 4/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 40.9686\n",
      "Epoch 4: val_loss improved from 25.19413 to 25.16215, saving model to ./model_save\\1_fold_004-25.1622.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 40.9686 - val_loss: 25.1622\n",
      "Epoch 5/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 37.9947\n",
      "Epoch 5: val_loss improved from 25.16215 to 18.25512, saving model to ./model_save\\1_fold_005-18.2551.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 38.0330 - val_loss: 18.2551\n",
      "Epoch 6/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 34.2344\n",
      "Epoch 6: val_loss improved from 18.25512 to 17.35242, saving model to ./model_save\\1_fold_006-17.3524.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 35.0868 - val_loss: 17.3524\n",
      "Epoch 7/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 33.0322\n",
      "Epoch 7: val_loss improved from 17.35242 to 16.80441, saving model to ./model_save\\1_fold_007-16.8044.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 34.4389 - val_loss: 16.8044\n",
      "Epoch 8/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 33.0265\n",
      "Epoch 8: val_loss improved from 16.80441 to 16.48497, saving model to ./model_save\\1_fold_008-16.4850.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 32.7939 - val_loss: 16.4850\n",
      "Epoch 9/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 31.8727\n",
      "Epoch 9: val_loss improved from 16.48497 to 15.04944, saving model to ./model_save\\1_fold_009-15.0494.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 31.5696 - val_loss: 15.0494\n",
      "Epoch 10/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 31.1582\n",
      "Epoch 10: val_loss did not improve from 15.04944\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 31.1582 - val_loss: 21.9543\n",
      "Epoch 11/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 29.7523\n",
      "Epoch 11: val_loss improved from 15.04944 to 14.75540, saving model to ./model_save\\1_fold_011-14.7554.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 29.4921 - val_loss: 14.7554\n",
      "Epoch 12/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 28.7697\n",
      "Epoch 12: val_loss improved from 14.75540 to 14.61630, saving model to ./model_save\\1_fold_012-14.6163.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 28.7697 - val_loss: 14.6163\n",
      "Epoch 13/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 28.6388\n",
      "Epoch 13: val_loss did not improve from 14.61630\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 27.9287 - val_loss: 15.4208\n",
      "Epoch 14/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 27.2985\n",
      "Epoch 14: val_loss did not improve from 14.61630\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 27.6048 - val_loss: 20.1193\n",
      "Epoch 15/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 27.4892\n",
      "Epoch 15: val_loss did not improve from 14.61630\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 27.4157 - val_loss: 15.1026\n",
      "Epoch 16/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 26.8901\n",
      "Epoch 16: val_loss did not improve from 14.61630\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 26.0670 - val_loss: 15.5293\n",
      "Epoch 17/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 26.6636\n",
      "Epoch 17: val_loss did not improve from 14.61630\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 26.2295 - val_loss: 15.3771\n",
      "Epoch 18/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 23.6829\n",
      "Epoch 18: val_loss did not improve from 14.61630\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 23.7131 - val_loss: 15.1805\n",
      "Epoch 19/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 23.6647\n",
      "Epoch 19: val_loss did not improve from 14.61630\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 23.6604 - val_loss: 16.2475\n",
      "Epoch 20/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 26.3453\n",
      "Epoch 20: val_loss did not improve from 14.61630\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 24.9367 - val_loss: 14.9410\n",
      "Epoch 21/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 24.8559\n",
      "Epoch 21: val_loss did not improve from 14.61630\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 24.1867 - val_loss: 16.0449\n",
      "Epoch 22/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 22.3817\n",
      "Epoch 22: val_loss improved from 14.61630 to 14.31325, saving model to ./model_save\\1_fold_022-14.3133.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 22.5973 - val_loss: 14.3133\n",
      "Epoch 23/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 22.4244\n",
      "Epoch 23: val_loss did not improve from 14.31325\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 21.6574 - val_loss: 15.2754\n",
      "Epoch 24/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 21.6842\n",
      "Epoch 24: val_loss improved from 14.31325 to 14.28607, saving model to ./model_save\\1_fold_024-14.2861.hdf5\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 21.1398 - val_loss: 14.2861\n",
      "Epoch 25/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 21.5336\n",
      "Epoch 25: val_loss did not improve from 14.28607\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 21.5336 - val_loss: 14.4182\n",
      "Epoch 26/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 20.6595\n",
      "Epoch 26: val_loss improved from 14.28607 to 13.61500, saving model to ./model_save\\1_fold_026-13.6150.hdf5\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 20.9209 - val_loss: 13.6150\n",
      "Epoch 27/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 20.0453\n",
      "Epoch 27: val_loss did not improve from 13.61500\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 20.4764 - val_loss: 14.8264\n",
      "Epoch 28/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 20.2114\n",
      "Epoch 28: val_loss did not improve from 13.61500\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 20.0145 - val_loss: 13.9066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 19.2616\n",
      "Epoch 29: val_loss did not improve from 13.61500\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.6201 - val_loss: 15.0963\n",
      "Epoch 30/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 20.1135\n",
      "Epoch 30: val_loss improved from 13.61500 to 13.35592, saving model to ./model_save\\1_fold_030-13.3559.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.8478 - val_loss: 13.3559\n",
      "Epoch 31/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 18.5922\n",
      "Epoch 31: val_loss did not improve from 13.35592\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.2673 - val_loss: 13.6626\n",
      "Epoch 32/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 18.2117\n",
      "Epoch 32: val_loss did not improve from 13.35592\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.2751 - val_loss: 13.8894\n",
      "Epoch 33/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 18.0782\n",
      "Epoch 33: val_loss did not improve from 13.35592\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.7912 - val_loss: 14.4457\n",
      "Epoch 34/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 18.8069\n",
      "Epoch 34: val_loss did not improve from 13.35592\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.0245 - val_loss: 13.4709\n",
      "Epoch 35/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 17.2142\n",
      "Epoch 35: val_loss did not improve from 13.35592\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.2619 - val_loss: 14.7647\n",
      "Epoch 36/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 18.1437\n",
      "Epoch 36: val_loss did not improve from 13.35592\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.5232 - val_loss: 13.5460\n",
      "Epoch 37/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 17.0201\n",
      "Epoch 37: val_loss did not improve from 13.35592\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.9154 - val_loss: 13.9228\n",
      "Epoch 38/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 17.0359\n",
      "Epoch 38: val_loss did not improve from 13.35592\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.6619 - val_loss: 16.2993\n",
      "Epoch 39/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 16.9020\n",
      "Epoch 39: val_loss did not improve from 13.35592\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.4189 - val_loss: 17.9550\n",
      "Epoch 40/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 17.5715\n",
      "Epoch 40: val_loss did not improve from 13.35592\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.1768 - val_loss: 15.2683\n",
      "Epoch 41/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 15.9636\n",
      "Epoch 41: val_loss did not improve from 13.35592\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.1095 - val_loss: 15.1097\n",
      "Epoch 42/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 15.8311\n",
      "Epoch 42: val_loss did not improve from 13.35592\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.9248 - val_loss: 16.5829\n",
      "Epoch 43/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 16.6286\n",
      "Epoch 43: val_loss did not improve from 13.35592\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.7738 - val_loss: 15.3871\n",
      "Epoch 44/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 14.6461\n",
      "Epoch 44: val_loss did not improve from 13.35592\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.1833 - val_loss: 14.3775\n",
      "Epoch 45/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 15.4223\n",
      "Epoch 45: val_loss improved from 13.35592 to 13.33088, saving model to ./model_save\\1_fold_045-13.3309.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.7473 - val_loss: 13.3309\n",
      "Epoch 46/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 15.3548\n",
      "Epoch 46: val_loss did not improve from 13.33088\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.1383 - val_loss: 13.6953\n",
      "Epoch 47/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 14.7434\n",
      "Epoch 47: val_loss did not improve from 13.33088\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.2009 - val_loss: 13.6396\n",
      "Epoch 48/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 14.3919\n",
      "Epoch 48: val_loss did not improve from 13.33088\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.2547 - val_loss: 14.0072\n",
      "Epoch 49/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 14.5686\n",
      "Epoch 49: val_loss did not improve from 13.33088\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.5320 - val_loss: 13.9933\n",
      "Epoch 50/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 14.2810\n",
      "Epoch 50: val_loss did not improve from 13.33088\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.3683 - val_loss: 15.3112\n",
      "Epoch 51/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 13.3100\n",
      "Epoch 51: val_loss did not improve from 13.33088\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.8284 - val_loss: 15.3757\n",
      "Epoch 52/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 13.2743\n",
      "Epoch 52: val_loss improved from 13.33088 to 13.13559, saving model to ./model_save\\1_fold_052-13.1356.hdf5\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 13.8460 - val_loss: 13.1356\n",
      "Epoch 53/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 15.1486\n",
      "Epoch 53: val_loss did not improve from 13.13559\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.2148 - val_loss: 14.9393\n",
      "Epoch 54/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 13.6856\n",
      "Epoch 54: val_loss did not improve from 13.13559\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.2527 - val_loss: 13.7676\n",
      "Epoch 55/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 13.8018\n",
      "Epoch 55: val_loss improved from 13.13559 to 12.89374, saving model to ./model_save\\1_fold_055-12.8937.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.7118 - val_loss: 12.8937\n",
      "Epoch 56/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 13.5125\n",
      "Epoch 56: val_loss did not improve from 12.89374\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.2846 - val_loss: 13.0157\n",
      "Epoch 57/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 13.8310\n",
      "Epoch 57: val_loss did not improve from 12.89374\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.0400 - val_loss: 13.6125\n",
      "Epoch 58/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 13.9744\n",
      "Epoch 58: val_loss did not improve from 12.89374\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.8021 - val_loss: 14.7901\n",
      "Epoch 59/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 13.0314\n",
      "Epoch 59: val_loss did not improve from 12.89374\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.0224 - val_loss: 14.4900\n",
      "Epoch 60/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 14.0867\n",
      "Epoch 60: val_loss did not improve from 12.89374\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.5855 - val_loss: 14.4577\n",
      "Epoch 61/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 13.4619\n",
      "Epoch 61: val_loss did not improve from 12.89374\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.7061 - val_loss: 13.5227\n",
      "Epoch 62/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 12.6857\n",
      "Epoch 62: val_loss improved from 12.89374 to 12.06320, saving model to ./model_save\\1_fold_062-12.0632.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.7367 - val_loss: 12.0632\n",
      "Epoch 63/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 11.2199\n",
      "Epoch 63: val_loss did not improve from 12.06320\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.6852 - val_loss: 13.9690\n",
      "Epoch 64/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 12.4533\n",
      "Epoch 64: val_loss did not improve from 12.06320\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.5450 - val_loss: 13.6308\n",
      "Epoch 65/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 13.0307\n",
      "Epoch 65: val_loss did not improve from 12.06320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 12.8128 - val_loss: 14.0347\n",
      "Epoch 66/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 12.3002\n",
      "Epoch 66: val_loss improved from 12.06320 to 11.56336, saving model to ./model_save\\1_fold_066-11.5634.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.5750 - val_loss: 11.5634\n",
      "Epoch 67/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 12.1993\n",
      "Epoch 67: val_loss did not improve from 11.56336\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.1620 - val_loss: 12.3852\n",
      "Epoch 68/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 11.9582\n",
      "Epoch 68: val_loss improved from 11.56336 to 11.48937, saving model to ./model_save\\1_fold_068-11.4894.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.8525 - val_loss: 11.4894\n",
      "Epoch 69/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 12.0601\n",
      "Epoch 69: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.8932 - val_loss: 11.8590\n",
      "Epoch 70/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 11.7841\n",
      "Epoch 70: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.6724 - val_loss: 13.3125\n",
      "Epoch 71/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 11.5254\n",
      "Epoch 71: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.1702 - val_loss: 13.5614\n",
      "Epoch 72/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 11.5450\n",
      "Epoch 72: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.4868 - val_loss: 13.6275\n",
      "Epoch 73/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 11.7877\n",
      "Epoch 73: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.6230 - val_loss: 12.9050\n",
      "Epoch 74/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 11.6992\n",
      "Epoch 74: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.9690 - val_loss: 14.1920\n",
      "Epoch 75/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 11.3246\n",
      "Epoch 75: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.2777 - val_loss: 14.3151\n",
      "Epoch 76/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 11.8330\n",
      "Epoch 76: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.6385 - val_loss: 12.4576\n",
      "Epoch 77/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 11.5294\n",
      "Epoch 77: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.1954 - val_loss: 13.2179\n",
      "Epoch 78/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 9.9575 \n",
      "Epoch 78: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.0397 - val_loss: 14.8753\n",
      "Epoch 79/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 10.3070\n",
      "Epoch 79: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.4995 - val_loss: 12.2527\n",
      "Epoch 80/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 10.2727\n",
      "Epoch 80: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.5274 - val_loss: 13.9919\n",
      "Epoch 81/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 9.7644\n",
      "Epoch 81: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.7183 - val_loss: 13.1110\n",
      "Epoch 82/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 10.1941\n",
      "Epoch 82: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.0697 - val_loss: 12.3759\n",
      "Epoch 83/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 9.8862 \n",
      "Epoch 83: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.8340 - val_loss: 12.6354\n",
      "Epoch 84/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 10.3767\n",
      "Epoch 84: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.4076 - val_loss: 13.0296\n",
      "Epoch 85/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 9.8022\n",
      "Epoch 85: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.9495 - val_loss: 12.8344\n",
      "Epoch 86/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 10.0356\n",
      "Epoch 86: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.7509 - val_loss: 12.4720\n",
      "Epoch 87/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 10.5424\n",
      "Epoch 87: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.5988 - val_loss: 13.5036\n",
      "Epoch 88/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 9.1455\n",
      "Epoch 88: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0294 - val_loss: 13.4138\n",
      "Epoch 89/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 10.3563\n",
      "Epoch 89: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.3828 - val_loss: 13.9653\n",
      "Epoch 90/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 10.8895\n",
      "Epoch 90: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.7692 - val_loss: 11.8479\n",
      "Epoch 91/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 9.7330 \n",
      "Epoch 91: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.7458 - val_loss: 11.8467\n",
      "Epoch 92/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 8.8187\n",
      "Epoch 92: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2237 - val_loss: 12.1947\n",
      "Epoch 93/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 8.9066\n",
      "Epoch 93: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0139 - val_loss: 12.1796\n",
      "Epoch 94/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 9.0866\n",
      "Epoch 94: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1530 - val_loss: 13.0420\n",
      "Epoch 95/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 10.0752\n",
      "Epoch 95: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.7115 - val_loss: 12.3182\n",
      "Epoch 96/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 9.6316\n",
      "Epoch 96: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.7328 - val_loss: 13.0065\n",
      "Epoch 97/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 9.4954\n",
      "Epoch 97: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1934 - val_loss: 12.3443\n",
      "Epoch 98/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 9.1933\n",
      "Epoch 98: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1108 - val_loss: 12.0923\n",
      "Epoch 99/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 9.2012\n",
      "Epoch 99: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2151 - val_loss: 12.6142\n",
      "Epoch 100/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 9.7778 \n",
      "Epoch 100: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1452 - val_loss: 12.2783\n",
      "Epoch 101/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 8.9771\n",
      "Epoch 101: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0945 - val_loss: 12.6614\n",
      "Epoch 102/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 9.2467\n",
      "Epoch 102: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2839 - val_loss: 13.0078\n",
      "Epoch 103/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/84 [======================>.......] - ETA: 0s - loss: 9.2381\n",
      "Epoch 103: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9282 - val_loss: 13.4087\n",
      "Epoch 104/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 9.1264\n",
      "Epoch 104: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9691 - val_loss: 11.9363\n",
      "Epoch 105/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 9.0892\n",
      "Epoch 105: val_loss did not improve from 11.48937\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0059 - val_loss: 13.7029\n",
      "Epoch 106/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 9.6487\n",
      "Epoch 106: val_loss improved from 11.48937 to 11.15048, saving model to ./model_save\\1_fold_106-11.1505.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.3755 - val_loss: 11.1505\n",
      "Epoch 107/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 9.1741\n",
      "Epoch 107: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0836 - val_loss: 13.1972\n",
      "Epoch 108/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 9.4034\n",
      "Epoch 108: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2634 - val_loss: 11.8772\n",
      "Epoch 109/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 8.7694\n",
      "Epoch 109: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9371 - val_loss: 11.3946\n",
      "Epoch 110/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 10.2598\n",
      "Epoch 110: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.8301 - val_loss: 11.8793\n",
      "Epoch 111/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 8.1085\n",
      "Epoch 111: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2432 - val_loss: 11.6184\n",
      "Epoch 112/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 9.0049\n",
      "Epoch 112: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.8645 - val_loss: 11.7856\n",
      "Epoch 113/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 8.3228\n",
      "Epoch 113: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1988 - val_loss: 11.3725\n",
      "Epoch 114/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 8.9786\n",
      "Epoch 114: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9641 - val_loss: 11.7122\n",
      "Epoch 115/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 7.9982\n",
      "Epoch 115: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2443 - val_loss: 11.5552\n",
      "Epoch 116/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.7822\n",
      "Epoch 116: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8558 - val_loss: 12.7099\n",
      "Epoch 117/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 8.3277\n",
      "Epoch 117: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3109 - val_loss: 11.6591\n",
      "Epoch 118/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 8.3169\n",
      "Epoch 118: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6529 - val_loss: 11.8391\n",
      "Epoch 119/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 9.2070\n",
      "Epoch 119: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9030 - val_loss: 12.7090\n",
      "Epoch 120/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 8.0744\n",
      "Epoch 120: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1365 - val_loss: 12.4165\n",
      "Epoch 121/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 9.0968\n",
      "Epoch 121: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9498 - val_loss: 12.4807\n",
      "Epoch 122/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 8.8961\n",
      "Epoch 122: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9612 - val_loss: 11.5837\n",
      "Epoch 123/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 8.3444\n",
      "Epoch 123: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3444 - val_loss: 12.4877\n",
      "Epoch 124/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 8.3221\n",
      "Epoch 124: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3804 - val_loss: 11.6007\n",
      "Epoch 125/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.6222\n",
      "Epoch 125: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.8440 - val_loss: 11.6772\n",
      "Epoch 126/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 8.0481\n",
      "Epoch 126: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0217 - val_loss: 11.5923\n",
      "Epoch 127/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.3597\n",
      "Epoch 127: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6291 - val_loss: 12.7739\n",
      "Epoch 128/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 8.5171\n",
      "Epoch 128: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4699 - val_loss: 11.5508\n",
      "Epoch 129/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.7882\n",
      "Epoch 129: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6827 - val_loss: 12.5363\n",
      "Epoch 130/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 8.1093\n",
      "Epoch 130: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0361 - val_loss: 12.1916\n",
      "Epoch 131/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.9615\n",
      "Epoch 131: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9615 - val_loss: 11.3525\n",
      "Epoch 132/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 7.7114\n",
      "Epoch 132: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7234 - val_loss: 12.6600\n",
      "Epoch 133/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 8.9026\n",
      "Epoch 133: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.8487 - val_loss: 12.1193\n",
      "Epoch 134/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 8.2444\n",
      "Epoch 134: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6005 - val_loss: 12.3094\n",
      "Epoch 135/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 8.5098\n",
      "Epoch 135: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5695 - val_loss: 11.5753\n",
      "Epoch 136/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.0884\n",
      "Epoch 136: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1123 - val_loss: 13.0244\n",
      "Epoch 137/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 8.5644\n",
      "Epoch 137: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5644 - val_loss: 12.0206\n",
      "Epoch 138/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.9050\n",
      "Epoch 138: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7408 - val_loss: 12.6186\n",
      "Epoch 139/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.9617\n",
      "Epoch 139: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8431 - val_loss: 12.1970\n",
      "Epoch 140/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 8.8938\n",
      "Epoch 140: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6448 - val_loss: 12.4090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 8.4170\n",
      "Epoch 141: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3695 - val_loss: 12.4626\n",
      "Epoch 142/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 7.7665\n",
      "Epoch 142: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1328 - val_loss: 12.1785\n",
      "Epoch 143/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.6393\n",
      "Epoch 143: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7710 - val_loss: 12.6203\n",
      "Epoch 144/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 8.4143\n",
      "Epoch 144: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3124 - val_loss: 11.8625\n",
      "Epoch 145/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 8.1904\n",
      "Epoch 145: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2726 - val_loss: 12.2654\n",
      "Epoch 146/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 8.3568\n",
      "Epoch 146: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0416 - val_loss: 12.8031\n",
      "Epoch 147/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 8.1984\n",
      "Epoch 147: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1018 - val_loss: 11.6753\n",
      "Epoch 148/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 8.3758\n",
      "Epoch 148: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4198 - val_loss: 11.8425\n",
      "Epoch 149/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.4081\n",
      "Epoch 149: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3904 - val_loss: 11.6469\n",
      "Epoch 150/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.7877\n",
      "Epoch 150: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1003 - val_loss: 11.7781\n",
      "Epoch 151/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 8.5686\n",
      "Epoch 151: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4866 - val_loss: 11.4430\n",
      "Epoch 152/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.5114\n",
      "Epoch 152: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5481 - val_loss: 12.4056\n",
      "Epoch 153/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 8.2210\n",
      "Epoch 153: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3301 - val_loss: 12.5705\n",
      "Epoch 154/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.9639\n",
      "Epoch 154: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7543 - val_loss: 12.1615\n",
      "Epoch 155/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 8.4740\n",
      "Epoch 155: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5350 - val_loss: 12.2893\n",
      "Epoch 156/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.7624\n",
      "Epoch 156: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7270 - val_loss: 12.2651\n",
      "Epoch 157/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 8.1904\n",
      "Epoch 157: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2919 - val_loss: 12.3285\n",
      "Epoch 158/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.7748\n",
      "Epoch 158: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8257 - val_loss: 12.3032\n",
      "Epoch 159/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.1963\n",
      "Epoch 159: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2017 - val_loss: 13.1593\n",
      "Epoch 160/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 8.0671\n",
      "Epoch 160: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0449 - val_loss: 12.0031\n",
      "Epoch 161/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 7.5710\n",
      "Epoch 161: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5593 - val_loss: 12.8387\n",
      "Epoch 162/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 7.7203\n",
      "Epoch 162: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6823 - val_loss: 11.3556\n",
      "Epoch 163/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 7.7230\n",
      "Epoch 163: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5251 - val_loss: 11.5084\n",
      "Epoch 164/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.8679\n",
      "Epoch 164: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9503 - val_loss: 12.8579\n",
      "Epoch 165/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 7.8450\n",
      "Epoch 165: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8138 - val_loss: 11.8573\n",
      "Epoch 166/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 8.4389\n",
      "Epoch 166: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1792 - val_loss: 12.1998\n",
      "Epoch 167/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.3641\n",
      "Epoch 167: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4054 - val_loss: 12.1518\n",
      "Epoch 168/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.2448\n",
      "Epoch 168: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4689 - val_loss: 12.0015\n",
      "Epoch 169/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.9017\n",
      "Epoch 169: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0802 - val_loss: 11.7192\n",
      "Epoch 170/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.8598\n",
      "Epoch 170: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9249 - val_loss: 11.5066\n",
      "Epoch 171/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 7.5856\n",
      "Epoch 171: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5947 - val_loss: 11.8573\n",
      "Epoch 172/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.5069\n",
      "Epoch 172: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.3745 - val_loss: 12.8706\n",
      "Epoch 173/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 7.3676\n",
      "Epoch 173: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4071 - val_loss: 11.8244\n",
      "Epoch 174/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.5992\n",
      "Epoch 174: val_loss did not improve from 11.15048\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0241 - val_loss: 13.7633\n",
      "Epoch 175/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.6291\n",
      "Epoch 175: val_loss improved from 11.15048 to 11.06679, saving model to ./model_save\\1_fold_175-11.0668.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7579 - val_loss: 11.0668\n",
      "Epoch 176/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.5564\n",
      "Epoch 176: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6704 - val_loss: 13.1995\n",
      "Epoch 177/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.8767\n",
      "Epoch 177: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.8678 - val_loss: 13.6559\n",
      "Epoch 178/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.3784\n",
      "Epoch 178: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5546 - val_loss: 12.1270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.7783\n",
      "Epoch 179: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6846 - val_loss: 12.0723\n",
      "Epoch 180/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.6880\n",
      "Epoch 180: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6730 - val_loss: 11.0704\n",
      "Epoch 181/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.0950\n",
      "Epoch 181: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9935 - val_loss: 12.7550\n",
      "Epoch 182/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 7.2799\n",
      "Epoch 182: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1135 - val_loss: 11.9012\n",
      "Epoch 183/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 7.4280\n",
      "Epoch 183: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2963 - val_loss: 11.3275\n",
      "Epoch 184/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 8.1865\n",
      "Epoch 184: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2024 - val_loss: 12.4051\n",
      "Epoch 185/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.5060\n",
      "Epoch 185: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5832 - val_loss: 12.4969\n",
      "Epoch 186/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 8.1560\n",
      "Epoch 186: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4301 - val_loss: 12.2666\n",
      "Epoch 187/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.8116\n",
      "Epoch 187: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8512 - val_loss: 11.5764\n",
      "Epoch 188/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.5151\n",
      "Epoch 188: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4566 - val_loss: 11.7693\n",
      "Epoch 189/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 7.1069\n",
      "Epoch 189: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2610 - val_loss: 12.4075\n",
      "Epoch 190/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.3374\n",
      "Epoch 190: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2486 - val_loss: 12.5445\n",
      "Epoch 191/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.6104\n",
      "Epoch 191: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5704 - val_loss: 11.2249\n",
      "Epoch 192/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.4489\n",
      "Epoch 192: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5887 - val_loss: 11.2241\n",
      "Epoch 193/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.5508\n",
      "Epoch 193: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5762 - val_loss: 11.7389\n",
      "Epoch 194/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.9498\n",
      "Epoch 194: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0320 - val_loss: 12.1752\n",
      "Epoch 195/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.7147\n",
      "Epoch 195: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8780 - val_loss: 12.2889\n",
      "Epoch 196/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 7.2285\n",
      "Epoch 196: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3332 - val_loss: 12.3293\n",
      "Epoch 197/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 7.4776\n",
      "Epoch 197: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4804 - val_loss: 11.9958\n",
      "Epoch 198/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 8.2591\n",
      "Epoch 198: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9340 - val_loss: 12.1491\n",
      "Epoch 199/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 7.5555\n",
      "Epoch 199: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5113 - val_loss: 11.2143\n",
      "Epoch 200/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.6030\n",
      "Epoch 200: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3495 - val_loss: 12.0999\n",
      "Epoch 201/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 7.3917\n",
      "Epoch 201: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1851 - val_loss: 11.9285\n",
      "Epoch 202/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 7.1091\n",
      "Epoch 202: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2858 - val_loss: 13.7839\n",
      "Epoch 203/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.1932\n",
      "Epoch 203: val_loss did not improve from 11.06679\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1932 - val_loss: 12.6253\n",
      "Epoch 204/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 7.8884\n",
      "Epoch 204: val_loss improved from 11.06679 to 10.95741, saving model to ./model_save\\1_fold_204-10.9574.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8449 - val_loss: 10.9574\n",
      "Epoch 205/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.9768\n",
      "Epoch 205: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9909 - val_loss: 12.3907\n",
      "Epoch 206/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 7.2123\n",
      "Epoch 206: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1305 - val_loss: 11.5958\n",
      "Epoch 207/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.9508\n",
      "Epoch 207: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9109 - val_loss: 11.9284\n",
      "Epoch 208/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.5735\n",
      "Epoch 208: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4223 - val_loss: 12.1931\n",
      "Epoch 209/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.3711\n",
      "Epoch 209: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4929 - val_loss: 11.5288\n",
      "Epoch 210/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 6.7444\n",
      "Epoch 210: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8275 - val_loss: 12.5973\n",
      "Epoch 211/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.6529\n",
      "Epoch 211: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6722 - val_loss: 12.3766\n",
      "Epoch 212/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.9549\n",
      "Epoch 212: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0537 - val_loss: 13.6606\n",
      "Epoch 213/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 7.0434\n",
      "Epoch 213: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0876 - val_loss: 13.0744\n",
      "Epoch 214/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 7.2581\n",
      "Epoch 214: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4206 - val_loss: 13.7778\n",
      "Epoch 215/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 7.2378\n",
      "Epoch 215: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3587 - val_loss: 11.9600\n",
      "Epoch 216/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.3340\n",
      "Epoch 216: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1927 - val_loss: 11.3435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.4062\n",
      "Epoch 217: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.3453 - val_loss: 11.7553\n",
      "Epoch 218/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.0860\n",
      "Epoch 218: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0054 - val_loss: 12.5908\n",
      "Epoch 219/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.3032\n",
      "Epoch 219: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3747 - val_loss: 11.4480\n",
      "Epoch 220/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.6416\n",
      "Epoch 220: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.5714 - val_loss: 11.5074\n",
      "Epoch 221/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 7.4683\n",
      "Epoch 221: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.1213 - val_loss: 11.0688\n",
      "Epoch 222/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.3269\n",
      "Epoch 222: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3269 - val_loss: 12.7395\n",
      "Epoch 223/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 7.1955\n",
      "Epoch 223: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1350 - val_loss: 11.8202\n",
      "Epoch 224/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.2413\n",
      "Epoch 224: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2788 - val_loss: 12.9595\n",
      "Epoch 225/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 6.4570\n",
      "Epoch 225: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5800 - val_loss: 12.7575\n",
      "Epoch 226/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.2688\n",
      "Epoch 226: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2688 - val_loss: 13.1670\n",
      "Epoch 227/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.1025\n",
      "Epoch 227: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0879 - val_loss: 11.9459\n",
      "Epoch 228/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.8237\n",
      "Epoch 228: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8237 - val_loss: 12.6470\n",
      "Epoch 229/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 8.0858\n",
      "Epoch 229: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7194 - val_loss: 12.9080\n",
      "Epoch 230/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.2075\n",
      "Epoch 230: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1420 - val_loss: 13.2088\n",
      "Epoch 231/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.5071\n",
      "Epoch 231: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4264 - val_loss: 12.2624\n",
      "Epoch 232/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 7.0831\n",
      "Epoch 232: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3196 - val_loss: 12.4937\n",
      "Epoch 233/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.8656\n",
      "Epoch 233: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8624 - val_loss: 12.3279\n",
      "Epoch 234/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.6723\n",
      "Epoch 234: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7754 - val_loss: 12.5884\n",
      "Epoch 235/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.0684\n",
      "Epoch 235: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8518 - val_loss: 11.4729\n",
      "Epoch 236/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.8656\n",
      "Epoch 236: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5037 - val_loss: 12.6845\n",
      "Epoch 237/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.3263\n",
      "Epoch 237: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0531 - val_loss: 12.5890\n",
      "Epoch 238/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.7082\n",
      "Epoch 238: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8424 - val_loss: 11.5435\n",
      "Epoch 239/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 6.7669\n",
      "Epoch 239: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7318 - val_loss: 12.3712\n",
      "Epoch 240/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.3707\n",
      "Epoch 240: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4076 - val_loss: 11.7982\n",
      "Epoch 241/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.2473\n",
      "Epoch 241: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7996 - val_loss: 11.9075\n",
      "Epoch 242/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.4205\n",
      "Epoch 242: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6686 - val_loss: 12.0057\n",
      "Epoch 243/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 7.6481\n",
      "Epoch 243: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4912 - val_loss: 11.7311\n",
      "Epoch 244/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.9430\n",
      "Epoch 244: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8193 - val_loss: 12.6162\n",
      "Epoch 245/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.7046\n",
      "Epoch 245: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9869 - val_loss: 11.6914\n",
      "Epoch 246/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.0580\n",
      "Epoch 246: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7323 - val_loss: 12.6762\n",
      "Epoch 247/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.5870\n",
      "Epoch 247: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6072 - val_loss: 13.0396\n",
      "Epoch 248/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.6642\n",
      "Epoch 248: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6577 - val_loss: 11.6073\n",
      "Epoch 249/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 7.0512\n",
      "Epoch 249: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.8929 - val_loss: 12.1073\n",
      "Epoch 250/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.9907\n",
      "Epoch 250: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9907 - val_loss: 13.0661\n",
      "Epoch 251/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.9719\n",
      "Epoch 251: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8535 - val_loss: 12.5495\n",
      "Epoch 252/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 7.1700\n",
      "Epoch 252: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1768 - val_loss: 13.1108\n",
      "Epoch 253/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 7.3404\n",
      "Epoch 253: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.1037 - val_loss: 12.1555\n",
      "Epoch 254/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.9483\n",
      "Epoch 254: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0567 - val_loss: 12.8663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 255/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.6053\n",
      "Epoch 255: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6212 - val_loss: 11.8041\n",
      "Epoch 256/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.7778\n",
      "Epoch 256: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6810 - val_loss: 11.6181\n",
      "Epoch 257/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.7739\n",
      "Epoch 257: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7686 - val_loss: 11.9805\n",
      "Epoch 258/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.4224\n",
      "Epoch 258: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3964 - val_loss: 11.4832\n",
      "Epoch 259/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.3984\n",
      "Epoch 259: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6955 - val_loss: 11.7967\n",
      "Epoch 260/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.9627\n",
      "Epoch 260: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9891 - val_loss: 13.1784\n",
      "Epoch 261/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.7257\n",
      "Epoch 261: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7165 - val_loss: 11.2598\n",
      "Epoch 262/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.9837\n",
      "Epoch 262: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0086 - val_loss: 11.7209\n",
      "Epoch 263/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.8316\n",
      "Epoch 263: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7750 - val_loss: 11.4060\n",
      "Epoch 264/700\n",
      "60/84 [====================>.........] - ETA: 0s - loss: 6.7777\n",
      "Epoch 264: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8505 - val_loss: 12.6411\n",
      "Epoch 265/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.9157\n",
      "Epoch 265: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8610 - val_loss: 12.1721\n",
      "Epoch 266/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 7.0187\n",
      "Epoch 266: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.0823 - val_loss: 11.8276\n",
      "Epoch 267/700\n",
      "61/84 [====================>.........] - ETA: 0s - loss: 6.4183\n",
      "Epoch 267: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.1821 - val_loss: 12.7746\n",
      "Epoch 268/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.8375\n",
      "Epoch 268: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7483 - val_loss: 11.4779\n",
      "Epoch 269/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.2158\n",
      "Epoch 269: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2158 - val_loss: 12.5487\n",
      "Epoch 270/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.6755\n",
      "Epoch 270: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6874 - val_loss: 12.1933\n",
      "Epoch 271/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.3394\n",
      "Epoch 271: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4215 - val_loss: 13.1343\n",
      "Epoch 272/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 6.9023\n",
      "Epoch 272: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.5047 - val_loss: 12.2596\n",
      "Epoch 273/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 7.2047\n",
      "Epoch 273: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.3902 - val_loss: 12.1454\n",
      "Epoch 274/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.6855\n",
      "Epoch 274: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5907 - val_loss: 13.1601\n",
      "Epoch 275/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.2008\n",
      "Epoch 275: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.3089 - val_loss: 12.4904\n",
      "Epoch 276/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.0597\n",
      "Epoch 276: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8728 - val_loss: 11.6623\n",
      "Epoch 277/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.2130\n",
      "Epoch 277: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2849 - val_loss: 11.8153\n",
      "Epoch 278/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.8174\n",
      "Epoch 278: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.9338 - val_loss: 12.4348\n",
      "Epoch 279/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.5517\n",
      "Epoch 279: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6046 - val_loss: 11.7585\n",
      "Epoch 280/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.2005\n",
      "Epoch 280: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0713 - val_loss: 12.2952\n",
      "Epoch 281/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.1939\n",
      "Epoch 281: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3028 - val_loss: 12.5393\n",
      "Epoch 282/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.1233\n",
      "Epoch 282: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1230 - val_loss: 12.4431\n",
      "Epoch 283/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.1435\n",
      "Epoch 283: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1435 - val_loss: 13.3214\n",
      "Epoch 284/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.4569\n",
      "Epoch 284: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5161 - val_loss: 13.1085\n",
      "Epoch 285/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 6.5506\n",
      "Epoch 285: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.7289 - val_loss: 11.2156\n",
      "Epoch 286/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.8221\n",
      "Epoch 286: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8024 - val_loss: 11.1910\n",
      "Epoch 287/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.4385\n",
      "Epoch 287: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4704 - val_loss: 12.3724\n",
      "Epoch 288/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.2556\n",
      "Epoch 288: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2398 - val_loss: 12.9904\n",
      "Epoch 289/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.3665\n",
      "Epoch 289: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3651 - val_loss: 12.1655\n",
      "Epoch 290/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.3476\n",
      "Epoch 290: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3065 - val_loss: 13.1616\n",
      "Epoch 291/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.4231\n",
      "Epoch 291: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5507 - val_loss: 12.3002\n",
      "Epoch 292/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.2625\n",
      "Epoch 292: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2625 - val_loss: 12.2902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.1510\n",
      "Epoch 293: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2458 - val_loss: 11.0508\n",
      "Epoch 294/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.7314\n",
      "Epoch 294: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7026 - val_loss: 12.2639\n",
      "Epoch 295/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.2252\n",
      "Epoch 295: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2549 - val_loss: 13.1755\n",
      "Epoch 296/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.1898\n",
      "Epoch 296: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1898 - val_loss: 12.1950\n",
      "Epoch 297/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.3275\n",
      "Epoch 297: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4421 - val_loss: 12.2855\n",
      "Epoch 298/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.3724\n",
      "Epoch 298: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.3627 - val_loss: 12.3392\n",
      "Epoch 299/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.3154\n",
      "Epoch 299: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2953 - val_loss: 12.1631\n",
      "Epoch 300/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.2992\n",
      "Epoch 300: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2464 - val_loss: 11.4704\n",
      "Epoch 301/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.8549\n",
      "Epoch 301: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8811 - val_loss: 13.0223\n",
      "Epoch 302/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.1668\n",
      "Epoch 302: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2551 - val_loss: 11.9918\n",
      "Epoch 303/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.1231\n",
      "Epoch 303: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1814 - val_loss: 11.9579\n",
      "Epoch 304/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.8874\n",
      "Epoch 304: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8750 - val_loss: 13.1868\n",
      "Epoch 305/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.8054\n",
      "Epoch 305: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5822 - val_loss: 12.2686\n",
      "Epoch 306/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.5341\n",
      "Epoch 306: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6080 - val_loss: 12.8710\n",
      "Epoch 307/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.6892\n",
      "Epoch 307: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7998 - val_loss: 11.3987\n",
      "Epoch 308/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.6335\n",
      "Epoch 308: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7531 - val_loss: 12.6548\n",
      "Epoch 309/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 6.5459\n",
      "Epoch 309: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.5655 - val_loss: 11.6474\n",
      "Epoch 310/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 6.4522\n",
      "Epoch 310: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.3367 - val_loss: 12.2616\n",
      "Epoch 311/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.1997\n",
      "Epoch 311: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1303 - val_loss: 12.4042\n",
      "Epoch 312/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 5.8491\n",
      "Epoch 312: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.7789 - val_loss: 11.9307\n",
      "Epoch 313/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 6.7662\n",
      "Epoch 313: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.7145 - val_loss: 12.3233\n",
      "Epoch 314/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.1828\n",
      "Epoch 314: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1795 - val_loss: 13.1400\n",
      "Epoch 315/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.7841\n",
      "Epoch 315: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7714 - val_loss: 11.2590\n",
      "Epoch 316/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.0508\n",
      "Epoch 316: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7516 - val_loss: 12.5487\n",
      "Epoch 317/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.7088\n",
      "Epoch 317: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0803 - val_loss: 12.3837\n",
      "Epoch 318/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.7858\n",
      "Epoch 318: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8058 - val_loss: 12.7902\n",
      "Epoch 319/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 6.6755\n",
      "Epoch 319: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.5391 - val_loss: 13.0875\n",
      "Epoch 320/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.8671\n",
      "Epoch 320: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.1604 - val_loss: 12.8915\n",
      "Epoch 321/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.3659\n",
      "Epoch 321: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3443 - val_loss: 12.4544\n",
      "Epoch 322/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.6723\n",
      "Epoch 322: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6065 - val_loss: 12.6037\n",
      "Epoch 323/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.5473\n",
      "Epoch 323: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4513 - val_loss: 12.5398\n",
      "Epoch 324/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.5047\n",
      "Epoch 324: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5047 - val_loss: 11.7143\n",
      "Epoch 325/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.6267\n",
      "Epoch 325: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6045 - val_loss: 12.1187\n",
      "Epoch 326/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.3893\n",
      "Epoch 326: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3893 - val_loss: 13.9044\n",
      "Epoch 327/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.3852\n",
      "Epoch 327: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4491 - val_loss: 12.1482\n",
      "Epoch 328/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.1721\n",
      "Epoch 328: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1986 - val_loss: 13.6094\n",
      "Epoch 329/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.5364\n",
      "Epoch 329: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3371 - val_loss: 12.4001\n",
      "Epoch 330/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.2981\n",
      "Epoch 330: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3202 - val_loss: 13.0737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.8815\n",
      "Epoch 331: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8760 - val_loss: 12.3527\n",
      "Epoch 332/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 6.4645\n",
      "Epoch 332: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.4622 - val_loss: 12.4063\n",
      "Epoch 333/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 5.8153\n",
      "Epoch 333: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.0439 - val_loss: 11.9638\n",
      "Epoch 334/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.9881\n",
      "Epoch 334: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1111 - val_loss: 12.3558\n",
      "Epoch 335/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.7697\n",
      "Epoch 335: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7697 - val_loss: 12.4482\n",
      "Epoch 336/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 6.8839\n",
      "Epoch 336: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6267 - val_loss: 11.9945\n",
      "Epoch 337/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.4878\n",
      "Epoch 337: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4878 - val_loss: 13.8974\n",
      "Epoch 338/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.8094\n",
      "Epoch 338: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8227 - val_loss: 12.7641\n",
      "Epoch 339/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.1889\n",
      "Epoch 339: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2899 - val_loss: 13.2650\n",
      "Epoch 340/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 6.0673\n",
      "Epoch 340: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.2549 - val_loss: 12.6166\n",
      "Epoch 341/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 5.2165\n",
      "Epoch 341: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.7370 - val_loss: 13.0115\n",
      "Epoch 342/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 6.5099\n",
      "Epoch 342: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3818 - val_loss: 12.3103\n",
      "Epoch 343/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 6.0586\n",
      "Epoch 343: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.0260 - val_loss: 12.5962\n",
      "Epoch 344/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 7.0749\n",
      "Epoch 344: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.5161 - val_loss: 12.0382\n",
      "Epoch 345/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.1083\n",
      "Epoch 345: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0836 - val_loss: 12.9146\n",
      "Epoch 346/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.3612\n",
      "Epoch 346: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3577 - val_loss: 13.0593\n",
      "Epoch 347/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.6239\n",
      "Epoch 347: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6367 - val_loss: 12.8751\n",
      "Epoch 348/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.8052\n",
      "Epoch 348: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8593 - val_loss: 13.8405\n",
      "Epoch 349/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 6.1890\n",
      "Epoch 349: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.0294 - val_loss: 13.6892\n",
      "Epoch 350/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.7817\n",
      "Epoch 350: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7630 - val_loss: 13.6638\n",
      "Epoch 351/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 5.8221\n",
      "Epoch 351: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1820 - val_loss: 12.1849\n",
      "Epoch 352/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.2308\n",
      "Epoch 352: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3468 - val_loss: 12.1495\n",
      "Epoch 353/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.0209\n",
      "Epoch 353: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0208 - val_loss: 13.3614\n",
      "Epoch 354/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.0781\n",
      "Epoch 354: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0781 - val_loss: 12.3636\n",
      "Epoch 355/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.1612\n",
      "Epoch 355: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0861 - val_loss: 12.3337\n",
      "Epoch 356/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.7371\n",
      "Epoch 356: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6090 - val_loss: 12.9105\n",
      "Epoch 357/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.0848\n",
      "Epoch 357: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0025 - val_loss: 12.6055\n",
      "Epoch 358/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.1188\n",
      "Epoch 358: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0636 - val_loss: 13.5541\n",
      "Epoch 359/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.0803\n",
      "Epoch 359: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1990 - val_loss: 13.4881\n",
      "Epoch 360/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.9114\n",
      "Epoch 360: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9692 - val_loss: 12.7976\n",
      "Epoch 361/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.3169\n",
      "Epoch 361: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2302 - val_loss: 12.6913\n",
      "Epoch 362/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.6932\n",
      "Epoch 362: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7168 - val_loss: 13.0664\n",
      "Epoch 363/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.3850\n",
      "Epoch 363: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4141 - val_loss: 13.5066\n",
      "Epoch 364/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.0831\n",
      "Epoch 364: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1748 - val_loss: 13.7447\n",
      "Epoch 365/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.9079\n",
      "Epoch 365: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0490 - val_loss: 13.5615\n",
      "Epoch 366/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.5762\n",
      "Epoch 366: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4431 - val_loss: 12.7224\n",
      "Epoch 367/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.8959\n",
      "Epoch 367: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9836 - val_loss: 13.6299\n",
      "Epoch 368/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.4295\n",
      "Epoch 368: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4908 - val_loss: 12.0964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.6478\n",
      "Epoch 369: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 6.6478 - val_loss: 13.8225\n",
      "Epoch 370/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.7418\n",
      "Epoch 370: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 5.8874 - val_loss: 14.2513\n",
      "Epoch 371/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.9484\n",
      "Epoch 371: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0575 - val_loss: 12.4496\n",
      "Epoch 372/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.7758\n",
      "Epoch 372: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9461 - val_loss: 12.6823\n",
      "Epoch 373/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.8189\n",
      "Epoch 373: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1333 - val_loss: 11.7601\n",
      "Epoch 374/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.1752\n",
      "Epoch 374: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2012 - val_loss: 13.7575\n",
      "Epoch 375/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.9488\n",
      "Epoch 375: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9779 - val_loss: 14.2238\n",
      "Epoch 376/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.8288\n",
      "Epoch 376: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8419 - val_loss: 12.8336\n",
      "Epoch 377/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.0647\n",
      "Epoch 377: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1140 - val_loss: 13.7900\n",
      "Epoch 378/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.9521\n",
      "Epoch 378: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9289 - val_loss: 12.9327\n",
      "Epoch 379/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.2576\n",
      "Epoch 379: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2512 - val_loss: 13.1281\n",
      "Epoch 380/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.1908\n",
      "Epoch 380: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1778 - val_loss: 13.4526\n",
      "Epoch 381/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.7249\n",
      "Epoch 381: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6946 - val_loss: 14.0686\n",
      "Epoch 382/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.1865\n",
      "Epoch 382: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1865 - val_loss: 12.2742\n",
      "Epoch 383/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.0027\n",
      "Epoch 383: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9892 - val_loss: 13.0776\n",
      "Epoch 384/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.9557\n",
      "Epoch 384: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0453 - val_loss: 12.7002\n",
      "Epoch 385/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.0894\n",
      "Epoch 385: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0019 - val_loss: 12.2228\n",
      "Epoch 386/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.5586\n",
      "Epoch 386: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6425 - val_loss: 14.2774\n",
      "Epoch 387/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.8866\n",
      "Epoch 387: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8987 - val_loss: 14.6576\n",
      "Epoch 388/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.9618\n",
      "Epoch 388: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0288 - val_loss: 13.8613\n",
      "Epoch 389/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.7334\n",
      "Epoch 389: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7306 - val_loss: 12.8645\n",
      "Epoch 390/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.2065\n",
      "Epoch 390: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1789 - val_loss: 14.1734\n",
      "Epoch 391/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.2455\n",
      "Epoch 391: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1975 - val_loss: 13.1263\n",
      "Epoch 392/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.7223\n",
      "Epoch 392: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7114 - val_loss: 13.5579\n",
      "Epoch 393/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.9703\n",
      "Epoch 393: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9703 - val_loss: 13.5565\n",
      "Epoch 394/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.9351\n",
      "Epoch 394: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8000 - val_loss: 13.0920\n",
      "Epoch 395/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.5295\n",
      "Epoch 395: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6389 - val_loss: 13.3834\n",
      "Epoch 396/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.5330\n",
      "Epoch 396: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6494 - val_loss: 13.9942\n",
      "Epoch 397/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.7266\n",
      "Epoch 397: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0102 - val_loss: 12.5682\n",
      "Epoch 398/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 5.6827\n",
      "Epoch 398: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8472 - val_loss: 14.7164\n",
      "Epoch 399/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.0987\n",
      "Epoch 399: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0976 - val_loss: 14.5318\n",
      "Epoch 400/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.3645\n",
      "Epoch 400: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3461 - val_loss: 14.4220\n",
      "Epoch 401/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.8413\n",
      "Epoch 401: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 5.8693 - val_loss: 13.1579\n",
      "Epoch 402/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.0923\n",
      "Epoch 402: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0069 - val_loss: 14.8383\n",
      "Epoch 403/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.9425\n",
      "Epoch 403: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9564 - val_loss: 12.4312\n",
      "Epoch 404/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.6024\n",
      "Epoch 404: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8372 - val_loss: 14.1006\n",
      "Epoch 405/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.0286\n",
      "Epoch 405: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2965 - val_loss: 13.2452\n",
      "Epoch 406/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.8447\n",
      "Epoch 406: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7867 - val_loss: 13.1997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.6922\n",
      "Epoch 407: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7140 - val_loss: 13.0996\n",
      "Epoch 408/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.5130\n",
      "Epoch 408: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5130 - val_loss: 14.4406\n",
      "Epoch 409/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.4267\n",
      "Epoch 409: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3624 - val_loss: 12.9744\n",
      "Epoch 410/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.6704\n",
      "Epoch 410: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6574 - val_loss: 12.8070\n",
      "Epoch 411/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.6879\n",
      "Epoch 411: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6369 - val_loss: 14.0076\n",
      "Epoch 412/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.4981\n",
      "Epoch 412: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4136 - val_loss: 13.4144\n",
      "Epoch 413/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.6396\n",
      "Epoch 413: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5482 - val_loss: 13.8436\n",
      "Epoch 414/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.6915\n",
      "Epoch 414: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6764 - val_loss: 13.7235\n",
      "Epoch 415/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.0742\n",
      "Epoch 415: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0186 - val_loss: 12.2937\n",
      "Epoch 416/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.6439\n",
      "Epoch 416: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5629 - val_loss: 12.4395\n",
      "Epoch 417/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.9277\n",
      "Epoch 417: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9173 - val_loss: 13.9457\n",
      "Epoch 418/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.8638\n",
      "Epoch 418: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8548 - val_loss: 14.6345\n",
      "Epoch 419/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.7511\n",
      "Epoch 419: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7764 - val_loss: 13.5726\n",
      "Epoch 420/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.1433\n",
      "Epoch 420: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1882 - val_loss: 14.0059\n",
      "Epoch 421/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.4958\n",
      "Epoch 421: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4596 - val_loss: 13.1420\n",
      "Epoch 422/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.6783\n",
      "Epoch 422: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6259 - val_loss: 13.4892\n",
      "Epoch 423/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.7361\n",
      "Epoch 423: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7361 - val_loss: 14.1136\n",
      "Epoch 424/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.3121\n",
      "Epoch 424: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.3672 - val_loss: 13.7043\n",
      "Epoch 425/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.4739\n",
      "Epoch 425: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4952 - val_loss: 14.2566\n",
      "Epoch 426/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.8882\n",
      "Epoch 426: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0456 - val_loss: 13.6479\n",
      "Epoch 427/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.8096\n",
      "Epoch 427: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8105 - val_loss: 13.3567\n",
      "Epoch 428/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.6827\n",
      "Epoch 428: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6218 - val_loss: 15.2515\n",
      "Epoch 429/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.5828\n",
      "Epoch 429: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4915 - val_loss: 14.0814\n",
      "Epoch 430/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.6716\n",
      "Epoch 430: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6716 - val_loss: 13.9125\n",
      "Epoch 431/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.9367\n",
      "Epoch 431: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9202 - val_loss: 13.6193\n",
      "Epoch 432/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.8363\n",
      "Epoch 432: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7975 - val_loss: 13.0880\n",
      "Epoch 433/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.6708\n",
      "Epoch 433: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6708 - val_loss: 14.3705\n",
      "Epoch 434/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 6.1366\n",
      "Epoch 434: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8768 - val_loss: 14.3454\n",
      "Epoch 435/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.4788\n",
      "Epoch 435: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4852 - val_loss: 13.6276\n",
      "Epoch 436/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.7091\n",
      "Epoch 436: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6365 - val_loss: 14.1865\n",
      "Epoch 437/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 5.6840\n",
      "Epoch 437: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.0934 - val_loss: 12.7862\n",
      "Epoch 438/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 5.3846\n",
      "Epoch 438: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.5031 - val_loss: 14.7025\n",
      "Epoch 439/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 5.0645\n",
      "Epoch 439: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0960 - val_loss: 14.7703\n",
      "Epoch 440/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.7546\n",
      "Epoch 440: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.7539 - val_loss: 15.0025\n",
      "Epoch 441/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.9576\n",
      "Epoch 441: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9516 - val_loss: 13.2203\n",
      "Epoch 442/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.4448\n",
      "Epoch 442: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4912 - val_loss: 12.7436\n",
      "Epoch 443/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.9630\n",
      "Epoch 443: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9093 - val_loss: 13.7753\n",
      "Epoch 444/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.3991\n",
      "Epoch 444: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3895 - val_loss: 13.1559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.7172\n",
      "Epoch 445: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8258 - val_loss: 14.9286\n",
      "Epoch 446/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.9374\n",
      "Epoch 446: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9020 - val_loss: 14.5747\n",
      "Epoch 447/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.8735\n",
      "Epoch 447: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8424 - val_loss: 13.5522\n",
      "Epoch 448/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.5093\n",
      "Epoch 448: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6318 - val_loss: 13.1615\n",
      "Epoch 449/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.9777\n",
      "Epoch 449: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9207 - val_loss: 14.5752\n",
      "Epoch 450/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.6887\n",
      "Epoch 450: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7202 - val_loss: 14.8002\n",
      "Epoch 451/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.3375\n",
      "Epoch 451: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4969 - val_loss: 13.5051\n",
      "Epoch 452/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.2069\n",
      "Epoch 452: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4225 - val_loss: 13.3827\n",
      "Epoch 453/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.3592\n",
      "Epoch 453: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4405 - val_loss: 13.4260\n",
      "Epoch 454/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.6495\n",
      "Epoch 454: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 5.4912 - val_loss: 13.2242\n",
      "Epoch 455/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.3283\n",
      "Epoch 455: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3363 - val_loss: 13.9388\n",
      "Epoch 456/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.0619\n",
      "Epoch 456: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0151 - val_loss: 13.9091\n",
      "Epoch 457/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.8142\n",
      "Epoch 457: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6144 - val_loss: 14.0087\n",
      "Epoch 458/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.1756\n",
      "Epoch 458: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1298 - val_loss: 13.2891\n",
      "Epoch 459/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.3014\n",
      "Epoch 459: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3433 - val_loss: 13.3188\n",
      "Epoch 460/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.3739\n",
      "Epoch 460: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3056 - val_loss: 13.9961\n",
      "Epoch 461/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.1687\n",
      "Epoch 461: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2699 - val_loss: 14.1745\n",
      "Epoch 462/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.1642\n",
      "Epoch 462: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1454 - val_loss: 13.8131\n",
      "Epoch 463/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.6684\n",
      "Epoch 463: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6459 - val_loss: 14.3729\n",
      "Epoch 464/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.4342\n",
      "Epoch 464: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4935 - val_loss: 13.0601\n",
      "Epoch 465/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.7447\n",
      "Epoch 465: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6647 - val_loss: 13.5344\n",
      "Epoch 466/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.3369\n",
      "Epoch 466: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3632 - val_loss: 14.5279\n",
      "Epoch 467/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 5.5259\n",
      "Epoch 467: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3596 - val_loss: 13.6616\n",
      "Epoch 468/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.2289\n",
      "Epoch 468: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3281 - val_loss: 14.1324\n",
      "Epoch 469/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.4863\n",
      "Epoch 469: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4766 - val_loss: 14.1884\n",
      "Epoch 470/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.6713\n",
      "Epoch 470: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7236 - val_loss: 14.1370\n",
      "Epoch 471/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.6107\n",
      "Epoch 471: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6107 - val_loss: 14.0655\n",
      "Epoch 472/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.4659\n",
      "Epoch 472: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4659 - val_loss: 13.8929\n",
      "Epoch 473/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.4621\n",
      "Epoch 473: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5193 - val_loss: 13.4808\n",
      "Epoch 474/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.1113\n",
      "Epoch 474: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3140 - val_loss: 13.3515\n",
      "Epoch 475/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.4537\n",
      "Epoch 475: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4597 - val_loss: 13.6021\n",
      "Epoch 476/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.1638\n",
      "Epoch 476: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2789 - val_loss: 14.1580\n",
      "Epoch 477/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.5550\n",
      "Epoch 477: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5003 - val_loss: 14.3777\n",
      "Epoch 478/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.4953\n",
      "Epoch 478: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4953 - val_loss: 13.6289\n",
      "Epoch 479/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.8099\n",
      "Epoch 479: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6284 - val_loss: 13.5049\n",
      "Epoch 480/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.2494\n",
      "Epoch 480: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2494 - val_loss: 14.1657\n",
      "Epoch 481/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.5706\n",
      "Epoch 481: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5857 - val_loss: 12.4366\n",
      "Epoch 482/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.3964\n",
      "Epoch 482: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3801 - val_loss: 13.9972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 483/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.6218\n",
      "Epoch 483: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6184 - val_loss: 14.3127\n",
      "Epoch 484/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.1549\n",
      "Epoch 484: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1549 - val_loss: 13.6732\n",
      "Epoch 485/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.0341\n",
      "Epoch 485: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0934 - val_loss: 14.5951\n",
      "Epoch 486/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.6116\n",
      "Epoch 486: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 5.6116 - val_loss: 14.2934\n",
      "Epoch 487/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.6051\n",
      "Epoch 487: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4590 - val_loss: 14.1653\n",
      "Epoch 488/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.9228\n",
      "Epoch 488: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8489 - val_loss: 14.9961\n",
      "Epoch 489/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.4777\n",
      "Epoch 489: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4482 - val_loss: 13.9606\n",
      "Epoch 490/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.4689\n",
      "Epoch 490: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4698 - val_loss: 15.0638\n",
      "Epoch 491/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.7424\n",
      "Epoch 491: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8326 - val_loss: 13.8580\n",
      "Epoch 492/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.0677\n",
      "Epoch 492: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0357 - val_loss: 15.9110\n",
      "Epoch 493/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.4897\n",
      "Epoch 493: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6575 - val_loss: 14.9372\n",
      "Epoch 494/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.4785\n",
      "Epoch 494: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4052 - val_loss: 14.3020\n",
      "Epoch 495/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.3331\n",
      "Epoch 495: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5044 - val_loss: 14.7068\n",
      "Epoch 496/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.6953\n",
      "Epoch 496: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6633 - val_loss: 14.6389\n",
      "Epoch 497/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.3129\n",
      "Epoch 497: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3084 - val_loss: 13.7754\n",
      "Epoch 498/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.6596\n",
      "Epoch 498: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7593 - val_loss: 13.9911\n",
      "Epoch 499/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.3277\n",
      "Epoch 499: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3512 - val_loss: 14.5181\n",
      "Epoch 500/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.6220\n",
      "Epoch 500: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6220 - val_loss: 14.7165\n",
      "Epoch 501/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.4505\n",
      "Epoch 501: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4880 - val_loss: 14.3498\n",
      "Epoch 502/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.0543\n",
      "Epoch 502: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0264 - val_loss: 14.4141\n",
      "Epoch 503/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.4872\n",
      "Epoch 503: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6890 - val_loss: 14.3151\n",
      "Epoch 504/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.4811\n",
      "Epoch 504: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5096 - val_loss: 13.9974\n",
      "Epoch 505/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.4840\n",
      "Epoch 505: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4122 - val_loss: 13.5663\n",
      "Epoch 506/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.2663\n",
      "Epoch 506: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2771 - val_loss: 13.8947\n",
      "Epoch 507/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.5642\n",
      "Epoch 507: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4950 - val_loss: 13.7811\n",
      "Epoch 508/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.6492\n",
      "Epoch 508: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8135 - val_loss: 13.3303\n",
      "Epoch 509/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.4047\n",
      "Epoch 509: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3873 - val_loss: 14.9173\n",
      "Epoch 510/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.5648\n",
      "Epoch 510: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5865 - val_loss: 14.7364\n",
      "Epoch 511/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.1855\n",
      "Epoch 511: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1855 - val_loss: 13.5155\n",
      "Epoch 512/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.3596\n",
      "Epoch 512: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3311 - val_loss: 13.1756\n",
      "Epoch 513/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.1605\n",
      "Epoch 513: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2371 - val_loss: 13.1028\n",
      "Epoch 514/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.6183\n",
      "Epoch 514: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5011 - val_loss: 13.5933\n",
      "Epoch 515/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.5946\n",
      "Epoch 515: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5946 - val_loss: 14.5241\n",
      "Epoch 516/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.7040\n",
      "Epoch 516: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7882 - val_loss: 13.4986\n",
      "Epoch 517/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.2471\n",
      "Epoch 517: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 5.2918 - val_loss: 15.1944\n",
      "Epoch 518/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.2078\n",
      "Epoch 518: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1831 - val_loss: 14.6426\n",
      "Epoch 519/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.2905\n",
      "Epoch 519: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 5.3992 - val_loss: 14.7588\n",
      "Epoch 520/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.0837\n",
      "Epoch 520: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1293 - val_loss: 15.1316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 521/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.3656\n",
      "Epoch 521: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3193 - val_loss: 14.1282\n",
      "Epoch 522/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.7540\n",
      "Epoch 522: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7940 - val_loss: 16.0145\n",
      "Epoch 523/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.8761\n",
      "Epoch 523: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8952 - val_loss: 14.8571\n",
      "Epoch 524/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.3580\n",
      "Epoch 524: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2856 - val_loss: 14.8549\n",
      "Epoch 525/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.4019\n",
      "Epoch 525: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4367 - val_loss: 14.4352\n",
      "Epoch 526/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.6204\n",
      "Epoch 526: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 5.6012 - val_loss: 13.8718\n",
      "Epoch 527/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.2782\n",
      "Epoch 527: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3496 - val_loss: 14.4789\n",
      "Epoch 528/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.1203\n",
      "Epoch 528: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1281 - val_loss: 15.6505\n",
      "Epoch 529/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.0180\n",
      "Epoch 529: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0050 - val_loss: 14.5603\n",
      "Epoch 530/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.0449\n",
      "Epoch 530: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0449 - val_loss: 14.5196\n",
      "Epoch 531/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.9854\n",
      "Epoch 531: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9893 - val_loss: 14.6834\n",
      "Epoch 532/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.6298\n",
      "Epoch 532: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5030 - val_loss: 14.2268\n",
      "Epoch 533/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.0344\n",
      "Epoch 533: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0246 - val_loss: 14.2457\n",
      "Epoch 534/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.4915\n",
      "Epoch 534: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 5.5696 - val_loss: 14.5424\n",
      "Epoch 535/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.1989\n",
      "Epoch 535: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1989 - val_loss: 14.3512\n",
      "Epoch 536/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 5.0182\n",
      "Epoch 536: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9193 - val_loss: 14.4113\n",
      "Epoch 537/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 4.9510\n",
      "Epoch 537: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9300 - val_loss: 14.8015\n",
      "Epoch 538/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.2748\n",
      "Epoch 538: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2179 - val_loss: 14.5337\n",
      "Epoch 539/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.4804\n",
      "Epoch 539: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4022 - val_loss: 15.6137\n",
      "Epoch 540/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.4768\n",
      "Epoch 540: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4269 - val_loss: 14.4097\n",
      "Epoch 541/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.4479\n",
      "Epoch 541: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3874 - val_loss: 15.4968\n",
      "Epoch 542/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.0591\n",
      "Epoch 542: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1257 - val_loss: 14.7126\n",
      "Epoch 543/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.1513\n",
      "Epoch 543: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1003 - val_loss: 14.6315\n",
      "Epoch 544/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.3340\n",
      "Epoch 544: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4204 - val_loss: 13.8962\n",
      "Epoch 545/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.2353\n",
      "Epoch 545: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 5.3766 - val_loss: 14.2339\n",
      "Epoch 546/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 4.7451\n",
      "Epoch 546: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 4.7821 - val_loss: 14.9292\n",
      "Epoch 547/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.2575\n",
      "Epoch 547: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 5.2137 - val_loss: 15.4397\n",
      "Epoch 548/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.0585\n",
      "Epoch 548: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 5.0489 - val_loss: 15.3639\n",
      "Epoch 549/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.2470\n",
      "Epoch 549: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2285 - val_loss: 16.8327\n",
      "Epoch 550/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.4636\n",
      "Epoch 550: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 5.3878 - val_loss: 14.6616\n",
      "Epoch 551/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.4239\n",
      "Epoch 551: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2766 - val_loss: 15.5689\n",
      "Epoch 552/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.2734\n",
      "Epoch 552: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3440 - val_loss: 15.3295\n",
      "Epoch 553/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.0595\n",
      "Epoch 553: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0595 - val_loss: 15.5043\n",
      "Epoch 554/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.5341\n",
      "Epoch 554: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3460 - val_loss: 14.0236\n",
      "Epoch 555/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.5679\n",
      "Epoch 555: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6478 - val_loss: 14.6386\n",
      "Epoch 556/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.6115\n",
      "Epoch 556: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5617 - val_loss: 15.2202\n",
      "Epoch 557/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.1009\n",
      "Epoch 557: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2353 - val_loss: 14.6007\n",
      "Epoch 558/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 4.9258\n",
      "Epoch 558: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8649 - val_loss: 14.4581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 559/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.5294\n",
      "Epoch 559: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4812 - val_loss: 14.7220\n",
      "Epoch 560/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.4207\n",
      "Epoch 560: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5072 - val_loss: 14.0465\n",
      "Epoch 561/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.9678\n",
      "Epoch 561: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8891 - val_loss: 14.0997\n",
      "Epoch 562/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.2180\n",
      "Epoch 562: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1676 - val_loss: 14.8385\n",
      "Epoch 563/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.5533\n",
      "Epoch 563: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5825 - val_loss: 15.5902\n",
      "Epoch 564/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.4693\n",
      "Epoch 564: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5261 - val_loss: 15.2529\n",
      "Epoch 565/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.1019\n",
      "Epoch 565: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0773 - val_loss: 14.6944\n",
      "Epoch 566/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.1921\n",
      "Epoch 566: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1496 - val_loss: 15.4169\n",
      "Epoch 567/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.0668\n",
      "Epoch 567: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0878 - val_loss: 16.5920\n",
      "Epoch 568/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 4.8586\n",
      "Epoch 568: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0816 - val_loss: 14.9449\n",
      "Epoch 569/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.2747\n",
      "Epoch 569: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3926 - val_loss: 15.6793\n",
      "Epoch 570/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.2606\n",
      "Epoch 570: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2816 - val_loss: 14.5667\n",
      "Epoch 571/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 4.8890\n",
      "Epoch 571: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9463 - val_loss: 14.7199\n",
      "Epoch 572/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.6958\n",
      "Epoch 572: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6734 - val_loss: 14.4439\n",
      "Epoch 573/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 4.7643\n",
      "Epoch 573: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7580 - val_loss: 14.7499\n",
      "Epoch 574/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 4.8443\n",
      "Epoch 574: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8569 - val_loss: 14.8499\n",
      "Epoch 575/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.4825\n",
      "Epoch 575: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4193 - val_loss: 14.8424\n",
      "Epoch 576/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.0198\n",
      "Epoch 576: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0820 - val_loss: 16.1294\n",
      "Epoch 577/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.0094\n",
      "Epoch 577: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1395 - val_loss: 14.7816\n",
      "Epoch 578/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.4379\n",
      "Epoch 578: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4379 - val_loss: 14.3382\n",
      "Epoch 579/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.3606\n",
      "Epoch 579: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3760 - val_loss: 15.0929\n",
      "Epoch 580/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.4069\n",
      "Epoch 580: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3035 - val_loss: 15.5551\n",
      "Epoch 581/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 4.8940\n",
      "Epoch 581: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9119 - val_loss: 15.0039\n",
      "Epoch 582/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 4.8969\n",
      "Epoch 582: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8969 - val_loss: 14.1910\n",
      "Epoch 583/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 4.9558\n",
      "Epoch 583: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9409 - val_loss: 14.6423\n",
      "Epoch 584/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.1113\n",
      "Epoch 584: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1435 - val_loss: 15.0271\n",
      "Epoch 585/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.3817\n",
      "Epoch 585: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1846 - val_loss: 14.9820\n",
      "Epoch 586/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.3663\n",
      "Epoch 586: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3493 - val_loss: 15.4384\n",
      "Epoch 587/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.1979\n",
      "Epoch 587: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0809 - val_loss: 13.7398\n",
      "Epoch 588/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.3398\n",
      "Epoch 588: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3153 - val_loss: 15.1555\n",
      "Epoch 589/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.5118\n",
      "Epoch 589: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4599 - val_loss: 14.7990\n",
      "Epoch 590/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.9248\n",
      "Epoch 590: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9144 - val_loss: 15.2928\n",
      "Epoch 591/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.1748\n",
      "Epoch 591: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1808 - val_loss: 14.3519\n",
      "Epoch 592/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.0941\n",
      "Epoch 592: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0927 - val_loss: 15.6275\n",
      "Epoch 593/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 4.8918\n",
      "Epoch 593: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8918 - val_loss: 13.6730\n",
      "Epoch 594/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 4.8716\n",
      "Epoch 594: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8716 - val_loss: 14.7687\n",
      "Epoch 595/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.2165\n",
      "Epoch 595: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1892 - val_loss: 14.3815\n",
      "Epoch 596/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 4.8784\n",
      "Epoch 596: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9013 - val_loss: 15.1112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 597/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.0285\n",
      "Epoch 597: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0047 - val_loss: 14.5830\n",
      "Epoch 598/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.1810\n",
      "Epoch 598: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1909 - val_loss: 14.5945\n",
      "Epoch 599/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 4.9085\n",
      "Epoch 599: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9270 - val_loss: 13.9947\n",
      "Epoch 600/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.0935\n",
      "Epoch 600: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0782 - val_loss: 13.9054\n",
      "Epoch 601/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 4.8963\n",
      "Epoch 601: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9448 - val_loss: 13.5366\n",
      "Epoch 602/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 4.8164\n",
      "Epoch 602: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8633 - val_loss: 13.2001\n",
      "Epoch 603/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 5.1170\n",
      "Epoch 603: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.2154 - val_loss: 14.9705\n",
      "Epoch 604/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.3137\n",
      "Epoch 604: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2758 - val_loss: 15.0804\n",
      "Epoch 605/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.0011\n",
      "Epoch 605: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9022 - val_loss: 14.5011\n",
      "Epoch 606/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 4.9019\n",
      "Epoch 606: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8139 - val_loss: 15.1736\n",
      "Epoch 607/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.0183\n",
      "Epoch 607: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0109 - val_loss: 15.3479\n",
      "Epoch 608/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.9744\n",
      "Epoch 608: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9358 - val_loss: 14.3910\n",
      "Epoch 609/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.8301\n",
      "Epoch 609: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7842 - val_loss: 15.3276\n",
      "Epoch 610/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.4123\n",
      "Epoch 610: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4036 - val_loss: 14.9197\n",
      "Epoch 611/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.1517\n",
      "Epoch 611: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1291 - val_loss: 14.5423\n",
      "Epoch 612/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.0583\n",
      "Epoch 612: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0969 - val_loss: 14.1700\n",
      "Epoch 613/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 4.8878\n",
      "Epoch 613: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1070 - val_loss: 14.9078\n",
      "Epoch 614/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.9797\n",
      "Epoch 614: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9708 - val_loss: 14.2832\n",
      "Epoch 615/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.4895\n",
      "Epoch 615: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4594 - val_loss: 15.7241\n",
      "Epoch 616/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.2621\n",
      "Epoch 616: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1467 - val_loss: 15.2542\n",
      "Epoch 617/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 4.9513\n",
      "Epoch 617: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9513 - val_loss: 15.1933\n",
      "Epoch 618/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.0716\n",
      "Epoch 618: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1077 - val_loss: 15.5560\n",
      "Epoch 619/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 4.7683\n",
      "Epoch 619: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9063 - val_loss: 15.3223\n",
      "Epoch 620/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 4.5891\n",
      "Epoch 620: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7527 - val_loss: 15.4548\n",
      "Epoch 621/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.1701\n",
      "Epoch 621: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1506 - val_loss: 14.5817\n",
      "Epoch 622/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 4.7148\n",
      "Epoch 622: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8778 - val_loss: 16.1939\n",
      "Epoch 623/700\n",
      "60/84 [====================>.........] - ETA: 0s - loss: 4.8769\n",
      "Epoch 623: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8509 - val_loss: 15.4505\n",
      "Epoch 624/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.0756\n",
      "Epoch 624: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1032 - val_loss: 14.9738\n",
      "Epoch 625/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 4.8415\n",
      "Epoch 625: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.0007 - val_loss: 15.0328\n",
      "Epoch 626/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.1363\n",
      "Epoch 626: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0368 - val_loss: 15.8715\n",
      "Epoch 627/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 4.9226\n",
      "Epoch 627: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8915 - val_loss: 14.8511\n",
      "Epoch 628/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.4175\n",
      "Epoch 628: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4129 - val_loss: 15.6975\n",
      "Epoch 629/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.1681\n",
      "Epoch 629: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.1885 - val_loss: 13.4749\n",
      "Epoch 630/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 4.7785\n",
      "Epoch 630: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7785 - val_loss: 15.1484\n",
      "Epoch 631/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.1914\n",
      "Epoch 631: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.1824 - val_loss: 15.3773\n",
      "Epoch 632/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.7818\n",
      "Epoch 632: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7726 - val_loss: 14.3041\n",
      "Epoch 633/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 4.8890\n",
      "Epoch 633: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8428 - val_loss: 14.9467\n",
      "Epoch 634/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.6820\n",
      "Epoch 634: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6867 - val_loss: 13.9832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 635/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 4.9708\n",
      "Epoch 635: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9775 - val_loss: 14.5728\n",
      "Epoch 636/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.8123\n",
      "Epoch 636: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8416 - val_loss: 15.3715\n",
      "Epoch 637/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.1583\n",
      "Epoch 637: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1249 - val_loss: 13.9945\n",
      "Epoch 638/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.5940\n",
      "Epoch 638: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5954 - val_loss: 15.0898\n",
      "Epoch 639/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.4953\n",
      "Epoch 639: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4953 - val_loss: 14.7925\n",
      "Epoch 640/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 4.9589\n",
      "Epoch 640: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9008 - val_loss: 14.3432\n",
      "Epoch 641/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 4.8912\n",
      "Epoch 641: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7943 - val_loss: 14.1724\n",
      "Epoch 642/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 4.7507\n",
      "Epoch 642: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8024 - val_loss: 14.3373\n",
      "Epoch 643/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.1660\n",
      "Epoch 643: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2688 - val_loss: 15.8510\n",
      "Epoch 644/700\n",
      "55/84 [==================>...........] - ETA: 0s - loss: 5.2542\n",
      "Epoch 644: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.4421 - val_loss: 15.1742\n",
      "Epoch 645/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 4.7569\n",
      "Epoch 645: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8455 - val_loss: 14.4740\n",
      "Epoch 646/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 4.8727\n",
      "Epoch 646: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8412 - val_loss: 14.1738\n",
      "Epoch 647/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 4.8936\n",
      "Epoch 647: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8902 - val_loss: 14.9647\n",
      "Epoch 648/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.5377\n",
      "Epoch 648: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5224 - val_loss: 14.3584\n",
      "Epoch 649/700\n",
      "55/84 [==================>...........] - ETA: 0s - loss: 5.1641\n",
      "Epoch 649: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.0717 - val_loss: 15.4469\n",
      "Epoch 650/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 4.8891\n",
      "Epoch 650: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8390 - val_loss: 15.4688\n",
      "Epoch 651/700\n",
      "60/84 [====================>.........] - ETA: 0s - loss: 5.0707\n",
      "Epoch 651: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.1529 - val_loss: 15.5451\n",
      "Epoch 652/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.9035\n",
      "Epoch 652: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9319 - val_loss: 13.9378\n",
      "Epoch 653/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.0068\n",
      "Epoch 653: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9030 - val_loss: 14.4805\n",
      "Epoch 654/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.3203\n",
      "Epoch 654: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3123 - val_loss: 14.6486\n",
      "Epoch 655/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 4.8100\n",
      "Epoch 655: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8555 - val_loss: 14.1250\n",
      "Epoch 656/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 4.7125\n",
      "Epoch 656: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2385 - val_loss: 15.3464\n",
      "Epoch 657/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 4.9912\n",
      "Epoch 657: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8446 - val_loss: 14.4259\n",
      "Epoch 658/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 4.6017\n",
      "Epoch 658: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6623 - val_loss: 13.7559\n",
      "Epoch 659/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 4.9728\n",
      "Epoch 659: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9697 - val_loss: 14.9654\n",
      "Epoch 660/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 5.1191\n",
      "Epoch 660: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2470 - val_loss: 15.2985\n",
      "Epoch 661/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 4.7792\n",
      "Epoch 661: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7171 - val_loss: 14.9303\n",
      "Epoch 662/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.1376\n",
      "Epoch 662: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0639 - val_loss: 13.8252\n",
      "Epoch 663/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 4.7925\n",
      "Epoch 663: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8588 - val_loss: 15.1232\n",
      "Epoch 664/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.3231\n",
      "Epoch 664: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3626 - val_loss: 14.6718\n",
      "Epoch 665/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 4.9199\n",
      "Epoch 665: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8854 - val_loss: 15.3777\n",
      "Epoch 666/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 4.7984\n",
      "Epoch 666: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7815 - val_loss: 15.0762\n",
      "Epoch 667/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 4.8232\n",
      "Epoch 667: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8769 - val_loss: 13.4999\n",
      "Epoch 668/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 4.8411\n",
      "Epoch 668: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8081 - val_loss: 15.4914\n",
      "Epoch 669/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 4.6502\n",
      "Epoch 669: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6513 - val_loss: 14.7826\n",
      "Epoch 670/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 4.9461\n",
      "Epoch 670: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9377 - val_loss: 15.3049\n",
      "Epoch 671/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 4.8988\n",
      "Epoch 671: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1252 - val_loss: 15.0560\n",
      "Epoch 672/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 4.9547\n",
      "Epoch 672: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8024 - val_loss: 15.4591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 673/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 4.8140\n",
      "Epoch 673: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7184 - val_loss: 14.5653\n",
      "Epoch 674/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.8367\n",
      "Epoch 674: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9142 - val_loss: 14.0730\n",
      "Epoch 675/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.1991\n",
      "Epoch 675: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3870 - val_loss: 14.5250\n",
      "Epoch 676/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 4.9100\n",
      "Epoch 676: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7168 - val_loss: 14.0295\n",
      "Epoch 677/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.2905\n",
      "Epoch 677: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0673 - val_loss: 14.4285\n",
      "Epoch 678/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 4.6595\n",
      "Epoch 678: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5917 - val_loss: 15.8358\n",
      "Epoch 679/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 4.6873\n",
      "Epoch 679: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6873 - val_loss: 14.4253\n",
      "Epoch 680/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.4913\n",
      "Epoch 680: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4902 - val_loss: 14.8336\n",
      "Epoch 681/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 4.9845\n",
      "Epoch 681: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9845 - val_loss: 15.6408\n",
      "Epoch 682/700\n",
      "61/84 [====================>.........] - ETA: 0s - loss: 4.7051\n",
      "Epoch 682: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9210 - val_loss: 12.9669\n",
      "Epoch 683/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.1393\n",
      "Epoch 683: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0504 - val_loss: 15.2671\n",
      "Epoch 684/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 4.8508\n",
      "Epoch 684: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7691 - val_loss: 14.3299\n",
      "Epoch 685/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 4.9903\n",
      "Epoch 685: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0012 - val_loss: 14.6691\n",
      "Epoch 686/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 4.7798\n",
      "Epoch 686: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7565 - val_loss: 13.8308\n",
      "Epoch 687/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 4.6412\n",
      "Epoch 687: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9388 - val_loss: 15.2984\n",
      "Epoch 688/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 4.8599\n",
      "Epoch 688: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8943 - val_loss: 15.0759\n",
      "Epoch 689/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 4.6102\n",
      "Epoch 689: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7064 - val_loss: 13.7398\n",
      "Epoch 690/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.1005\n",
      "Epoch 690: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1346 - val_loss: 15.1265\n",
      "Epoch 691/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.5989\n",
      "Epoch 691: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6452 - val_loss: 15.1840\n",
      "Epoch 692/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 4.6916\n",
      "Epoch 692: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7243 - val_loss: 14.0615\n",
      "Epoch 693/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 4.7744\n",
      "Epoch 693: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7071 - val_loss: 14.9887\n",
      "Epoch 694/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 4.9177\n",
      "Epoch 694: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9702 - val_loss: 15.5977\n",
      "Epoch 695/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 4.7795\n",
      "Epoch 695: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7865 - val_loss: 13.5316\n",
      "Epoch 696/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 4.9881\n",
      "Epoch 696: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9075 - val_loss: 14.7454\n",
      "Epoch 697/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 4.6246\n",
      "Epoch 697: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6561 - val_loss: 14.9909\n",
      "Epoch 698/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 4.8065\n",
      "Epoch 698: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8716 - val_loss: 15.4676\n",
      "Epoch 699/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 4.9845\n",
      "Epoch 699: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9381 - val_loss: 14.1632\n",
      "Epoch 700/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 4.9158\n",
      "Epoch 700: val_loss did not improve from 10.95741\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8465 - val_loss: 15.4040\n",
      "\n",
      " ---------- 1 ---------- \n",
      "\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 22, 8, 360)        3600      \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 7, 2, 360)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " reshape_8 (Reshape)         (None, 7, 720)            0         \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 7, 720)            0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 180)               648720    \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 180)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 181       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 652,501\n",
      "Trainable params: 652,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 53.5732\n",
      "Epoch 1: val_loss improved from inf to 27.57668, saving model to ./model_save\\2_fold_001-27.5767.hdf5\n",
      "84/84 [==============================] - 1s 5ms/step - loss: 50.6831 - val_loss: 27.5767\n",
      "Epoch 2/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 44.7088\n",
      "Epoch 2: val_loss improved from 27.57668 to 25.91962, saving model to ./model_save\\2_fold_002-25.9196.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 43.8869 - val_loss: 25.9196\n",
      "Epoch 3/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 41.4793\n",
      "Epoch 3: val_loss improved from 25.91962 to 21.41320, saving model to ./model_save\\2_fold_003-21.4132.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 4ms/step - loss: 41.1890 - val_loss: 21.4132\n",
      "Epoch 4/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 38.2020\n",
      "Epoch 4: val_loss improved from 21.41320 to 20.30310, saving model to ./model_save\\2_fold_004-20.3031.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 38.0783 - val_loss: 20.3031\n",
      "Epoch 5/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 36.6812\n",
      "Epoch 5: val_loss improved from 20.30310 to 17.59026, saving model to ./model_save\\2_fold_005-17.5903.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 36.2016 - val_loss: 17.5903\n",
      "Epoch 6/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 34.5034\n",
      "Epoch 6: val_loss improved from 17.59026 to 17.22552, saving model to ./model_save\\2_fold_006-17.2255.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 34.9491 - val_loss: 17.2255\n",
      "Epoch 7/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 32.9571\n",
      "Epoch 7: val_loss improved from 17.22552 to 16.08868, saving model to ./model_save\\2_fold_007-16.0887.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 32.9571 - val_loss: 16.0887\n",
      "Epoch 8/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 32.3557\n",
      "Epoch 8: val_loss did not improve from 16.08868\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 31.7254 - val_loss: 17.5615\n",
      "Epoch 9/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 31.9146\n",
      "Epoch 9: val_loss improved from 16.08868 to 15.77293, saving model to ./model_save\\2_fold_009-15.7729.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 31.7193 - val_loss: 15.7729\n",
      "Epoch 10/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 29.7905\n",
      "Epoch 10: val_loss improved from 15.77293 to 15.54899, saving model to ./model_save\\2_fold_010-15.5490.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 30.3817 - val_loss: 15.5490\n",
      "Epoch 11/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 28.4709\n",
      "Epoch 11: val_loss improved from 15.54899 to 15.54720, saving model to ./model_save\\2_fold_011-15.5472.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 28.3551 - val_loss: 15.5472\n",
      "Epoch 12/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 27.5188\n",
      "Epoch 12: val_loss improved from 15.54720 to 14.96668, saving model to ./model_save\\2_fold_012-14.9667.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 27.7953 - val_loss: 14.9667\n",
      "Epoch 13/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 27.6168\n",
      "Epoch 13: val_loss improved from 14.96668 to 14.05939, saving model to ./model_save\\2_fold_013-14.0594.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 27.4251 - val_loss: 14.0594\n",
      "Epoch 14/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 27.3125\n",
      "Epoch 14: val_loss did not improve from 14.05939\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 26.6645 - val_loss: 20.3021\n",
      "Epoch 15/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 25.9541\n",
      "Epoch 15: val_loss did not improve from 14.05939\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 25.8498 - val_loss: 22.7441\n",
      "Epoch 16/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 23.3145\n",
      "Epoch 16: val_loss did not improve from 14.05939\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 24.5091 - val_loss: 14.9558\n",
      "Epoch 17/700\n",
      "61/84 [====================>.........] - ETA: 0s - loss: 26.4235\n",
      "Epoch 17: val_loss improved from 14.05939 to 12.73083, saving model to ./model_save\\2_fold_017-12.7308.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 24.3932 - val_loss: 12.7308\n",
      "Epoch 18/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 24.1622\n",
      "Epoch 18: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 23.7864 - val_loss: 14.2403\n",
      "Epoch 19/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 22.9674\n",
      "Epoch 19: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 22.4844 - val_loss: 13.4625\n",
      "Epoch 20/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 24.2529\n",
      "Epoch 20: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 22.6819 - val_loss: 16.0533\n",
      "Epoch 21/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 22.1809\n",
      "Epoch 21: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 22.2067 - val_loss: 15.5389\n",
      "Epoch 22/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 22.1516\n",
      "Epoch 22: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 22.0885 - val_loss: 17.5616\n",
      "Epoch 23/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 21.2719\n",
      "Epoch 23: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 21.0208 - val_loss: 15.9074\n",
      "Epoch 24/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 21.2108\n",
      "Epoch 24: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 20.5092 - val_loss: 18.1230\n",
      "Epoch 25/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 22.2846\n",
      "Epoch 25: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 21.2192 - val_loss: 15.1007\n",
      "Epoch 26/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 20.5380\n",
      "Epoch 26: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 20.2422 - val_loss: 24.2181\n",
      "Epoch 27/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 23.1767\n",
      "Epoch 27: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 21.9402 - val_loss: 13.1549\n",
      "Epoch 28/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 20.1811\n",
      "Epoch 28: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.9102 - val_loss: 16.0838\n",
      "Epoch 29/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 19.8595\n",
      "Epoch 29: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.0379 - val_loss: 17.7365\n",
      "Epoch 30/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 19.1465\n",
      "Epoch 30: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.8750 - val_loss: 15.6836\n",
      "Epoch 31/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 19.2027\n",
      "Epoch 31: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.8340 - val_loss: 14.7316\n",
      "Epoch 32/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 17.9672\n",
      "Epoch 32: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.5694 - val_loss: 13.7756\n",
      "Epoch 33/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 17.8260\n",
      "Epoch 33: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.6528 - val_loss: 13.5002\n",
      "Epoch 34/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 19.4769\n",
      "Epoch 34: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.9534 - val_loss: 16.6531\n",
      "Epoch 35/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 16.7908\n",
      "Epoch 35: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.5630 - val_loss: 13.9253\n",
      "Epoch 36/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 17.0569\n",
      "Epoch 36: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.0569 - val_loss: 12.8789\n",
      "Epoch 37/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 17.9058\n",
      "Epoch 37: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.1225 - val_loss: 15.2964\n",
      "Epoch 38/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 18.0089\n",
      "Epoch 38: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.0971 - val_loss: 17.5006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 17.6324\n",
      "Epoch 39: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.3598 - val_loss: 13.3063\n",
      "Epoch 40/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 19.0029\n",
      "Epoch 40: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.0545 - val_loss: 13.5481\n",
      "Epoch 41/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 15.6475\n",
      "Epoch 41: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.3974 - val_loss: 15.3983\n",
      "Epoch 42/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 17.1647\n",
      "Epoch 42: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.7308 - val_loss: 15.0444\n",
      "Epoch 43/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 16.3869\n",
      "Epoch 43: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.6613 - val_loss: 13.1603\n",
      "Epoch 44/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 16.3953\n",
      "Epoch 44: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.8356 - val_loss: 16.2936\n",
      "Epoch 45/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 17.1644\n",
      "Epoch 45: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.7039 - val_loss: 13.4419\n",
      "Epoch 46/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 16.0306\n",
      "Epoch 46: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.7030 - val_loss: 13.0220\n",
      "Epoch 47/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 15.9200\n",
      "Epoch 47: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.7145 - val_loss: 13.8692\n",
      "Epoch 48/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 14.5758\n",
      "Epoch 48: val_loss did not improve from 12.73083\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.9447 - val_loss: 14.7403\n",
      "Epoch 49/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 15.1184\n",
      "Epoch 49: val_loss improved from 12.73083 to 12.29665, saving model to ./model_save\\2_fold_049-12.2967.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.2268 - val_loss: 12.2967\n",
      "Epoch 50/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 14.7973\n",
      "Epoch 50: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.6049 - val_loss: 13.4855\n",
      "Epoch 51/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 15.0070\n",
      "Epoch 51: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.0618 - val_loss: 12.5862\n",
      "Epoch 52/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 14.4432\n",
      "Epoch 52: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.0421 - val_loss: 13.1182\n",
      "Epoch 53/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 14.7678\n",
      "Epoch 53: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.9069 - val_loss: 14.2608\n",
      "Epoch 54/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 13.3775\n",
      "Epoch 54: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.3983 - val_loss: 13.9162\n",
      "Epoch 55/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 14.4426\n",
      "Epoch 55: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.4059 - val_loss: 13.2024\n",
      "Epoch 56/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 13.7726\n",
      "Epoch 56: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.5888 - val_loss: 13.7610\n",
      "Epoch 57/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 14.2560\n",
      "Epoch 57: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.3288 - val_loss: 16.2495\n",
      "Epoch 58/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 13.5375\n",
      "Epoch 58: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.7227 - val_loss: 14.4245\n",
      "Epoch 59/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 13.7961\n",
      "Epoch 59: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.5071 - val_loss: 13.7775\n",
      "Epoch 60/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 12.9680\n",
      "Epoch 60: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.2163 - val_loss: 16.7156\n",
      "Epoch 61/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 13.4222\n",
      "Epoch 61: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.0724 - val_loss: 14.4736\n",
      "Epoch 62/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 12.6025\n",
      "Epoch 62: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.5023 - val_loss: 13.4967\n",
      "Epoch 63/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 13.1888\n",
      "Epoch 63: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.1298 - val_loss: 14.3006\n",
      "Epoch 64/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 13.8229\n",
      "Epoch 64: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.6786 - val_loss: 14.3942\n",
      "Epoch 65/700\n",
      "61/84 [====================>.........] - ETA: 0s - loss: 13.9048\n",
      "Epoch 65: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.1873 - val_loss: 14.2388\n",
      "Epoch 66/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 13.2146\n",
      "Epoch 66: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.5004 - val_loss: 15.1955\n",
      "Epoch 67/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 11.8680\n",
      "Epoch 67: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.2402 - val_loss: 15.3412\n",
      "Epoch 68/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 13.2164\n",
      "Epoch 68: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.8965 - val_loss: 14.3717\n",
      "Epoch 69/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 12.5533\n",
      "Epoch 69: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.4960 - val_loss: 15.0253\n",
      "Epoch 70/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 12.0477\n",
      "Epoch 70: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.9842 - val_loss: 15.1314\n",
      "Epoch 71/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 11.5671\n",
      "Epoch 71: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.5710 - val_loss: 14.3037\n",
      "Epoch 72/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 11.9287\n",
      "Epoch 72: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.8841 - val_loss: 16.0140\n",
      "Epoch 73/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 12.2680\n",
      "Epoch 73: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.5706 - val_loss: 15.3764\n",
      "Epoch 74/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 11.7890\n",
      "Epoch 74: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.7541 - val_loss: 15.5429\n",
      "Epoch 75/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 11.8022\n",
      "Epoch 75: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 11.6451 - val_loss: 13.6016\n",
      "Epoch 76/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 11.0494\n",
      "Epoch 76: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.1159 - val_loss: 15.6698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 11.1994\n",
      "Epoch 77: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.5154 - val_loss: 14.5918\n",
      "Epoch 78/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 10.8732\n",
      "Epoch 78: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.8009 - val_loss: 18.0784\n",
      "Epoch 79/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 12.0338\n",
      "Epoch 79: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.1049 - val_loss: 15.8510\n",
      "Epoch 80/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 11.9427\n",
      "Epoch 80: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.6556 - val_loss: 15.0334\n",
      "Epoch 81/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 10.7288\n",
      "Epoch 81: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.8101 - val_loss: 14.3747\n",
      "Epoch 82/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 11.0989\n",
      "Epoch 82: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.1969 - val_loss: 16.3632\n",
      "Epoch 83/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 11.4759\n",
      "Epoch 83: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.3321 - val_loss: 15.2625\n",
      "Epoch 84/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 10.3050\n",
      "Epoch 84: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.2974 - val_loss: 15.1529\n",
      "Epoch 85/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 10.8021\n",
      "Epoch 85: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.7566 - val_loss: 17.0711\n",
      "Epoch 86/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 10.5795\n",
      "Epoch 86: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.7030 - val_loss: 17.4158\n",
      "Epoch 87/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 9.8174\n",
      "Epoch 87: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.7506 - val_loss: 16.2283\n",
      "Epoch 88/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 9.1512\n",
      "Epoch 88: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.4775 - val_loss: 14.8545\n",
      "Epoch 89/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 11.2540\n",
      "Epoch 89: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.9124 - val_loss: 15.3837\n",
      "Epoch 90/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 10.4069\n",
      "Epoch 90: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.5123 - val_loss: 15.8337\n",
      "Epoch 91/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 9.9885 \n",
      "Epoch 91: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.8919 - val_loss: 18.3406\n",
      "Epoch 92/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 10.4826\n",
      "Epoch 92: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.3362 - val_loss: 16.8812\n",
      "Epoch 93/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 10.1192\n",
      "Epoch 93: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.0760 - val_loss: 16.0478\n",
      "Epoch 94/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 9.8892\n",
      "Epoch 94: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.1345 - val_loss: 15.1491\n",
      "Epoch 95/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 10.4216\n",
      "Epoch 95: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.2572 - val_loss: 16.0530\n",
      "Epoch 96/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 9.3876\n",
      "Epoch 96: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.5348 - val_loss: 16.0107\n",
      "Epoch 97/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 9.1646\n",
      "Epoch 97: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.6098 - val_loss: 16.0620\n",
      "Epoch 98/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 9.0412\n",
      "Epoch 98: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1439 - val_loss: 14.6911\n",
      "Epoch 99/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 8.9947\n",
      "Epoch 99: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2574 - val_loss: 17.0941\n",
      "Epoch 100/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 9.0708\n",
      "Epoch 100: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1625 - val_loss: 15.5240\n",
      "Epoch 101/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 9.1985\n",
      "Epoch 101: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.4255 - val_loss: 17.1510\n",
      "Epoch 102/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 9.3636\n",
      "Epoch 102: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.3684 - val_loss: 15.5641\n",
      "Epoch 103/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 10.0099\n",
      "Epoch 103: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.8434 - val_loss: 15.5542\n",
      "Epoch 104/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 9.7131\n",
      "Epoch 104: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.7131 - val_loss: 15.2111\n",
      "Epoch 105/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 9.2043\n",
      "Epoch 105: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.3470 - val_loss: 15.0246\n",
      "Epoch 106/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 9.4977\n",
      "Epoch 106: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.4577 - val_loss: 17.0314\n",
      "Epoch 107/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 9.4663 \n",
      "Epoch 107: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.5396 - val_loss: 15.9154\n",
      "Epoch 108/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 9.3638\n",
      "Epoch 108: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.5644 - val_loss: 16.2087\n",
      "Epoch 109/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.9475\n",
      "Epoch 109: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1390 - val_loss: 16.6172\n",
      "Epoch 110/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 8.6613\n",
      "Epoch 110: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.8713 - val_loss: 17.1475\n",
      "Epoch 111/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 9.6584\n",
      "Epoch 111: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.6318 - val_loss: 16.3392\n",
      "Epoch 112/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 9.7818\n",
      "Epoch 112: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.6545 - val_loss: 16.5087\n",
      "Epoch 113/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 9.0075\n",
      "Epoch 113: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.5545 - val_loss: 15.8286\n",
      "Epoch 114/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 9.0844\n",
      "Epoch 114: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0602 - val_loss: 17.0184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 9.4157\n",
      "Epoch 115: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.3774 - val_loss: 15.9100\n",
      "Epoch 116/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 9.2163\n",
      "Epoch 116: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.3794 - val_loss: 16.9782\n",
      "Epoch 117/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 8.3527\n",
      "Epoch 117: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5545 - val_loss: 16.5622\n",
      "Epoch 118/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 8.9022\n",
      "Epoch 118: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.9859 - val_loss: 16.4415\n",
      "Epoch 119/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 10.0603\n",
      "Epoch 119: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.9250 - val_loss: 16.1799\n",
      "Epoch 120/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 9.4177\n",
      "Epoch 120: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2821 - val_loss: 16.1325\n",
      "Epoch 121/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 8.9619\n",
      "Epoch 121: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.8223 - val_loss: 17.2067\n",
      "Epoch 122/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 9.1316\n",
      "Epoch 122: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2144 - val_loss: 18.4764\n",
      "Epoch 123/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 9.7116 \n",
      "Epoch 123: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.7216 - val_loss: 15.9617\n",
      "Epoch 124/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.5915\n",
      "Epoch 124: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.8140 - val_loss: 16.6048\n",
      "Epoch 125/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 8.6104\n",
      "Epoch 125: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3667 - val_loss: 14.9991\n",
      "Epoch 126/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.3708\n",
      "Epoch 126: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7825 - val_loss: 18.3353\n",
      "Epoch 127/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 8.6896\n",
      "Epoch 127: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6541 - val_loss: 15.2253\n",
      "Epoch 128/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 9.7168\n",
      "Epoch 128: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.7303 - val_loss: 15.5353\n",
      "Epoch 129/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 9.5714\n",
      "Epoch 129: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.4514 - val_loss: 15.0143\n",
      "Epoch 130/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 9.6658\n",
      "Epoch 130: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.5974 - val_loss: 16.0259\n",
      "Epoch 131/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.6346\n",
      "Epoch 131: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5455 - val_loss: 16.7311\n",
      "Epoch 132/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 8.1501\n",
      "Epoch 132: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4559 - val_loss: 16.2186\n",
      "Epoch 133/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.7867\n",
      "Epoch 133: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5265 - val_loss: 15.4709\n",
      "Epoch 134/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 9.3910\n",
      "Epoch 134: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 9.2566 - val_loss: 15.7989\n",
      "Epoch 135/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 8.0330\n",
      "Epoch 135: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1839 - val_loss: 16.3020\n",
      "Epoch 136/700\n",
      "61/84 [====================>.........] - ETA: 0s - loss: 8.2704\n",
      "Epoch 136: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2461 - val_loss: 17.1300\n",
      "Epoch 137/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.5303\n",
      "Epoch 137: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 7.5862 - val_loss: 16.5489\n",
      "Epoch 138/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 8.3685\n",
      "Epoch 138: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4328 - val_loss: 15.8066\n",
      "Epoch 139/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.9105\n",
      "Epoch 139: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9105 - val_loss: 16.8957\n",
      "Epoch 140/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 8.3228\n",
      "Epoch 140: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4128 - val_loss: 16.8688\n",
      "Epoch 141/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 8.1761\n",
      "Epoch 141: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2184 - val_loss: 15.8226\n",
      "Epoch 142/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.2561\n",
      "Epoch 142: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2359 - val_loss: 16.0225\n",
      "Epoch 143/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 8.0818\n",
      "Epoch 143: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1526 - val_loss: 14.6863\n",
      "Epoch 144/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 8.6156\n",
      "Epoch 144: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3988 - val_loss: 15.9503\n",
      "Epoch 145/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 8.6342\n",
      "Epoch 145: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5211 - val_loss: 15.0281\n",
      "Epoch 146/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 9.3970\n",
      "Epoch 146: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.7820 - val_loss: 17.1641\n",
      "Epoch 147/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 9.3607\n",
      "Epoch 147: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.3565 - val_loss: 16.2495\n",
      "Epoch 148/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 8.9043\n",
      "Epoch 148: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9215 - val_loss: 16.8045\n",
      "Epoch 149/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 8.4667\n",
      "Epoch 149: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2628 - val_loss: 15.8313\n",
      "Epoch 150/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 7.5715\n",
      "Epoch 150: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6639 - val_loss: 16.4316\n",
      "Epoch 151/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.8664\n",
      "Epoch 151: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 7.8993 - val_loss: 15.6168\n",
      "Epoch 152/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 9.1036\n",
      "Epoch 152: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9494 - val_loss: 15.4406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 8.1571\n",
      "Epoch 153: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2502 - val_loss: 15.9986\n",
      "Epoch 154/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 8.3601\n",
      "Epoch 154: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3303 - val_loss: 16.0090\n",
      "Epoch 155/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.7880\n",
      "Epoch 155: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8514 - val_loss: 16.8598\n",
      "Epoch 156/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.2207\n",
      "Epoch 156: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2962 - val_loss: 15.4216\n",
      "Epoch 157/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.5430\n",
      "Epoch 157: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3628 - val_loss: 16.9218\n",
      "Epoch 158/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.8397\n",
      "Epoch 158: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1368 - val_loss: 19.8041\n",
      "Epoch 159/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 8.9819\n",
      "Epoch 159: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9819 - val_loss: 16.1088\n",
      "Epoch 160/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 8.6400\n",
      "Epoch 160: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6889 - val_loss: 17.0085\n",
      "Epoch 161/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 8.3460\n",
      "Epoch 161: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.3239 - val_loss: 16.5666\n",
      "Epoch 162/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 8.0473\n",
      "Epoch 162: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0689 - val_loss: 17.0070\n",
      "Epoch 163/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 8.5837\n",
      "Epoch 163: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5703 - val_loss: 16.6656\n",
      "Epoch 164/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.3247\n",
      "Epoch 164: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4835 - val_loss: 16.4231\n",
      "Epoch 165/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 7.8180\n",
      "Epoch 165: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1005 - val_loss: 16.0895\n",
      "Epoch 166/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 8.0084\n",
      "Epoch 166: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0112 - val_loss: 18.9735\n",
      "Epoch 167/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 8.4585\n",
      "Epoch 167: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3973 - val_loss: 17.4795\n",
      "Epoch 168/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.8328\n",
      "Epoch 168: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9738 - val_loss: 17.5960\n",
      "Epoch 169/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 7.5295\n",
      "Epoch 169: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7683 - val_loss: 17.4508\n",
      "Epoch 170/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 8.1173\n",
      "Epoch 170: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9612 - val_loss: 16.2629\n",
      "Epoch 171/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 8.0147\n",
      "Epoch 171: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0431 - val_loss: 14.8296\n",
      "Epoch 172/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 8.2519\n",
      "Epoch 172: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2830 - val_loss: 15.2621\n",
      "Epoch 173/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 8.3317\n",
      "Epoch 173: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3008 - val_loss: 16.2446\n",
      "Epoch 174/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.5601\n",
      "Epoch 174: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5384 - val_loss: 16.1279\n",
      "Epoch 175/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 8.1029\n",
      "Epoch 175: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0605 - val_loss: 16.4335\n",
      "Epoch 176/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 7.7447\n",
      "Epoch 176: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8595 - val_loss: 15.8820\n",
      "Epoch 177/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 7.8709\n",
      "Epoch 177: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9101 - val_loss: 16.0191\n",
      "Epoch 178/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 7.8773\n",
      "Epoch 178: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.6442 - val_loss: 18.0352\n",
      "Epoch 179/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 7.6797\n",
      "Epoch 179: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.8200 - val_loss: 16.3609\n",
      "Epoch 180/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 6.9041\n",
      "Epoch 180: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.5446 - val_loss: 16.7108\n",
      "Epoch 181/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 8.3374\n",
      "Epoch 181: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3094 - val_loss: 18.3712\n",
      "Epoch 182/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.4522\n",
      "Epoch 182: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4746 - val_loss: 15.8304\n",
      "Epoch 183/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.9730\n",
      "Epoch 183: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9211 - val_loss: 17.1723\n",
      "Epoch 184/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 7.5981\n",
      "Epoch 184: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4771 - val_loss: 15.1151\n",
      "Epoch 185/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 8.4732\n",
      "Epoch 185: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6802 - val_loss: 17.2483\n",
      "Epoch 186/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 8.1975\n",
      "Epoch 186: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0851 - val_loss: 18.7656\n",
      "Epoch 187/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.4909\n",
      "Epoch 187: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8322 - val_loss: 16.8011\n",
      "Epoch 188/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.5655\n",
      "Epoch 188: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5327 - val_loss: 17.8132\n",
      "Epoch 189/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 8.6978\n",
      "Epoch 189: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5517 - val_loss: 16.1834\n",
      "Epoch 190/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.3793\n",
      "Epoch 190: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7045 - val_loss: 17.4072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.9355\n",
      "Epoch 191: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8834 - val_loss: 17.4372\n",
      "Epoch 192/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.5652\n",
      "Epoch 192: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7056 - val_loss: 16.7766\n",
      "Epoch 193/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.4346\n",
      "Epoch 193: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4254 - val_loss: 17.4627\n",
      "Epoch 194/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.0456\n",
      "Epoch 194: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9606 - val_loss: 17.1024\n",
      "Epoch 195/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 8.0136\n",
      "Epoch 195: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7550 - val_loss: 17.8006\n",
      "Epoch 196/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.7230\n",
      "Epoch 196: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.8279 - val_loss: 16.3786\n",
      "Epoch 197/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.7851\n",
      "Epoch 197: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7851 - val_loss: 16.6961\n",
      "Epoch 198/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.7723\n",
      "Epoch 198: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7723 - val_loss: 18.5405\n",
      "Epoch 199/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 8.4096\n",
      "Epoch 199: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3389 - val_loss: 17.9245\n",
      "Epoch 200/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 8.5843\n",
      "Epoch 200: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5212 - val_loss: 16.3364\n",
      "Epoch 201/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 8.0780\n",
      "Epoch 201: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7240 - val_loss: 16.4105\n",
      "Epoch 202/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.4266\n",
      "Epoch 202: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3826 - val_loss: 18.0546\n",
      "Epoch 203/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.7774\n",
      "Epoch 203: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8648 - val_loss: 15.2836\n",
      "Epoch 204/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.4303\n",
      "Epoch 204: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4475 - val_loss: 15.7911\n",
      "Epoch 205/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.2393\n",
      "Epoch 205: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2868 - val_loss: 17.1241\n",
      "Epoch 206/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 7.9844\n",
      "Epoch 206: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9016 - val_loss: 17.1804\n",
      "Epoch 207/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.1942\n",
      "Epoch 207: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4464 - val_loss: 16.6457\n",
      "Epoch 208/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 7.4862\n",
      "Epoch 208: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7127 - val_loss: 15.4942\n",
      "Epoch 209/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.3614\n",
      "Epoch 209: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3232 - val_loss: 16.6626\n",
      "Epoch 210/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.3632\n",
      "Epoch 210: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2702 - val_loss: 16.2111\n",
      "Epoch 211/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.3289\n",
      "Epoch 211: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2764 - val_loss: 16.6227\n",
      "Epoch 212/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.2372\n",
      "Epoch 212: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3054 - val_loss: 17.5324\n",
      "Epoch 213/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.9506\n",
      "Epoch 213: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9550 - val_loss: 17.5871\n",
      "Epoch 214/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 7.3610\n",
      "Epoch 214: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1387 - val_loss: 18.7206\n",
      "Epoch 215/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.9071\n",
      "Epoch 215: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1020 - val_loss: 16.9098\n",
      "Epoch 216/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 9.6172\n",
      "Epoch 216: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.4123 - val_loss: 16.2329\n",
      "Epoch 217/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 7.2594\n",
      "Epoch 217: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.6264 - val_loss: 16.4615\n",
      "Epoch 218/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 8.0907\n",
      "Epoch 218: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.8925 - val_loss: 17.0305\n",
      "Epoch 219/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 7.2566\n",
      "Epoch 219: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3128 - val_loss: 17.0369\n",
      "Epoch 220/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.3462\n",
      "Epoch 220: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2393 - val_loss: 15.8732\n",
      "Epoch 221/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.3442\n",
      "Epoch 221: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4837 - val_loss: 16.6319\n",
      "Epoch 222/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.4211\n",
      "Epoch 222: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4619 - val_loss: 16.5721\n",
      "Epoch 223/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 7.5735\n",
      "Epoch 223: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3680 - val_loss: 15.6807\n",
      "Epoch 224/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.9107\n",
      "Epoch 224: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9107 - val_loss: 15.9991\n",
      "Epoch 225/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 7.6951\n",
      "Epoch 225: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.5532 - val_loss: 17.1879\n",
      "Epoch 226/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.5525\n",
      "Epoch 226: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4987 - val_loss: 18.3917\n",
      "Epoch 227/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 8.1012\n",
      "Epoch 227: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0457 - val_loss: 18.8772\n",
      "Epoch 228/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.2305\n",
      "Epoch 228: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2825 - val_loss: 17.7410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.9716\n",
      "Epoch 229: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9650 - val_loss: 18.3377\n",
      "Epoch 230/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 7.4323\n",
      "Epoch 230: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4780 - val_loss: 17.1867\n",
      "Epoch 231/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 7.9330\n",
      "Epoch 231: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8894 - val_loss: 18.5087\n",
      "Epoch 232/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 7.4674\n",
      "Epoch 232: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4835 - val_loss: 17.9925\n",
      "Epoch 233/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.5942\n",
      "Epoch 233: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6422 - val_loss: 18.0434\n",
      "Epoch 234/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.8311\n",
      "Epoch 234: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8040 - val_loss: 18.0605\n",
      "Epoch 235/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.9171\n",
      "Epoch 235: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9396 - val_loss: 18.1818\n",
      "Epoch 236/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 7.4098\n",
      "Epoch 236: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3375 - val_loss: 17.5535\n",
      "Epoch 237/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.4088\n",
      "Epoch 237: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 7.4327 - val_loss: 18.5867\n",
      "Epoch 238/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.0396\n",
      "Epoch 238: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1616 - val_loss: 16.5178\n",
      "Epoch 239/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 7.6661\n",
      "Epoch 239: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6675 - val_loss: 16.6908\n",
      "Epoch 240/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 7.4279\n",
      "Epoch 240: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4626 - val_loss: 16.4797\n",
      "Epoch 241/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 7.3603\n",
      "Epoch 241: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.1165 - val_loss: 15.6546\n",
      "Epoch 242/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.7807\n",
      "Epoch 242: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0324 - val_loss: 17.2863\n",
      "Epoch 243/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.9828\n",
      "Epoch 243: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9828 - val_loss: 16.2516\n",
      "Epoch 244/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 6.6620\n",
      "Epoch 244: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7833 - val_loss: 17.5662\n",
      "Epoch 245/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.3042\n",
      "Epoch 245: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3042 - val_loss: 16.8792\n",
      "Epoch 246/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.9770\n",
      "Epoch 246: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0873 - val_loss: 17.4535\n",
      "Epoch 247/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.9646\n",
      "Epoch 247: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1715 - val_loss: 16.5235\n",
      "Epoch 248/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.5233\n",
      "Epoch 248: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3561 - val_loss: 19.2356\n",
      "Epoch 249/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 7.1010\n",
      "Epoch 249: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1326 - val_loss: 17.7535\n",
      "Epoch 250/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 7.1782\n",
      "Epoch 250: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2446 - val_loss: 18.4737\n",
      "Epoch 251/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.8380\n",
      "Epoch 251: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6402 - val_loss: 19.3027\n",
      "Epoch 252/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.0903\n",
      "Epoch 252: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9741 - val_loss: 18.9016\n",
      "Epoch 253/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.0301\n",
      "Epoch 253: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1176 - val_loss: 18.2627\n",
      "Epoch 254/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.5944\n",
      "Epoch 254: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4944 - val_loss: 17.2613\n",
      "Epoch 255/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.4481\n",
      "Epoch 255: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3652 - val_loss: 17.6436\n",
      "Epoch 256/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 7.0208\n",
      "Epoch 256: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9252 - val_loss: 18.0562\n",
      "Epoch 257/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.5970\n",
      "Epoch 257: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6407 - val_loss: 18.1997\n",
      "Epoch 258/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.7777\n",
      "Epoch 258: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7906 - val_loss: 17.7674\n",
      "Epoch 259/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 7.3740\n",
      "Epoch 259: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2225 - val_loss: 18.2223\n",
      "Epoch 260/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 7.2786\n",
      "Epoch 260: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2674 - val_loss: 19.1621\n",
      "Epoch 261/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 7.1615\n",
      "Epoch 261: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1415 - val_loss: 18.7410\n",
      "Epoch 262/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 7.0750\n",
      "Epoch 262: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9409 - val_loss: 19.7188\n",
      "Epoch 263/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.6335\n",
      "Epoch 263: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7612 - val_loss: 17.8935\n",
      "Epoch 264/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.4049\n",
      "Epoch 264: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3251 - val_loss: 17.6094\n",
      "Epoch 265/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.4841\n",
      "Epoch 265: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4097 - val_loss: 19.4299\n",
      "Epoch 266/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.7893\n",
      "Epoch 266: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8377 - val_loss: 18.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267/700\n",
      "55/84 [==================>...........] - ETA: 0s - loss: 6.3504\n",
      "Epoch 267: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.8321 - val_loss: 18.0109\n",
      "Epoch 268/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.3376\n",
      "Epoch 268: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0694 - val_loss: 17.8351\n",
      "Epoch 269/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.6518\n",
      "Epoch 269: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6889 - val_loss: 17.7083\n",
      "Epoch 270/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.8662\n",
      "Epoch 270: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7647 - val_loss: 17.6729\n",
      "Epoch 271/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.4799\n",
      "Epoch 271: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4931 - val_loss: 16.9295\n",
      "Epoch 272/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.8372\n",
      "Epoch 272: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9183 - val_loss: 17.2704\n",
      "Epoch 273/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.5358\n",
      "Epoch 273: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4050 - val_loss: 17.7315\n",
      "Epoch 274/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.6030\n",
      "Epoch 274: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8790 - val_loss: 18.5548\n",
      "Epoch 275/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.1014\n",
      "Epoch 275: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9375 - val_loss: 17.1706\n",
      "Epoch 276/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.4808\n",
      "Epoch 276: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4469 - val_loss: 17.9902\n",
      "Epoch 277/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.9302\n",
      "Epoch 277: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3274 - val_loss: 17.1627\n",
      "Epoch 278/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 7.6431\n",
      "Epoch 278: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8677 - val_loss: 18.5454\n",
      "Epoch 279/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.8375\n",
      "Epoch 279: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8467 - val_loss: 17.6870\n",
      "Epoch 280/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 6.8112\n",
      "Epoch 280: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.9818 - val_loss: 18.8798\n",
      "Epoch 281/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.1762\n",
      "Epoch 281: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9783 - val_loss: 17.6914\n",
      "Epoch 282/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.5684\n",
      "Epoch 282: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5684 - val_loss: 18.3826\n",
      "Epoch 283/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.7136\n",
      "Epoch 283: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7236 - val_loss: 19.8402\n",
      "Epoch 284/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.7899\n",
      "Epoch 284: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7840 - val_loss: 18.8215\n",
      "Epoch 285/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.5967\n",
      "Epoch 285: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5881 - val_loss: 16.8498\n",
      "Epoch 286/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.5585\n",
      "Epoch 286: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4805 - val_loss: 19.0737\n",
      "Epoch 287/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.5712\n",
      "Epoch 287: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4994 - val_loss: 16.1276\n",
      "Epoch 288/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.4286\n",
      "Epoch 288: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6081 - val_loss: 19.1017\n",
      "Epoch 289/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.3272\n",
      "Epoch 289: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4009 - val_loss: 18.0604\n",
      "Epoch 290/700\n",
      "61/84 [====================>.........] - ETA: 0s - loss: 7.0076\n",
      "Epoch 290: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5739 - val_loss: 18.8145\n",
      "Epoch 291/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.7426\n",
      "Epoch 291: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8330 - val_loss: 17.3698\n",
      "Epoch 292/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 7.8614\n",
      "Epoch 292: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5399 - val_loss: 20.0729\n",
      "Epoch 293/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.1493\n",
      "Epoch 293: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0218 - val_loss: 18.7040\n",
      "Epoch 294/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.7466\n",
      "Epoch 294: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7628 - val_loss: 19.7680\n",
      "Epoch 295/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.5557\n",
      "Epoch 295: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4313 - val_loss: 19.3959\n",
      "Epoch 296/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.7300\n",
      "Epoch 296: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7827 - val_loss: 19.4672\n",
      "Epoch 297/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.1604\n",
      "Epoch 297: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1685 - val_loss: 18.8142\n",
      "Epoch 298/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.4678\n",
      "Epoch 298: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5075 - val_loss: 20.2078\n",
      "Epoch 299/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.3564\n",
      "Epoch 299: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.3494 - val_loss: 19.1554\n",
      "Epoch 300/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.9146\n",
      "Epoch 300: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8956 - val_loss: 19.4328\n",
      "Epoch 301/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.4868\n",
      "Epoch 301: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4881 - val_loss: 18.5979\n",
      "Epoch 302/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.8447\n",
      "Epoch 302: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8579 - val_loss: 18.1994\n",
      "Epoch 303/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.6595\n",
      "Epoch 303: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7177 - val_loss: 19.1398\n",
      "Epoch 304/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.7869\n",
      "Epoch 304: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7680 - val_loss: 16.5050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.2482\n",
      "Epoch 305: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1898 - val_loss: 18.3298\n",
      "Epoch 306/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.3775\n",
      "Epoch 306: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4542 - val_loss: 20.1401\n",
      "Epoch 307/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.4153\n",
      "Epoch 307: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4132 - val_loss: 18.5435\n",
      "Epoch 308/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 7.3165\n",
      "Epoch 308: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2527 - val_loss: 18.5562\n",
      "Epoch 309/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.8070\n",
      "Epoch 309: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7468 - val_loss: 19.2268\n",
      "Epoch 310/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.3317\n",
      "Epoch 310: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1793 - val_loss: 19.1200\n",
      "Epoch 311/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 6.7325\n",
      "Epoch 311: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5203 - val_loss: 18.7991\n",
      "Epoch 312/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.5420\n",
      "Epoch 312: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5535 - val_loss: 20.1427\n",
      "Epoch 313/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.8781\n",
      "Epoch 313: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8939 - val_loss: 19.1251\n",
      "Epoch 314/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.6637\n",
      "Epoch 314: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6863 - val_loss: 18.7569\n",
      "Epoch 315/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.8632\n",
      "Epoch 315: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7284 - val_loss: 19.2576\n",
      "Epoch 316/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.2288\n",
      "Epoch 316: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1350 - val_loss: 19.6162\n",
      "Epoch 317/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.1778\n",
      "Epoch 317: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1778 - val_loss: 18.4407\n",
      "Epoch 318/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.3017\n",
      "Epoch 318: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3167 - val_loss: 18.5591\n",
      "Epoch 319/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.1445\n",
      "Epoch 319: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3257 - val_loss: 18.9676\n",
      "Epoch 320/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.1235\n",
      "Epoch 320: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1976 - val_loss: 18.9549\n",
      "Epoch 321/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.7970\n",
      "Epoch 321: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8206 - val_loss: 20.5535\n",
      "Epoch 322/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.3005\n",
      "Epoch 322: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 7.1787 - val_loss: 19.4605\n",
      "Epoch 323/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.9643\n",
      "Epoch 323: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0652 - val_loss: 18.7634\n",
      "Epoch 324/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.3096\n",
      "Epoch 324: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2829 - val_loss: 18.3178\n",
      "Epoch 325/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.4181\n",
      "Epoch 325: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3550 - val_loss: 17.7748\n",
      "Epoch 326/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 7.0057\n",
      "Epoch 326: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9883 - val_loss: 19.3438\n",
      "Epoch 327/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.5169\n",
      "Epoch 327: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5169 - val_loss: 18.8384\n",
      "Epoch 328/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.1242\n",
      "Epoch 328: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0409 - val_loss: 18.3459\n",
      "Epoch 329/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.2624\n",
      "Epoch 329: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5752 - val_loss: 17.6850\n",
      "Epoch 330/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.1705\n",
      "Epoch 330: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1142 - val_loss: 19.0792\n",
      "Epoch 331/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 6.7014\n",
      "Epoch 331: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8651 - val_loss: 16.9776\n",
      "Epoch 332/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.2115\n",
      "Epoch 332: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1407 - val_loss: 18.0473\n",
      "Epoch 333/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.5751\n",
      "Epoch 333: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6025 - val_loss: 20.7615\n",
      "Epoch 334/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.1800\n",
      "Epoch 334: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3667 - val_loss: 17.0984\n",
      "Epoch 335/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.2664\n",
      "Epoch 335: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3003 - val_loss: 21.0109\n",
      "Epoch 336/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.4100\n",
      "Epoch 336: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4636 - val_loss: 19.6625\n",
      "Epoch 337/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.2638\n",
      "Epoch 337: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2638 - val_loss: 18.7178\n",
      "Epoch 338/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.5850\n",
      "Epoch 338: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5414 - val_loss: 19.9979\n",
      "Epoch 339/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.7705\n",
      "Epoch 339: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8286 - val_loss: 19.3990\n",
      "Epoch 340/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.8102\n",
      "Epoch 340: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8102 - val_loss: 17.5424\n",
      "Epoch 341/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.0817\n",
      "Epoch 341: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0054 - val_loss: 19.1167\n",
      "Epoch 342/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.2549\n",
      "Epoch 342: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2443 - val_loss: 19.9041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.0849\n",
      "Epoch 343: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0891 - val_loss: 16.8806\n",
      "Epoch 344/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.5332\n",
      "Epoch 344: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6136 - val_loss: 22.5987\n",
      "Epoch 345/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.4318\n",
      "Epoch 345: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4357 - val_loss: 19.7112\n",
      "Epoch 346/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.3452\n",
      "Epoch 346: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2595 - val_loss: 19.5138\n",
      "Epoch 347/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.1061\n",
      "Epoch 347: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8537 - val_loss: 18.6045\n",
      "Epoch 348/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.0992\n",
      "Epoch 348: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2224 - val_loss: 18.2863\n",
      "Epoch 349/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 5.5148\n",
      "Epoch 349: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7978 - val_loss: 20.9188\n",
      "Epoch 350/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.9722\n",
      "Epoch 350: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0685 - val_loss: 20.8595\n",
      "Epoch 351/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.5244\n",
      "Epoch 351: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6985 - val_loss: 20.2708\n",
      "Epoch 352/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.1939\n",
      "Epoch 352: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0827 - val_loss: 18.6487\n",
      "Epoch 353/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.3526\n",
      "Epoch 353: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4207 - val_loss: 19.7116\n",
      "Epoch 354/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.0896\n",
      "Epoch 354: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0558 - val_loss: 17.7732\n",
      "Epoch 355/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.9744\n",
      "Epoch 355: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9371 - val_loss: 18.1475\n",
      "Epoch 356/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.4974\n",
      "Epoch 356: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5890 - val_loss: 19.6338\n",
      "Epoch 357/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.0488\n",
      "Epoch 357: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0296 - val_loss: 18.8966\n",
      "Epoch 358/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.1503\n",
      "Epoch 358: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0983 - val_loss: 18.0630\n",
      "Epoch 359/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.0576\n",
      "Epoch 359: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0631 - val_loss: 19.9164\n",
      "Epoch 360/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.4275\n",
      "Epoch 360: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4526 - val_loss: 23.8809\n",
      "Epoch 361/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 7.1808\n",
      "Epoch 361: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9933 - val_loss: 19.5154\n",
      "Epoch 362/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.2271\n",
      "Epoch 362: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1819 - val_loss: 18.6436\n",
      "Epoch 363/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.5169\n",
      "Epoch 363: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6737 - val_loss: 18.5035\n",
      "Epoch 364/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.2505\n",
      "Epoch 364: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1070 - val_loss: 17.3535\n",
      "Epoch 365/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.2023\n",
      "Epoch 365: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2948 - val_loss: 17.1846\n",
      "Epoch 366/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.0170\n",
      "Epoch 366: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0686 - val_loss: 18.1909\n",
      "Epoch 367/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.8307\n",
      "Epoch 367: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8166 - val_loss: 18.2074\n",
      "Epoch 368/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.8770\n",
      "Epoch 368: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8953 - val_loss: 18.3129\n",
      "Epoch 369/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.0048\n",
      "Epoch 369: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0528 - val_loss: 18.4730\n",
      "Epoch 370/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.7587\n",
      "Epoch 370: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8927 - val_loss: 19.4538\n",
      "Epoch 371/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.0202\n",
      "Epoch 371: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0809 - val_loss: 19.0119\n",
      "Epoch 372/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.2612\n",
      "Epoch 372: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3317 - val_loss: 19.5289\n",
      "Epoch 373/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.2031\n",
      "Epoch 373: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3379 - val_loss: 19.1416\n",
      "Epoch 374/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.5802\n",
      "Epoch 374: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5747 - val_loss: 18.8913\n",
      "Epoch 375/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.8402\n",
      "Epoch 375: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9129 - val_loss: 19.3702\n",
      "Epoch 376/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.8686\n",
      "Epoch 376: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8542 - val_loss: 19.0405\n",
      "Epoch 377/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.9212\n",
      "Epoch 377: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0097 - val_loss: 21.9071\n",
      "Epoch 378/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.9520\n",
      "Epoch 378: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1080 - val_loss: 19.7464\n",
      "Epoch 379/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.1940\n",
      "Epoch 379: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1927 - val_loss: 18.8987\n",
      "Epoch 380/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.8178\n",
      "Epoch 380: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8045 - val_loss: 18.9382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.5104\n",
      "Epoch 381: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4062 - val_loss: 17.6400\n",
      "Epoch 382/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.9250\n",
      "Epoch 382: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8412 - val_loss: 20.8840\n",
      "Epoch 383/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.1329\n",
      "Epoch 383: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1593 - val_loss: 18.8508\n",
      "Epoch 384/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.4658\n",
      "Epoch 384: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6879 - val_loss: 18.1493\n",
      "Epoch 385/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.8208\n",
      "Epoch 385: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7442 - val_loss: 20.7822\n",
      "Epoch 386/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 6.0308\n",
      "Epoch 386: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9988 - val_loss: 20.3835\n",
      "Epoch 387/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.4593\n",
      "Epoch 387: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7237 - val_loss: 18.6984\n",
      "Epoch 388/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.7828\n",
      "Epoch 388: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7976 - val_loss: 18.7881\n",
      "Epoch 389/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.7484\n",
      "Epoch 389: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8259 - val_loss: 17.5881\n",
      "Epoch 390/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.7947\n",
      "Epoch 390: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0254 - val_loss: 18.8082\n",
      "Epoch 391/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.2519\n",
      "Epoch 391: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1893 - val_loss: 17.7639\n",
      "Epoch 392/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.5795\n",
      "Epoch 392: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4938 - val_loss: 18.4777\n",
      "Epoch 393/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.3789\n",
      "Epoch 393: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3044 - val_loss: 18.8205\n",
      "Epoch 394/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.9705\n",
      "Epoch 394: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0153 - val_loss: 20.0086\n",
      "Epoch 395/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.9598\n",
      "Epoch 395: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0339 - val_loss: 18.9809\n",
      "Epoch 396/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.8673\n",
      "Epoch 396: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9489 - val_loss: 19.2387\n",
      "Epoch 397/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.8642\n",
      "Epoch 397: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.8019 - val_loss: 18.7748\n",
      "Epoch 398/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.2174\n",
      "Epoch 398: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1687 - val_loss: 18.1786\n",
      "Epoch 399/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.6940\n",
      "Epoch 399: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5218 - val_loss: 20.0498\n",
      "Epoch 400/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.8618\n",
      "Epoch 400: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9948 - val_loss: 18.8798\n",
      "Epoch 401/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.1815\n",
      "Epoch 401: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0858 - val_loss: 19.0444\n",
      "Epoch 402/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.2720\n",
      "Epoch 402: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5397 - val_loss: 18.6044\n",
      "Epoch 403/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.4059\n",
      "Epoch 403: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4665 - val_loss: 18.5500\n",
      "Epoch 404/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.1515\n",
      "Epoch 404: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1760 - val_loss: 17.8203\n",
      "Epoch 405/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.4047\n",
      "Epoch 405: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3606 - val_loss: 19.7670\n",
      "Epoch 406/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.1167\n",
      "Epoch 406: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0831 - val_loss: 16.8289\n",
      "Epoch 407/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.5276\n",
      "Epoch 407: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5518 - val_loss: 16.1956\n",
      "Epoch 408/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.4870\n",
      "Epoch 408: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6241 - val_loss: 16.0341\n",
      "Epoch 409/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.3882\n",
      "Epoch 409: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4364 - val_loss: 16.7445\n",
      "Epoch 410/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.7226\n",
      "Epoch 410: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7825 - val_loss: 14.9551\n",
      "Epoch 411/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.0973\n",
      "Epoch 411: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0066 - val_loss: 17.4854\n",
      "Epoch 412/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.8185\n",
      "Epoch 412: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7826 - val_loss: 18.4259\n",
      "Epoch 413/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.1037\n",
      "Epoch 413: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0725 - val_loss: 17.8246\n",
      "Epoch 414/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.2984\n",
      "Epoch 414: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.3132 - val_loss: 18.5585\n",
      "Epoch 415/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.2067\n",
      "Epoch 415: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3440 - val_loss: 20.0406\n",
      "Epoch 416/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.3160\n",
      "Epoch 416: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1729 - val_loss: 18.1665\n",
      "Epoch 417/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.7931\n",
      "Epoch 417: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7074 - val_loss: 17.9794\n",
      "Epoch 418/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.6895\n",
      "Epoch 418: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6347 - val_loss: 18.1376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.3635\n",
      "Epoch 419: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2766 - val_loss: 17.5864\n",
      "Epoch 420/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.5979\n",
      "Epoch 420: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5204 - val_loss: 17.2612\n",
      "Epoch 421/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.9861\n",
      "Epoch 421: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8223 - val_loss: 17.5246\n",
      "Epoch 422/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.6289\n",
      "Epoch 422: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6940 - val_loss: 17.2319\n",
      "Epoch 423/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.8602\n",
      "Epoch 423: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7892 - val_loss: 18.5070\n",
      "Epoch 424/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.9172\n",
      "Epoch 424: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7409 - val_loss: 18.0182\n",
      "Epoch 425/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.9044\n",
      "Epoch 425: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8900 - val_loss: 18.5333\n",
      "Epoch 426/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.7421\n",
      "Epoch 426: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8433 - val_loss: 18.5997\n",
      "Epoch 427/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.9381\n",
      "Epoch 427: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1261 - val_loss: 17.9100\n",
      "Epoch 428/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.9084\n",
      "Epoch 428: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8533 - val_loss: 15.3879\n",
      "Epoch 429/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.5964\n",
      "Epoch 429: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5715 - val_loss: 16.6655\n",
      "Epoch 430/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.8068\n",
      "Epoch 430: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8188 - val_loss: 18.8472\n",
      "Epoch 431/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.5521\n",
      "Epoch 431: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5245 - val_loss: 16.8890\n",
      "Epoch 432/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.4855\n",
      "Epoch 432: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6712 - val_loss: 18.5344\n",
      "Epoch 433/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.4605\n",
      "Epoch 433: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4726 - val_loss: 18.7509\n",
      "Epoch 434/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.6186\n",
      "Epoch 434: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5755 - val_loss: 19.5702\n",
      "Epoch 435/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.3564\n",
      "Epoch 435: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3130 - val_loss: 18.6409\n",
      "Epoch 436/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.5943\n",
      "Epoch 436: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4442 - val_loss: 18.3454\n",
      "Epoch 437/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.9041\n",
      "Epoch 437: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9465 - val_loss: 17.5782\n",
      "Epoch 438/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.4907\n",
      "Epoch 438: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.4537 - val_loss: 18.5911\n",
      "Epoch 439/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.2247\n",
      "Epoch 439: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2910 - val_loss: 17.2240\n",
      "Epoch 440/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.0910\n",
      "Epoch 440: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9854 - val_loss: 18.2502\n",
      "Epoch 441/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.1072\n",
      "Epoch 441: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1796 - val_loss: 16.4245\n",
      "Epoch 442/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.6377\n",
      "Epoch 442: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6495 - val_loss: 17.5266\n",
      "Epoch 443/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.7338\n",
      "Epoch 443: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7172 - val_loss: 17.7243\n",
      "Epoch 444/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.4786\n",
      "Epoch 444: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5517 - val_loss: 18.0475\n",
      "Epoch 445/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.6429\n",
      "Epoch 445: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6177 - val_loss: 19.1774\n",
      "Epoch 446/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.2444\n",
      "Epoch 446: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1884 - val_loss: 16.7542\n",
      "Epoch 447/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.9878\n",
      "Epoch 447: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9234 - val_loss: 19.9130\n",
      "Epoch 448/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.6556\n",
      "Epoch 448: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.6733 - val_loss: 17.8616\n",
      "Epoch 449/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.5355\n",
      "Epoch 449: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5902 - val_loss: 17.9468\n",
      "Epoch 450/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.1851\n",
      "Epoch 450: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1026 - val_loss: 19.4671\n",
      "Epoch 451/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.4760\n",
      "Epoch 451: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5971 - val_loss: 19.3732\n",
      "Epoch 452/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.8523\n",
      "Epoch 452: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7125 - val_loss: 19.9929\n",
      "Epoch 453/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.0931\n",
      "Epoch 453: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9232 - val_loss: 18.5358\n",
      "Epoch 454/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.6961\n",
      "Epoch 454: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6012 - val_loss: 18.4100\n",
      "Epoch 455/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.7035\n",
      "Epoch 455: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8127 - val_loss: 18.2905\n",
      "Epoch 456/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.2907\n",
      "Epoch 456: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2604 - val_loss: 17.8271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.3378\n",
      "Epoch 457: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3685 - val_loss: 18.7013\n",
      "Epoch 458/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.4800\n",
      "Epoch 458: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4414 - val_loss: 17.2447\n",
      "Epoch 459/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.5243\n",
      "Epoch 459: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4848 - val_loss: 18.3117\n",
      "Epoch 460/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.8664\n",
      "Epoch 460: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7505 - val_loss: 18.6081\n",
      "Epoch 461/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.0071\n",
      "Epoch 461: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9453 - val_loss: 18.0516\n",
      "Epoch 462/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.3026\n",
      "Epoch 462: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.2939 - val_loss: 20.4006\n",
      "Epoch 463/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.8399\n",
      "Epoch 463: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8613 - val_loss: 19.4711\n",
      "Epoch 464/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.4478\n",
      "Epoch 464: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5599 - val_loss: 15.9706\n",
      "Epoch 465/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.0445\n",
      "Epoch 465: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0307 - val_loss: 17.9500\n",
      "Epoch 466/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.6080\n",
      "Epoch 466: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5046 - val_loss: 18.4170\n",
      "Epoch 467/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.4298\n",
      "Epoch 467: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4342 - val_loss: 17.8702\n",
      "Epoch 468/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.8567\n",
      "Epoch 468: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7443 - val_loss: 18.0726\n",
      "Epoch 469/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.4921\n",
      "Epoch 469: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4664 - val_loss: 15.0695\n",
      "Epoch 470/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.9095\n",
      "Epoch 470: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.8073 - val_loss: 17.5848\n",
      "Epoch 471/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.8544\n",
      "Epoch 471: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7482 - val_loss: 18.2769\n",
      "Epoch 472/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.3504\n",
      "Epoch 472: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3851 - val_loss: 16.9986\n",
      "Epoch 473/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.3624\n",
      "Epoch 473: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2388 - val_loss: 18.6234\n",
      "Epoch 474/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.5029\n",
      "Epoch 474: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4202 - val_loss: 17.2489\n",
      "Epoch 475/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.0939\n",
      "Epoch 475: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0916 - val_loss: 18.0632\n",
      "Epoch 476/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.1647\n",
      "Epoch 476: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2180 - val_loss: 18.7277\n",
      "Epoch 477/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.4308\n",
      "Epoch 477: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5489 - val_loss: 16.3195\n",
      "Epoch 478/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.8228\n",
      "Epoch 478: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8244 - val_loss: 17.4728\n",
      "Epoch 479/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.0285\n",
      "Epoch 479: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9746 - val_loss: 19.0469\n",
      "Epoch 480/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.5519\n",
      "Epoch 480: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4947 - val_loss: 17.3881\n",
      "Epoch 481/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.3726\n",
      "Epoch 481: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3316 - val_loss: 19.1768\n",
      "Epoch 482/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.2620\n",
      "Epoch 482: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1378 - val_loss: 18.7198\n",
      "Epoch 483/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.3241\n",
      "Epoch 483: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.2907 - val_loss: 18.4308\n",
      "Epoch 484/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.2517\n",
      "Epoch 484: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3287 - val_loss: 17.4725\n",
      "Epoch 485/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.6641\n",
      "Epoch 485: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5104 - val_loss: 19.2537\n",
      "Epoch 486/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.7144\n",
      "Epoch 486: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2155 - val_loss: 18.6708\n",
      "Epoch 487/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.3520\n",
      "Epoch 487: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2302 - val_loss: 17.3158\n",
      "Epoch 488/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.2967\n",
      "Epoch 488: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.2822 - val_loss: 18.1568\n",
      "Epoch 489/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.7862\n",
      "Epoch 489: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6631 - val_loss: 20.8591\n",
      "Epoch 490/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.8546\n",
      "Epoch 490: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8638 - val_loss: 16.8244\n",
      "Epoch 491/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.2832\n",
      "Epoch 491: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2533 - val_loss: 16.5420\n",
      "Epoch 492/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.0408\n",
      "Epoch 492: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1073 - val_loss: 17.0385\n",
      "Epoch 493/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.0900\n",
      "Epoch 493: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2418 - val_loss: 17.7492\n",
      "Epoch 494/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.2298\n",
      "Epoch 494: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.2589 - val_loss: 17.6615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.3068\n",
      "Epoch 495: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2488 - val_loss: 17.5570\n",
      "Epoch 496/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 4.9641\n",
      "Epoch 496: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9838 - val_loss: 19.0338\n",
      "Epoch 497/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.6623\n",
      "Epoch 497: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5977 - val_loss: 17.3176\n",
      "Epoch 498/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 4.9668\n",
      "Epoch 498: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9606 - val_loss: 18.4298\n",
      "Epoch 499/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.6416\n",
      "Epoch 499: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5704 - val_loss: 16.0624\n",
      "Epoch 500/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.5980\n",
      "Epoch 500: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5692 - val_loss: 18.9070\n",
      "Epoch 501/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.4223\n",
      "Epoch 501: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5006 - val_loss: 18.1152\n",
      "Epoch 502/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 4.9812\n",
      "Epoch 502: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9812 - val_loss: 17.5229\n",
      "Epoch 503/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.1788\n",
      "Epoch 503: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2788 - val_loss: 19.5244\n",
      "Epoch 504/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.7326\n",
      "Epoch 504: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6537 - val_loss: 18.2215\n",
      "Epoch 505/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 5.0318\n",
      "Epoch 505: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1922 - val_loss: 16.7119\n",
      "Epoch 506/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 5.0269\n",
      "Epoch 506: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9772 - val_loss: 18.5369\n",
      "Epoch 507/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.5635\n",
      "Epoch 507: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5932 - val_loss: 18.5092\n",
      "Epoch 508/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.6455\n",
      "Epoch 508: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7243 - val_loss: 19.2770\n",
      "Epoch 509/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.5532\n",
      "Epoch 509: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7126 - val_loss: 19.4331\n",
      "Epoch 510/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.8484\n",
      "Epoch 510: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7727 - val_loss: 19.2759\n",
      "Epoch 511/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 4.9857\n",
      "Epoch 511: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1001 - val_loss: 16.8621\n",
      "Epoch 512/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.9877\n",
      "Epoch 512: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0519 - val_loss: 17.7271\n",
      "Epoch 513/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.9366\n",
      "Epoch 513: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8597 - val_loss: 16.6593\n",
      "Epoch 514/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.9961\n",
      "Epoch 514: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8389 - val_loss: 17.9777\n",
      "Epoch 515/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.3194\n",
      "Epoch 515: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3036 - val_loss: 18.4118\n",
      "Epoch 516/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.8307\n",
      "Epoch 516: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6714 - val_loss: 16.7073\n",
      "Epoch 517/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.9906\n",
      "Epoch 517: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9602 - val_loss: 18.2215\n",
      "Epoch 518/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.2644\n",
      "Epoch 518: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2753 - val_loss: 17.8548\n",
      "Epoch 519/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.6230\n",
      "Epoch 519: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7401 - val_loss: 16.5836\n",
      "Epoch 520/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 5.5736\n",
      "Epoch 520: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4392 - val_loss: 16.8996\n",
      "Epoch 521/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.7066\n",
      "Epoch 521: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7130 - val_loss: 17.1802\n",
      "Epoch 522/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.0343\n",
      "Epoch 522: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0487 - val_loss: 18.6853\n",
      "Epoch 523/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.9204\n",
      "Epoch 523: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8690 - val_loss: 17.5185\n",
      "Epoch 524/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.6303\n",
      "Epoch 524: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.6473 - val_loss: 17.2440\n",
      "Epoch 525/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.7543\n",
      "Epoch 525: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8370 - val_loss: 17.2872\n",
      "Epoch 526/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.3041\n",
      "Epoch 526: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3021 - val_loss: 19.1368\n",
      "Epoch 527/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.0455\n",
      "Epoch 527: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9401 - val_loss: 18.1959\n",
      "Epoch 528/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.4387\n",
      "Epoch 528: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4856 - val_loss: 15.5504\n",
      "Epoch 529/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.2095\n",
      "Epoch 529: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2616 - val_loss: 18.2536\n",
      "Epoch 530/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.6577\n",
      "Epoch 530: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6028 - val_loss: 17.7570\n",
      "Epoch 531/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.3087\n",
      "Epoch 531: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5516 - val_loss: 19.4109\n",
      "Epoch 532/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 5.2118\n",
      "Epoch 532: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2657 - val_loss: 17.3278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.6162\n",
      "Epoch 533: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6207 - val_loss: 16.8190\n",
      "Epoch 534/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.3470\n",
      "Epoch 534: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3643 - val_loss: 16.8895\n",
      "Epoch 535/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.9238\n",
      "Epoch 535: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9317 - val_loss: 16.1303\n",
      "Epoch 536/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.6872\n",
      "Epoch 536: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6652 - val_loss: 16.6894\n",
      "Epoch 537/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.2321\n",
      "Epoch 537: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4183 - val_loss: 16.6487\n",
      "Epoch 538/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.5099\n",
      "Epoch 538: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4201 - val_loss: 16.9828\n",
      "Epoch 539/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 4.9615\n",
      "Epoch 539: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.1698 - val_loss: 17.8985\n",
      "Epoch 540/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.1693\n",
      "Epoch 540: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1755 - val_loss: 16.9961\n",
      "Epoch 541/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 4.9339\n",
      "Epoch 541: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0442 - val_loss: 17.5849\n",
      "Epoch 542/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 6.0101\n",
      "Epoch 542: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7651 - val_loss: 17.6592\n",
      "Epoch 543/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.1501\n",
      "Epoch 543: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3869 - val_loss: 17.0611\n",
      "Epoch 544/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.0670\n",
      "Epoch 544: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9572 - val_loss: 17.0442\n",
      "Epoch 545/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.0117\n",
      "Epoch 545: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9636 - val_loss: 18.1979\n",
      "Epoch 546/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.3418\n",
      "Epoch 546: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4128 - val_loss: 17.8524\n",
      "Epoch 547/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.1146\n",
      "Epoch 547: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1019 - val_loss: 16.9681\n",
      "Epoch 548/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.3435\n",
      "Epoch 548: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3848 - val_loss: 20.7754\n",
      "Epoch 549/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.4094\n",
      "Epoch 549: val_loss did not improve from 12.29665\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2946 - val_loss: 18.2222\n",
      "\n",
      " ---------- 2 ---------- \n",
      "\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 22, 8, 360)        3600      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 7, 2, 360)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " reshape_9 (Reshape)         (None, 7, 720)            0         \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 7, 720)            0         \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 180)               648720    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 180)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 181       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 652,501\n",
      "Trainable params: 652,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 47.7757\n",
      "Epoch 1: val_loss improved from inf to 43.42027, saving model to ./model_save\\3_fold_001-43.4203.hdf5\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 46.7214 - val_loss: 43.4203\n",
      "Epoch 2/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 40.7212\n",
      "Epoch 2: val_loss improved from 43.42027 to 40.99548, saving model to ./model_save\\3_fold_002-40.9955.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 40.7876 - val_loss: 40.9955\n",
      "Epoch 3/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 41.7124\n",
      "Epoch 3: val_loss improved from 40.99548 to 39.80482, saving model to ./model_save\\3_fold_003-39.8048.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 38.5294 - val_loss: 39.8048\n",
      "Epoch 4/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 38.7974\n",
      "Epoch 4: val_loss improved from 39.80482 to 35.35527, saving model to ./model_save\\3_fold_004-35.3553.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 36.3777 - val_loss: 35.3553\n",
      "Epoch 5/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 34.5527\n",
      "Epoch 5: val_loss improved from 35.35527 to 32.82663, saving model to ./model_save\\3_fold_005-32.8266.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 33.6780 - val_loss: 32.8266\n",
      "Epoch 6/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 32.8867\n",
      "Epoch 6: val_loss improved from 32.82663 to 30.73829, saving model to ./model_save\\3_fold_006-30.7383.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 32.9108 - val_loss: 30.7383\n",
      "Epoch 7/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 31.2631\n",
      "Epoch 7: val_loss did not improve from 30.73829\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 31.0945 - val_loss: 31.1060\n",
      "Epoch 8/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 30.1543\n",
      "Epoch 8: val_loss improved from 30.73829 to 30.36797, saving model to ./model_save\\3_fold_008-30.3680.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 30.1014 - val_loss: 30.3680\n",
      "Epoch 9/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 29.3754\n",
      "Epoch 9: val_loss improved from 30.36797 to 28.09801, saving model to ./model_save\\3_fold_009-28.0980.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 28.2962 - val_loss: 28.0980\n",
      "Epoch 10/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 25.8459\n",
      "Epoch 10: val_loss improved from 28.09801 to 25.78180, saving model to ./model_save\\3_fold_010-25.7818.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 27.6309 - val_loss: 25.7818\n",
      "Epoch 11/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 28.0475\n",
      "Epoch 11: val_loss improved from 25.78180 to 25.29145, saving model to ./model_save\\3_fold_011-25.2915.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 27.0204 - val_loss: 25.2915\n",
      "Epoch 12/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 27.0825\n",
      "Epoch 12: val_loss improved from 25.29145 to 23.88442, saving model to ./model_save\\3_fold_012-23.8844.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 26.0641 - val_loss: 23.8844\n",
      "Epoch 13/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 24.7159\n",
      "Epoch 13: val_loss did not improve from 23.88442\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 25.1747 - val_loss: 24.0487\n",
      "Epoch 14/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 25.5232\n",
      "Epoch 14: val_loss did not improve from 23.88442\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 25.3598 - val_loss: 26.3146\n",
      "Epoch 15/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 25.5449\n",
      "Epoch 15: val_loss improved from 23.88442 to 22.15234, saving model to ./model_save\\3_fold_015-22.1523.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 25.0398 - val_loss: 22.1523\n",
      "Epoch 16/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 22.6235\n",
      "Epoch 16: val_loss improved from 22.15234 to 21.10307, saving model to ./model_save\\3_fold_016-21.1031.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 23.7283 - val_loss: 21.1031\n",
      "Epoch 17/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 23.4966\n",
      "Epoch 17: val_loss did not improve from 21.10307\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 23.5230 - val_loss: 21.3305\n",
      "Epoch 18/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 23.6036\n",
      "Epoch 18: val_loss did not improve from 21.10307\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 23.6036 - val_loss: 21.1517\n",
      "Epoch 19/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 22.2404\n",
      "Epoch 19: val_loss improved from 21.10307 to 19.21480, saving model to ./model_save\\3_fold_019-19.2148.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 22.2404 - val_loss: 19.2148\n",
      "Epoch 20/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 22.9323\n",
      "Epoch 20: val_loss did not improve from 19.21480\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 22.9963 - val_loss: 25.4744\n",
      "Epoch 21/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 22.6925\n",
      "Epoch 21: val_loss did not improve from 19.21480\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 22.6360 - val_loss: 20.9121\n",
      "Epoch 22/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 22.6180\n",
      "Epoch 22: val_loss improved from 19.21480 to 18.56066, saving model to ./model_save\\3_fold_022-18.5607.hdf5\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 22.9891 - val_loss: 18.5607\n",
      "Epoch 23/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 22.3256\n",
      "Epoch 23: val_loss did not improve from 18.56066\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 22.2986 - val_loss: 19.1287\n",
      "Epoch 24/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 20.6902\n",
      "Epoch 24: val_loss improved from 18.56066 to 17.24111, saving model to ./model_save\\3_fold_024-17.2411.hdf5\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 20.9329 - val_loss: 17.2411\n",
      "Epoch 25/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 21.0583\n",
      "Epoch 25: val_loss did not improve from 17.24111\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 21.9081 - val_loss: 18.1829\n",
      "Epoch 26/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 20.3050\n",
      "Epoch 26: val_loss did not improve from 17.24111\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 20.0715 - val_loss: 18.1777\n",
      "Epoch 27/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 20.5408\n",
      "Epoch 27: val_loss improved from 17.24111 to 15.94977, saving model to ./model_save\\3_fold_027-15.9498.hdf5\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 20.2571 - val_loss: 15.9498\n",
      "Epoch 28/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 19.6513\n",
      "Epoch 28: val_loss did not improve from 15.94977\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.7562 - val_loss: 15.9621\n",
      "Epoch 29/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 21.3674\n",
      "Epoch 29: val_loss did not improve from 15.94977\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 21.0838 - val_loss: 17.1090\n",
      "Epoch 30/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 19.6910\n",
      "Epoch 30: val_loss improved from 15.94977 to 15.60670, saving model to ./model_save\\3_fold_030-15.6067.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.6910 - val_loss: 15.6067\n",
      "Epoch 31/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 18.3541\n",
      "Epoch 31: val_loss did not improve from 15.60670\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.2794 - val_loss: 19.4565\n",
      "Epoch 32/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 19.7942\n",
      "Epoch 32: val_loss did not improve from 15.60670\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.4789 - val_loss: 17.3954\n",
      "Epoch 33/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 18.8341\n",
      "Epoch 33: val_loss did not improve from 15.60670\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.6176 - val_loss: 18.1509\n",
      "Epoch 34/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 18.8791\n",
      "Epoch 34: val_loss improved from 15.60670 to 15.58099, saving model to ./model_save\\3_fold_034-15.5810.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.7645 - val_loss: 15.5810\n",
      "Epoch 35/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 17.8062\n",
      "Epoch 35: val_loss did not improve from 15.58099\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.0364 - val_loss: 15.7876\n",
      "Epoch 36/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 18.4107\n",
      "Epoch 36: val_loss improved from 15.58099 to 14.61845, saving model to ./model_save\\3_fold_036-14.6185.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.0506 - val_loss: 14.6185\n",
      "Epoch 37/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 18.3429\n",
      "Epoch 37: val_loss did not improve from 14.61845\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.3807 - val_loss: 15.3817\n",
      "Epoch 38/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 18.1360\n",
      "Epoch 38: val_loss improved from 14.61845 to 14.27688, saving model to ./model_save\\3_fold_038-14.2769.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.0767 - val_loss: 14.2769\n",
      "Epoch 39/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 17.4974\n",
      "Epoch 39: val_loss did not improve from 14.27688\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.6063 - val_loss: 14.9574\n",
      "Epoch 40/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 16.8861\n",
      "Epoch 40: val_loss did not improve from 14.27688\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.7070 - val_loss: 15.2748\n",
      "Epoch 41/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 17.9787\n",
      "Epoch 41: val_loss did not improve from 14.27688\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.2671 - val_loss: 16.0556\n",
      "Epoch 42/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 17.6486\n",
      "Epoch 42: val_loss did not improve from 14.27688\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.7855 - val_loss: 15.8341\n",
      "Epoch 43/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 16.2572\n",
      "Epoch 43: val_loss did not improve from 14.27688\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.2572 - val_loss: 14.3685\n",
      "Epoch 44/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 17.8161\n",
      "Epoch 44: val_loss did not improve from 14.27688\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.1190 - val_loss: 15.0201\n",
      "Epoch 45/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 16.2692\n",
      "Epoch 45: val_loss improved from 14.27688 to 13.90352, saving model to ./model_save\\3_fold_045-13.9035.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.4888 - val_loss: 13.9035\n",
      "Epoch 46/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 16.6447\n",
      "Epoch 46: val_loss did not improve from 13.90352\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.7866 - val_loss: 14.8217\n",
      "Epoch 47/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 17.0211\n",
      "Epoch 47: val_loss did not improve from 13.90352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 17.0186 - val_loss: 15.2458\n",
      "Epoch 48/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 16.0250\n",
      "Epoch 48: val_loss did not improve from 13.90352\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.2405 - val_loss: 14.0673\n",
      "Epoch 49/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 16.8195\n",
      "Epoch 49: val_loss did not improve from 13.90352\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.5655 - val_loss: 15.9167\n",
      "Epoch 50/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 15.0859\n",
      "Epoch 50: val_loss did not improve from 13.90352\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.3098 - val_loss: 14.5087\n",
      "Epoch 51/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 15.9234\n",
      "Epoch 51: val_loss did not improve from 13.90352\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.6515 - val_loss: 13.9582\n",
      "Epoch 52/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 14.8882\n",
      "Epoch 52: val_loss did not improve from 13.90352\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.8812 - val_loss: 14.6610\n",
      "Epoch 53/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 15.8311\n",
      "Epoch 53: val_loss improved from 13.90352 to 13.56568, saving model to ./model_save\\3_fold_053-13.5657.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.5914 - val_loss: 13.5657\n",
      "Epoch 54/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 15.1501\n",
      "Epoch 54: val_loss improved from 13.56568 to 13.28641, saving model to ./model_save\\3_fold_054-13.2864.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.9388 - val_loss: 13.2864\n",
      "Epoch 55/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 14.9025\n",
      "Epoch 55: val_loss did not improve from 13.28641\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.0341 - val_loss: 15.0857\n",
      "Epoch 56/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 14.6090\n",
      "Epoch 56: val_loss did not improve from 13.28641\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.5340 - val_loss: 13.6893\n",
      "Epoch 57/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 14.6925\n",
      "Epoch 57: val_loss did not improve from 13.28641\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.0998 - val_loss: 16.2592\n",
      "Epoch 58/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 14.1878\n",
      "Epoch 58: val_loss improved from 13.28641 to 12.75997, saving model to ./model_save\\3_fold_058-12.7600.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.1395 - val_loss: 12.7600\n",
      "Epoch 59/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 14.0009\n",
      "Epoch 59: val_loss did not improve from 12.75997\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.2975 - val_loss: 18.0306\n",
      "Epoch 60/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 15.0379\n",
      "Epoch 60: val_loss did not improve from 12.75997\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.9991 - val_loss: 16.3664\n",
      "Epoch 61/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 14.4635\n",
      "Epoch 61: val_loss did not improve from 12.75997\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.3471 - val_loss: 15.2612\n",
      "Epoch 62/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 14.1377\n",
      "Epoch 62: val_loss did not improve from 12.75997\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 13.5444 - val_loss: 14.7952\n",
      "Epoch 63/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 12.8023\n",
      "Epoch 63: val_loss did not improve from 12.75997\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.0395 - val_loss: 14.2870\n",
      "Epoch 64/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 13.7602\n",
      "Epoch 64: val_loss did not improve from 12.75997\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.6929 - val_loss: 17.7560\n",
      "Epoch 65/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 12.6817\n",
      "Epoch 65: val_loss did not improve from 12.75997\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.2337 - val_loss: 15.0176\n",
      "Epoch 66/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 13.2569\n",
      "Epoch 66: val_loss did not improve from 12.75997\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.1166 - val_loss: 15.6671\n",
      "Epoch 67/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 12.9295\n",
      "Epoch 67: val_loss did not improve from 12.75997\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.6557 - val_loss: 14.3898\n",
      "Epoch 68/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 12.5852\n",
      "Epoch 68: val_loss did not improve from 12.75997\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.6243 - val_loss: 15.1343\n",
      "Epoch 69/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 13.6660\n",
      "Epoch 69: val_loss did not improve from 12.75997\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.7870 - val_loss: 13.8078\n",
      "Epoch 70/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 12.8096\n",
      "Epoch 70: val_loss improved from 12.75997 to 12.66230, saving model to ./model_save\\3_fold_070-12.6623.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.6265 - val_loss: 12.6623\n",
      "Epoch 71/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 11.8388\n",
      "Epoch 71: val_loss did not improve from 12.66230\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.7148 - val_loss: 14.0079\n",
      "Epoch 72/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 11.4894\n",
      "Epoch 72: val_loss did not improve from 12.66230\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 11.4799 - val_loss: 14.2031\n",
      "Epoch 73/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 12.6788\n",
      "Epoch 73: val_loss did not improve from 12.66230\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.5302 - val_loss: 16.2419\n",
      "Epoch 74/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 11.7760\n",
      "Epoch 74: val_loss did not improve from 12.66230\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.6146 - val_loss: 16.3047\n",
      "Epoch 75/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 11.4158\n",
      "Epoch 75: val_loss did not improve from 12.66230\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.6527 - val_loss: 18.1031\n",
      "Epoch 76/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 11.4829\n",
      "Epoch 76: val_loss did not improve from 12.66230\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.5293 - val_loss: 16.3881\n",
      "Epoch 77/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 11.0943\n",
      "Epoch 77: val_loss did not improve from 12.66230\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.0853 - val_loss: 16.2542\n",
      "Epoch 78/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 11.9020\n",
      "Epoch 78: val_loss did not improve from 12.66230\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.5443 - val_loss: 17.5634\n",
      "Epoch 79/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 11.5026\n",
      "Epoch 79: val_loss improved from 12.66230 to 12.47151, saving model to ./model_save\\3_fold_079-12.4715.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.2814 - val_loss: 12.4715\n",
      "Epoch 80/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 10.6621\n",
      "Epoch 80: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.7109 - val_loss: 17.0732\n",
      "Epoch 81/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 10.0377\n",
      "Epoch 81: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.1572 - val_loss: 12.9448\n",
      "Epoch 82/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 12.4956\n",
      "Epoch 82: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.4958 - val_loss: 12.9534\n",
      "Epoch 83/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 10.3865\n",
      "Epoch 83: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.2547 - val_loss: 14.0434\n",
      "Epoch 84/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/84 [=========================>....] - ETA: 0s - loss: 10.2028\n",
      "Epoch 84: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.0930 - val_loss: 15.5329\n",
      "Epoch 85/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 10.7310\n",
      "Epoch 85: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.4557 - val_loss: 16.0670\n",
      "Epoch 86/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 10.5842\n",
      "Epoch 86: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.6840 - val_loss: 15.7229\n",
      "Epoch 87/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 10.7299\n",
      "Epoch 87: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.7236 - val_loss: 14.3390\n",
      "Epoch 88/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 10.1765\n",
      "Epoch 88: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.5327 - val_loss: 14.9165\n",
      "Epoch 89/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 9.8003 \n",
      "Epoch 89: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.1940 - val_loss: 13.9665\n",
      "Epoch 90/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 9.7495\n",
      "Epoch 90: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.8492 - val_loss: 13.4082\n",
      "Epoch 91/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 9.7521\n",
      "Epoch 91: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.6115 - val_loss: 17.8812\n",
      "Epoch 92/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 9.0734\n",
      "Epoch 92: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.5974 - val_loss: 14.4901\n",
      "Epoch 93/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 10.1196\n",
      "Epoch 93: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.1199 - val_loss: 15.8659\n",
      "Epoch 94/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 9.4236\n",
      "Epoch 94: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.4233 - val_loss: 20.0352\n",
      "Epoch 95/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 10.4386\n",
      "Epoch 95: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.3692 - val_loss: 18.3106\n",
      "Epoch 96/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 10.6171\n",
      "Epoch 96: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.4667 - val_loss: 16.0704\n",
      "Epoch 97/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 9.0999\n",
      "Epoch 97: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1108 - val_loss: 14.9553\n",
      "Epoch 98/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 10.1447\n",
      "Epoch 98: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.0991 - val_loss: 17.3572\n",
      "Epoch 99/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 9.5224\n",
      "Epoch 99: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.4699 - val_loss: 20.6088\n",
      "Epoch 100/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 9.4804\n",
      "Epoch 100: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.5633 - val_loss: 13.4049\n",
      "Epoch 101/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 10.2718\n",
      "Epoch 101: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.3266 - val_loss: 13.3201\n",
      "Epoch 102/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 9.6010\n",
      "Epoch 102: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.6394 - val_loss: 17.0217\n",
      "Epoch 103/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 9.8711\n",
      "Epoch 103: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.6680 - val_loss: 14.0774\n",
      "Epoch 104/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.9617\n",
      "Epoch 104: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0568 - val_loss: 13.7828\n",
      "Epoch 105/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 9.5850\n",
      "Epoch 105: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.4108 - val_loss: 17.0452\n",
      "Epoch 106/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 9.6532\n",
      "Epoch 106: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.8659 - val_loss: 20.5478\n",
      "Epoch 107/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 8.8067\n",
      "Epoch 107: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7167 - val_loss: 18.7741\n",
      "Epoch 108/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 9.4604\n",
      "Epoch 108: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.3383 - val_loss: 16.6175\n",
      "Epoch 109/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 9.1378\n",
      "Epoch 109: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2054 - val_loss: 15.5067\n",
      "Epoch 110/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 9.1003\n",
      "Epoch 110: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1322 - val_loss: 19.4559\n",
      "Epoch 111/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 8.0617\n",
      "Epoch 111: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1775 - val_loss: 19.1727\n",
      "Epoch 112/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 9.1170\n",
      "Epoch 112: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9576 - val_loss: 17.0082\n",
      "Epoch 113/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 8.6878\n",
      "Epoch 113: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7739 - val_loss: 15.3896\n",
      "Epoch 114/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.8396\n",
      "Epoch 114: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7344 - val_loss: 16.1281\n",
      "Epoch 115/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 8.8467\n",
      "Epoch 115: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.8247 - val_loss: 19.3603\n",
      "Epoch 116/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 9.0889\n",
      "Epoch 116: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.3475 - val_loss: 13.0650\n",
      "Epoch 117/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 9.2531\n",
      "Epoch 117: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1576 - val_loss: 13.3673\n",
      "Epoch 118/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 9.3739 \n",
      "Epoch 118: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.3051 - val_loss: 16.0762\n",
      "Epoch 119/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 8.5903\n",
      "Epoch 119: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6830 - val_loss: 15.9006\n",
      "Epoch 120/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 9.5643\n",
      "Epoch 120: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.3647 - val_loss: 15.6815\n",
      "Epoch 121/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 9.3134\n",
      "Epoch 121: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.4379 - val_loss: 15.1663\n",
      "Epoch 122/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/84 [=========================>....] - ETA: 0s - loss: 8.4713\n",
      "Epoch 122: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6153 - val_loss: 15.1762\n",
      "Epoch 123/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 9.1827\n",
      "Epoch 123: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0326 - val_loss: 14.2204\n",
      "Epoch 124/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 8.7194\n",
      "Epoch 124: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.8095 - val_loss: 16.7436\n",
      "Epoch 125/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 9.2831\n",
      "Epoch 125: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0411 - val_loss: 13.0576\n",
      "Epoch 126/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 8.3425\n",
      "Epoch 126: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4854 - val_loss: 18.4771\n",
      "Epoch 127/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 8.1624\n",
      "Epoch 127: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2680 - val_loss: 17.2115\n",
      "Epoch 128/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 8.3313\n",
      "Epoch 128: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2964 - val_loss: 20.4251\n",
      "Epoch 129/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.2903\n",
      "Epoch 129: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1834 - val_loss: 15.6130\n",
      "Epoch 130/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 8.0646\n",
      "Epoch 130: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0751 - val_loss: 15.4652\n",
      "Epoch 131/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.8359\n",
      "Epoch 131: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8597 - val_loss: 15.2544\n",
      "Epoch 132/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 8.9413\n",
      "Epoch 132: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5778 - val_loss: 14.4462\n",
      "Epoch 133/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 9.5027\n",
      "Epoch 133: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.4436 - val_loss: 17.4129\n",
      "Epoch 134/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.5777\n",
      "Epoch 134: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5511 - val_loss: 17.2968\n",
      "Epoch 135/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.5562\n",
      "Epoch 135: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4879 - val_loss: 17.6836\n",
      "Epoch 136/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 8.5174\n",
      "Epoch 136: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4676 - val_loss: 15.3300\n",
      "Epoch 137/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.0112\n",
      "Epoch 137: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7848 - val_loss: 15.8219\n",
      "Epoch 138/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.6760\n",
      "Epoch 138: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7921 - val_loss: 13.6459\n",
      "Epoch 139/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 8.1413\n",
      "Epoch 139: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0725 - val_loss: 13.8967\n",
      "Epoch 140/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.5063\n",
      "Epoch 140: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5850 - val_loss: 14.5997\n",
      "Epoch 141/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.3025\n",
      "Epoch 141: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5782 - val_loss: 14.9031\n",
      "Epoch 142/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 8.7171\n",
      "Epoch 142: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7210 - val_loss: 16.1191\n",
      "Epoch 143/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 8.3593\n",
      "Epoch 143: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1855 - val_loss: 15.1378\n",
      "Epoch 144/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.1029\n",
      "Epoch 144: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1214 - val_loss: 14.7938\n",
      "Epoch 145/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 8.0100\n",
      "Epoch 145: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0687 - val_loss: 16.5040\n",
      "Epoch 146/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 8.5397\n",
      "Epoch 146: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3020 - val_loss: 18.0005\n",
      "Epoch 147/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 7.4216\n",
      "Epoch 147: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5484 - val_loss: 15.8858\n",
      "Epoch 148/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.8369\n",
      "Epoch 148: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6317 - val_loss: 16.5063\n",
      "Epoch 149/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 8.1300\n",
      "Epoch 149: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2160 - val_loss: 15.9686\n",
      "Epoch 150/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.7130\n",
      "Epoch 150: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9700 - val_loss: 15.7194\n",
      "Epoch 151/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 7.5570\n",
      "Epoch 151: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8221 - val_loss: 15.0062\n",
      "Epoch 152/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.0146\n",
      "Epoch 152: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0166 - val_loss: 18.7057\n",
      "Epoch 153/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.6820\n",
      "Epoch 153: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4616 - val_loss: 13.4667\n",
      "Epoch 154/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.2777\n",
      "Epoch 154: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3030 - val_loss: 13.7210\n",
      "Epoch 155/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 8.4848\n",
      "Epoch 155: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4099 - val_loss: 19.0660\n",
      "Epoch 156/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.5745\n",
      "Epoch 156: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6710 - val_loss: 13.9752\n",
      "Epoch 157/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.6062\n",
      "Epoch 157: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6059 - val_loss: 15.3053\n",
      "Epoch 158/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 8.1496\n",
      "Epoch 158: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2795 - val_loss: 17.4910\n",
      "Epoch 159/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 7.6233\n",
      "Epoch 159: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5903 - val_loss: 16.5498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 8.0280\n",
      "Epoch 160: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0378 - val_loss: 15.8687\n",
      "Epoch 161/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 7.5167\n",
      "Epoch 161: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8186 - val_loss: 14.3637\n",
      "Epoch 162/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 7.6525\n",
      "Epoch 162: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5568 - val_loss: 14.1737\n",
      "Epoch 163/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.1740\n",
      "Epoch 163: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3773 - val_loss: 14.7347\n",
      "Epoch 164/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 7.9768\n",
      "Epoch 164: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6689 - val_loss: 15.8308\n",
      "Epoch 165/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.3202\n",
      "Epoch 165: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3118 - val_loss: 14.4838\n",
      "Epoch 166/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 8.0580\n",
      "Epoch 166: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1310 - val_loss: 16.5628\n",
      "Epoch 167/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.5905\n",
      "Epoch 167: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6456 - val_loss: 18.4291\n",
      "Epoch 168/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.7314\n",
      "Epoch 168: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6521 - val_loss: 15.6162\n",
      "Epoch 169/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 9.7232\n",
      "Epoch 169: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.5808 - val_loss: 13.5612\n",
      "Epoch 170/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.6806\n",
      "Epoch 170: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8093 - val_loss: 15.7272\n",
      "Epoch 171/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.6433\n",
      "Epoch 171: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.8091 - val_loss: 21.1330\n",
      "Epoch 172/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.5621\n",
      "Epoch 172: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5010 - val_loss: 17.8932\n",
      "Epoch 173/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 8.0507\n",
      "Epoch 173: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9270 - val_loss: 16.8439\n",
      "Epoch 174/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.6179\n",
      "Epoch 174: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6055 - val_loss: 15.5981\n",
      "Epoch 175/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.4234\n",
      "Epoch 175: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3308 - val_loss: 14.2269\n",
      "Epoch 176/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.8168\n",
      "Epoch 176: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8323 - val_loss: 18.6748\n",
      "Epoch 177/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.8379\n",
      "Epoch 177: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9473 - val_loss: 17.2093\n",
      "Epoch 178/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.9991\n",
      "Epoch 178: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2376 - val_loss: 15.1650\n",
      "Epoch 179/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.7889\n",
      "Epoch 179: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0205 - val_loss: 15.2629\n",
      "Epoch 180/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.4752\n",
      "Epoch 180: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4503 - val_loss: 17.9998\n",
      "Epoch 181/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.3732\n",
      "Epoch 181: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4256 - val_loss: 13.4906\n",
      "Epoch 182/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.2298\n",
      "Epoch 182: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3265 - val_loss: 17.6941\n",
      "Epoch 183/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.7896\n",
      "Epoch 183: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0139 - val_loss: 14.3125\n",
      "Epoch 184/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.8380\n",
      "Epoch 184: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8034 - val_loss: 14.7742\n",
      "Epoch 185/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.2263\n",
      "Epoch 185: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4397 - val_loss: 14.8055\n",
      "Epoch 186/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 7.0413\n",
      "Epoch 186: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1037 - val_loss: 13.9941\n",
      "Epoch 187/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 7.1759\n",
      "Epoch 187: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2626 - val_loss: 15.1270\n",
      "Epoch 188/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.6393\n",
      "Epoch 188: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8396 - val_loss: 14.3653\n",
      "Epoch 189/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.4581\n",
      "Epoch 189: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6299 - val_loss: 17.7799\n",
      "Epoch 190/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.1277\n",
      "Epoch 190: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2278 - val_loss: 17.1138\n",
      "Epoch 191/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.0242\n",
      "Epoch 191: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0856 - val_loss: 16.1572\n",
      "Epoch 192/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.4470\n",
      "Epoch 192: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3411 - val_loss: 19.0411\n",
      "Epoch 193/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.2655\n",
      "Epoch 193: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3151 - val_loss: 17.5575\n",
      "Epoch 194/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.9266\n",
      "Epoch 194: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5460 - val_loss: 15.5923\n",
      "Epoch 195/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.9596\n",
      "Epoch 195: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9365 - val_loss: 15.1389\n",
      "Epoch 196/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.4364\n",
      "Epoch 196: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2836 - val_loss: 17.2185\n",
      "Epoch 197/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.3902\n",
      "Epoch 197: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3646 - val_loss: 15.4819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.2769\n",
      "Epoch 198: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1577 - val_loss: 14.8481\n",
      "Epoch 199/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.0958\n",
      "Epoch 199: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1618 - val_loss: 16.5107\n",
      "Epoch 200/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.8682\n",
      "Epoch 200: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9390 - val_loss: 16.2347\n",
      "Epoch 201/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 7.1362\n",
      "Epoch 201: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9326 - val_loss: 14.6300\n",
      "Epoch 202/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.0476\n",
      "Epoch 202: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0742 - val_loss: 16.7398\n",
      "Epoch 203/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 7.8794\n",
      "Epoch 203: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7201 - val_loss: 17.9299\n",
      "Epoch 204/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.7754\n",
      "Epoch 204: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9278 - val_loss: 17.0789\n",
      "Epoch 205/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.7314\n",
      "Epoch 205: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7326 - val_loss: 17.4070\n",
      "Epoch 206/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.1981\n",
      "Epoch 206: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3466 - val_loss: 15.0828\n",
      "Epoch 207/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.8471\n",
      "Epoch 207: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8506 - val_loss: 13.3916\n",
      "Epoch 208/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.4771\n",
      "Epoch 208: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8768 - val_loss: 14.2353\n",
      "Epoch 209/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.1274\n",
      "Epoch 209: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0790 - val_loss: 16.8198\n",
      "Epoch 210/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.7868\n",
      "Epoch 210: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6673 - val_loss: 17.4333\n",
      "Epoch 211/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.0783\n",
      "Epoch 211: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1507 - val_loss: 17.7591\n",
      "Epoch 212/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.6538\n",
      "Epoch 212: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6546 - val_loss: 13.4425\n",
      "Epoch 213/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.6366\n",
      "Epoch 213: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4234 - val_loss: 19.1153\n",
      "Epoch 214/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.7330\n",
      "Epoch 214: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.9642 - val_loss: 15.0569\n",
      "Epoch 215/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.3257\n",
      "Epoch 215: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2363 - val_loss: 18.6503\n",
      "Epoch 216/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.2949\n",
      "Epoch 216: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2834 - val_loss: 20.0191\n",
      "Epoch 217/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.9018\n",
      "Epoch 217: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.0194 - val_loss: 17.9901\n",
      "Epoch 218/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.8187\n",
      "Epoch 218: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9236 - val_loss: 14.8467\n",
      "Epoch 219/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.9662\n",
      "Epoch 219: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0497 - val_loss: 17.8843\n",
      "Epoch 220/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.4501\n",
      "Epoch 220: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3516 - val_loss: 17.9345\n",
      "Epoch 221/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.8137\n",
      "Epoch 221: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7629 - val_loss: 14.1361\n",
      "Epoch 222/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.6939\n",
      "Epoch 222: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6346 - val_loss: 16.1424\n",
      "Epoch 223/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.0735\n",
      "Epoch 223: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0735 - val_loss: 14.7703\n",
      "Epoch 224/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.7470\n",
      "Epoch 224: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6787 - val_loss: 14.6780\n",
      "Epoch 225/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.1933\n",
      "Epoch 225: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1227 - val_loss: 17.2378\n",
      "Epoch 226/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.8290\n",
      "Epoch 226: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7105 - val_loss: 15.5955\n",
      "Epoch 227/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.0026\n",
      "Epoch 227: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0121 - val_loss: 17.8994\n",
      "Epoch 228/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.2328\n",
      "Epoch 228: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3324 - val_loss: 16.8621\n",
      "Epoch 229/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.7651\n",
      "Epoch 229: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7437 - val_loss: 19.9715\n",
      "Epoch 230/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.6920\n",
      "Epoch 230: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8482 - val_loss: 22.3880\n",
      "Epoch 231/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.7670\n",
      "Epoch 231: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7116 - val_loss: 14.9275\n",
      "Epoch 232/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 8.0055\n",
      "Epoch 232: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7684 - val_loss: 15.0277\n",
      "Epoch 233/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.5237\n",
      "Epoch 233: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4539 - val_loss: 15.8814\n",
      "Epoch 234/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.6614\n",
      "Epoch 234: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8619 - val_loss: 13.9706\n",
      "Epoch 235/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.7957\n",
      "Epoch 235: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7485 - val_loss: 15.2107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.2166\n",
      "Epoch 236: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2522 - val_loss: 16.0425\n",
      "Epoch 237/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.4445\n",
      "Epoch 237: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4123 - val_loss: 15.4235\n",
      "Epoch 238/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 7.0702\n",
      "Epoch 238: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0570 - val_loss: 16.2880\n",
      "Epoch 239/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.1798\n",
      "Epoch 239: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2909 - val_loss: 14.9729\n",
      "Epoch 240/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.2414\n",
      "Epoch 240: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3661 - val_loss: 20.6780\n",
      "Epoch 241/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.0026\n",
      "Epoch 241: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0923 - val_loss: 18.3105\n",
      "Epoch 242/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.7603\n",
      "Epoch 242: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6313 - val_loss: 14.8691\n",
      "Epoch 243/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.8214\n",
      "Epoch 243: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7437 - val_loss: 17.9643\n",
      "Epoch 244/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.2650\n",
      "Epoch 244: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1827 - val_loss: 15.3144\n",
      "Epoch 245/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.2521\n",
      "Epoch 245: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3374 - val_loss: 17.8853\n",
      "Epoch 246/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.8139\n",
      "Epoch 246: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0753 - val_loss: 15.0005\n",
      "Epoch 247/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.9522\n",
      "Epoch 247: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6769 - val_loss: 17.6347\n",
      "Epoch 248/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.3662\n",
      "Epoch 248: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4365 - val_loss: 15.1126\n",
      "Epoch 249/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.1211\n",
      "Epoch 249: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0849 - val_loss: 12.8654\n",
      "Epoch 250/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.3131\n",
      "Epoch 250: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6154 - val_loss: 21.0117\n",
      "Epoch 251/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.2127\n",
      "Epoch 251: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2699 - val_loss: 19.3173\n",
      "Epoch 252/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.4361\n",
      "Epoch 252: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4655 - val_loss: 19.7671\n",
      "Epoch 253/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.7463\n",
      "Epoch 253: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7132 - val_loss: 13.9573\n",
      "Epoch 254/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.0464\n",
      "Epoch 254: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0694 - val_loss: 18.1657\n",
      "Epoch 255/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.2114\n",
      "Epoch 255: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4739 - val_loss: 15.7083\n",
      "Epoch 256/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.7640\n",
      "Epoch 256: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8061 - val_loss: 16.6938\n",
      "Epoch 257/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 5.9043\n",
      "Epoch 257: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1443 - val_loss: 19.9380\n",
      "Epoch 258/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 6.3540\n",
      "Epoch 258: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5053 - val_loss: 17.2606\n",
      "Epoch 259/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.7648\n",
      "Epoch 259: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8905 - val_loss: 18.2432\n",
      "Epoch 260/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.7592\n",
      "Epoch 260: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6766 - val_loss: 19.5596\n",
      "Epoch 261/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.3960\n",
      "Epoch 261: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3607 - val_loss: 17.2416\n",
      "Epoch 262/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.0301\n",
      "Epoch 262: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7693 - val_loss: 17.8269\n",
      "Epoch 263/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.8963\n",
      "Epoch 263: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8499 - val_loss: 18.9664\n",
      "Epoch 264/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.6419\n",
      "Epoch 264: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5406 - val_loss: 14.5694\n",
      "Epoch 265/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.7655\n",
      "Epoch 265: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8175 - val_loss: 15.6793\n",
      "Epoch 266/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.8279\n",
      "Epoch 266: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0522 - val_loss: 15.0749\n",
      "Epoch 267/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.9783\n",
      "Epoch 267: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0786 - val_loss: 16.7101\n",
      "Epoch 268/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.2935\n",
      "Epoch 268: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3680 - val_loss: 13.6377\n",
      "Epoch 269/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.9485\n",
      "Epoch 269: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8873 - val_loss: 16.0925\n",
      "Epoch 270/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.2928\n",
      "Epoch 270: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9805 - val_loss: 15.7774\n",
      "Epoch 271/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.0280\n",
      "Epoch 271: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0280 - val_loss: 18.8592\n",
      "Epoch 272/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.3550\n",
      "Epoch 272: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3562 - val_loss: 17.9390\n",
      "Epoch 273/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.9385\n",
      "Epoch 273: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9782 - val_loss: 17.7313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.4146\n",
      "Epoch 274: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3950 - val_loss: 18.8264\n",
      "Epoch 275/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.0048\n",
      "Epoch 275: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0458 - val_loss: 14.8052\n",
      "Epoch 276/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.4047\n",
      "Epoch 276: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3328 - val_loss: 16.9792\n",
      "Epoch 277/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.0077\n",
      "Epoch 277: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8742 - val_loss: 15.2796\n",
      "Epoch 278/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.2647\n",
      "Epoch 278: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2023 - val_loss: 13.9962\n",
      "Epoch 279/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 6.1516\n",
      "Epoch 279: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2390 - val_loss: 14.1684\n",
      "Epoch 280/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.0791\n",
      "Epoch 280: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1721 - val_loss: 18.2272\n",
      "Epoch 281/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.2581\n",
      "Epoch 281: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1729 - val_loss: 17.3450\n",
      "Epoch 282/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.2759\n",
      "Epoch 282: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4549 - val_loss: 15.7372\n",
      "Epoch 283/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.5224\n",
      "Epoch 283: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2711 - val_loss: 15.5686\n",
      "Epoch 284/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 7.0575\n",
      "Epoch 284: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7669 - val_loss: 18.0713\n",
      "Epoch 285/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.4031\n",
      "Epoch 285: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3572 - val_loss: 14.2292\n",
      "Epoch 286/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.1935\n",
      "Epoch 286: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2118 - val_loss: 18.1941\n",
      "Epoch 287/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.7214\n",
      "Epoch 287: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4834 - val_loss: 15.6936\n",
      "Epoch 288/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.1145\n",
      "Epoch 288: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0654 - val_loss: 13.3266\n",
      "Epoch 289/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.1275\n",
      "Epoch 289: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1091 - val_loss: 12.5133\n",
      "Epoch 290/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.5878\n",
      "Epoch 290: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3033 - val_loss: 18.1280\n",
      "Epoch 291/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.9223\n",
      "Epoch 291: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0737 - val_loss: 16.3454\n",
      "Epoch 292/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.8200\n",
      "Epoch 292: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7352 - val_loss: 13.5663\n",
      "Epoch 293/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.1791\n",
      "Epoch 293: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2284 - val_loss: 13.7930\n",
      "Epoch 294/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.0811\n",
      "Epoch 294: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3271 - val_loss: 13.5681\n",
      "Epoch 295/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.2947\n",
      "Epoch 295: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1570 - val_loss: 17.6945\n",
      "Epoch 296/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.3042\n",
      "Epoch 296: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3966 - val_loss: 13.9597\n",
      "Epoch 297/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.9166\n",
      "Epoch 297: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8328 - val_loss: 14.4769\n",
      "Epoch 298/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.7694\n",
      "Epoch 298: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8459 - val_loss: 14.5118\n",
      "Epoch 299/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.2768\n",
      "Epoch 299: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0746 - val_loss: 16.2481\n",
      "Epoch 300/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.1780\n",
      "Epoch 300: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1570 - val_loss: 19.1064\n",
      "Epoch 301/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.7734\n",
      "Epoch 301: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.9051 - val_loss: 17.0399\n",
      "Epoch 302/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.0062\n",
      "Epoch 302: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1652 - val_loss: 14.4496\n",
      "Epoch 303/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.7714\n",
      "Epoch 303: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7804 - val_loss: 13.9183\n",
      "Epoch 304/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.0642\n",
      "Epoch 304: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1034 - val_loss: 14.2696\n",
      "Epoch 305/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.9685\n",
      "Epoch 305: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4701 - val_loss: 13.1980\n",
      "Epoch 306/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.2418\n",
      "Epoch 306: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1881 - val_loss: 16.5480\n",
      "Epoch 307/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.2325\n",
      "Epoch 307: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0928 - val_loss: 13.9014\n",
      "Epoch 308/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.9384\n",
      "Epoch 308: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0626 - val_loss: 19.8923\n",
      "Epoch 309/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.8665\n",
      "Epoch 309: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8980 - val_loss: 20.1624\n",
      "Epoch 310/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.4126\n",
      "Epoch 310: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3390 - val_loss: 20.1105\n",
      "Epoch 311/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.9197\n",
      "Epoch 311: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7579 - val_loss: 20.8347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 312/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.7738\n",
      "Epoch 312: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8149 - val_loss: 17.3700\n",
      "Epoch 313/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.7737\n",
      "Epoch 313: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9334 - val_loss: 18.8014\n",
      "Epoch 314/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.9712\n",
      "Epoch 314: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9946 - val_loss: 15.5307\n",
      "Epoch 315/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.0450\n",
      "Epoch 315: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0638 - val_loss: 18.2694\n",
      "Epoch 316/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.9413\n",
      "Epoch 316: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9906 - val_loss: 12.6948\n",
      "Epoch 317/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.7326\n",
      "Epoch 317: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7323 - val_loss: 15.6840\n",
      "Epoch 318/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.1572\n",
      "Epoch 318: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1233 - val_loss: 15.4484\n",
      "Epoch 319/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.1769\n",
      "Epoch 319: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0503 - val_loss: 16.4903\n",
      "Epoch 320/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.0937\n",
      "Epoch 320: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9509 - val_loss: 13.8297\n",
      "Epoch 321/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.5558\n",
      "Epoch 321: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5398 - val_loss: 13.8827\n",
      "Epoch 322/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.1063\n",
      "Epoch 322: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9574 - val_loss: 14.9480\n",
      "Epoch 323/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.2852\n",
      "Epoch 323: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2091 - val_loss: 15.1316\n",
      "Epoch 324/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.5346\n",
      "Epoch 324: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3693 - val_loss: 12.7129\n",
      "Epoch 325/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.7284\n",
      "Epoch 325: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8238 - val_loss: 14.4844\n",
      "Epoch 326/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.0257\n",
      "Epoch 326: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0555 - val_loss: 17.2017\n",
      "Epoch 327/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.0470\n",
      "Epoch 327: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8623 - val_loss: 15.7276\n",
      "Epoch 328/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.5039\n",
      "Epoch 328: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5229 - val_loss: 14.3216\n",
      "Epoch 329/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.7435\n",
      "Epoch 329: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6664 - val_loss: 17.3438\n",
      "Epoch 330/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.8290\n",
      "Epoch 330: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8200 - val_loss: 13.5768\n",
      "Epoch 331/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.3033\n",
      "Epoch 331: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1470 - val_loss: 13.8071\n",
      "Epoch 332/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.8367\n",
      "Epoch 332: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0593 - val_loss: 15.4960\n",
      "Epoch 333/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.9222\n",
      "Epoch 333: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0955 - val_loss: 16.8722\n",
      "Epoch 334/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.0197\n",
      "Epoch 334: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9454 - val_loss: 15.9919\n",
      "Epoch 335/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.8235\n",
      "Epoch 335: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8235 - val_loss: 14.2124\n",
      "Epoch 336/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.5403\n",
      "Epoch 336: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7583 - val_loss: 16.1271\n",
      "Epoch 337/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.3107\n",
      "Epoch 337: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2267 - val_loss: 17.6809\n",
      "Epoch 338/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.5450\n",
      "Epoch 338: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5457 - val_loss: 17.4740\n",
      "Epoch 339/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.5100\n",
      "Epoch 339: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6313 - val_loss: 17.7444\n",
      "Epoch 340/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 5.4563\n",
      "Epoch 340: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5720 - val_loss: 16.7835\n",
      "Epoch 341/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.9424\n",
      "Epoch 341: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0317 - val_loss: 13.4301\n",
      "Epoch 342/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.6964\n",
      "Epoch 342: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7370 - val_loss: 17.2737\n",
      "Epoch 343/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.1369\n",
      "Epoch 343: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1652 - val_loss: 15.5383\n",
      "Epoch 344/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.5372\n",
      "Epoch 344: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5558 - val_loss: 17.8755\n",
      "Epoch 345/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.8242\n",
      "Epoch 345: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8031 - val_loss: 19.4961\n",
      "Epoch 346/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.1079\n",
      "Epoch 346: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1637 - val_loss: 16.8660\n",
      "Epoch 347/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.5832\n",
      "Epoch 347: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6934 - val_loss: 15.1426\n",
      "Epoch 348/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.8911\n",
      "Epoch 348: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6564 - val_loss: 15.3896\n",
      "Epoch 349/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.7321\n",
      "Epoch 349: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7114 - val_loss: 14.9217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.2854\n",
      "Epoch 350: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4701 - val_loss: 15.5820\n",
      "Epoch 351/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.8484\n",
      "Epoch 351: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8562 - val_loss: 20.4900\n",
      "Epoch 352/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.6765\n",
      "Epoch 352: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6299 - val_loss: 15.5922\n",
      "Epoch 353/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.4622\n",
      "Epoch 353: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5490 - val_loss: 14.9116\n",
      "Epoch 354/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.6339\n",
      "Epoch 354: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6869 - val_loss: 14.7350\n",
      "Epoch 355/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.2708\n",
      "Epoch 355: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2071 - val_loss: 16.7174\n",
      "Epoch 356/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.9721\n",
      "Epoch 356: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6486 - val_loss: 15.7901\n",
      "Epoch 357/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.8072\n",
      "Epoch 357: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7920 - val_loss: 16.3567\n",
      "Epoch 358/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.9726\n",
      "Epoch 358: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9967 - val_loss: 18.1741\n",
      "Epoch 359/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.4544\n",
      "Epoch 359: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3501 - val_loss: 19.8846\n",
      "Epoch 360/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.8325\n",
      "Epoch 360: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7540 - val_loss: 14.4988\n",
      "Epoch 361/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.8786\n",
      "Epoch 361: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7729 - val_loss: 19.6520\n",
      "Epoch 362/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.3398\n",
      "Epoch 362: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1646 - val_loss: 17.5399\n",
      "Epoch 363/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.7946\n",
      "Epoch 363: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8033 - val_loss: 16.2018\n",
      "Epoch 364/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.6864\n",
      "Epoch 364: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6022 - val_loss: 18.0710\n",
      "Epoch 365/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.7366\n",
      "Epoch 365: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7809 - val_loss: 16.4412\n",
      "Epoch 366/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.8746\n",
      "Epoch 366: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7818 - val_loss: 17.4210\n",
      "Epoch 367/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.8723\n",
      "Epoch 367: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8914 - val_loss: 19.1834\n",
      "Epoch 368/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.2939\n",
      "Epoch 368: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1909 - val_loss: 20.3659\n",
      "Epoch 369/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.4122\n",
      "Epoch 369: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4072 - val_loss: 16.9652\n",
      "Epoch 370/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.6201\n",
      "Epoch 370: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7020 - val_loss: 17.0275\n",
      "Epoch 371/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.7627\n",
      "Epoch 371: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0111 - val_loss: 18.6421\n",
      "Epoch 372/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.8116\n",
      "Epoch 372: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7141 - val_loss: 15.9250\n",
      "Epoch 373/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.8174\n",
      "Epoch 373: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6165 - val_loss: 16.5242\n",
      "Epoch 374/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.3859\n",
      "Epoch 374: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4126 - val_loss: 17.3884\n",
      "Epoch 375/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.3492\n",
      "Epoch 375: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3492 - val_loss: 14.3022\n",
      "Epoch 376/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.5672\n",
      "Epoch 376: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5355 - val_loss: 18.9060\n",
      "Epoch 377/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.4963\n",
      "Epoch 377: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6591 - val_loss: 15.3978\n",
      "Epoch 378/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.6236\n",
      "Epoch 378: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6475 - val_loss: 14.6400\n",
      "Epoch 379/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.7985\n",
      "Epoch 379: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6353 - val_loss: 17.2277\n",
      "Epoch 380/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.8793\n",
      "Epoch 380: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8085 - val_loss: 18.4326\n",
      "Epoch 381/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.4674\n",
      "Epoch 381: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5003 - val_loss: 17.9202\n",
      "Epoch 382/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.2281\n",
      "Epoch 382: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2632 - val_loss: 13.5248\n",
      "Epoch 383/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.8115\n",
      "Epoch 383: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5965 - val_loss: 15.8688\n",
      "Epoch 384/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 6.0257\n",
      "Epoch 384: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1645 - val_loss: 17.3137\n",
      "Epoch 385/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.6411\n",
      "Epoch 385: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6607 - val_loss: 17.1667\n",
      "Epoch 386/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.7803\n",
      "Epoch 386: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5250 - val_loss: 18.2051\n",
      "Epoch 387/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.1613\n",
      "Epoch 387: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2522 - val_loss: 15.5845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.4477\n",
      "Epoch 388: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6495 - val_loss: 15.7662\n",
      "Epoch 389/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.0642\n",
      "Epoch 389: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1120 - val_loss: 18.4785\n",
      "Epoch 390/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.8525\n",
      "Epoch 390: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0567 - val_loss: 16.6948\n",
      "Epoch 391/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.5321\n",
      "Epoch 391: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5245 - val_loss: 16.6821\n",
      "Epoch 392/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.9257\n",
      "Epoch 392: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9218 - val_loss: 16.8693\n",
      "Epoch 393/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.3705\n",
      "Epoch 393: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2713 - val_loss: 20.2327\n",
      "Epoch 394/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.5735\n",
      "Epoch 394: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5216 - val_loss: 18.2938\n",
      "Epoch 395/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.2686\n",
      "Epoch 395: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3088 - val_loss: 14.2472\n",
      "Epoch 396/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.1869\n",
      "Epoch 396: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0873 - val_loss: 17.7463\n",
      "Epoch 397/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.2581\n",
      "Epoch 397: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1002 - val_loss: 16.4498\n",
      "Epoch 398/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.5719\n",
      "Epoch 398: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6873 - val_loss: 15.2687\n",
      "Epoch 399/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 7.2062\n",
      "Epoch 399: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2316 - val_loss: 17.9784\n",
      "Epoch 400/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.2745\n",
      "Epoch 400: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2697 - val_loss: 14.1077\n",
      "Epoch 401/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.6587\n",
      "Epoch 401: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5836 - val_loss: 17.6143\n",
      "Epoch 402/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.2788\n",
      "Epoch 402: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2655 - val_loss: 18.2820\n",
      "Epoch 403/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.7237\n",
      "Epoch 403: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7330 - val_loss: 14.6912\n",
      "Epoch 404/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.5718\n",
      "Epoch 404: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5625 - val_loss: 19.2566\n",
      "Epoch 405/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.8748\n",
      "Epoch 405: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8748 - val_loss: 17.9429\n",
      "Epoch 406/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.4039\n",
      "Epoch 406: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4058 - val_loss: 17.3836\n",
      "Epoch 407/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.3367\n",
      "Epoch 407: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4951 - val_loss: 13.4922\n",
      "Epoch 408/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.2044\n",
      "Epoch 408: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2563 - val_loss: 17.0774\n",
      "Epoch 409/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 4.9804\n",
      "Epoch 409: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9301 - val_loss: 16.6413\n",
      "Epoch 410/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.6875\n",
      "Epoch 410: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8214 - val_loss: 14.9277\n",
      "Epoch 411/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.9645\n",
      "Epoch 411: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9408 - val_loss: 16.3139\n",
      "Epoch 412/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.4092\n",
      "Epoch 412: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3884 - val_loss: 14.8067\n",
      "Epoch 413/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.9325\n",
      "Epoch 413: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8803 - val_loss: 16.1403\n",
      "Epoch 414/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.2624\n",
      "Epoch 414: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2893 - val_loss: 16.8858\n",
      "Epoch 415/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.0113\n",
      "Epoch 415: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8803 - val_loss: 16.2342\n",
      "Epoch 416/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.6979\n",
      "Epoch 416: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6979 - val_loss: 15.7532\n",
      "Epoch 417/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.4470\n",
      "Epoch 417: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3739 - val_loss: 13.8818\n",
      "Epoch 418/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.3263\n",
      "Epoch 418: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.3416 - val_loss: 14.9903\n",
      "Epoch 419/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.4476\n",
      "Epoch 419: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4261 - val_loss: 16.0447\n",
      "Epoch 420/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 5.1928\n",
      "Epoch 420: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.3628 - val_loss: 16.1214\n",
      "Epoch 421/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 5.4412\n",
      "Epoch 421: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.4309 - val_loss: 15.6203\n",
      "Epoch 422/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 5.8286\n",
      "Epoch 422: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.6811 - val_loss: 15.1183\n",
      "Epoch 423/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 5.4089\n",
      "Epoch 423: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.4066 - val_loss: 16.5686\n",
      "Epoch 424/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.1498\n",
      "Epoch 424: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1498 - val_loss: 13.6769\n",
      "Epoch 425/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 5.1986\n",
      "Epoch 425: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.0246 - val_loss: 20.7704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.8490\n",
      "Epoch 426: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9246 - val_loss: 17.6772\n",
      "Epoch 427/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.7797\n",
      "Epoch 427: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8610 - val_loss: 16.6068\n",
      "Epoch 428/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 5.2408\n",
      "Epoch 428: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.2531 - val_loss: 14.0847\n",
      "Epoch 429/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 5.3874\n",
      "Epoch 429: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.6489 - val_loss: 18.5404\n",
      "Epoch 430/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.5468\n",
      "Epoch 430: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5843 - val_loss: 16.0018\n",
      "Epoch 431/700\n",
      "60/84 [====================>.........] - ETA: 0s - loss: 5.1028\n",
      "Epoch 431: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.3390 - val_loss: 21.7470\n",
      "Epoch 432/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.5273\n",
      "Epoch 432: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5432 - val_loss: 15.6907\n",
      "Epoch 433/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.9367\n",
      "Epoch 433: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8971 - val_loss: 14.9304\n",
      "Epoch 434/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.2074\n",
      "Epoch 434: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2649 - val_loss: 18.1916\n",
      "Epoch 435/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.3812\n",
      "Epoch 435: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3161 - val_loss: 20.1019\n",
      "Epoch 436/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.8324\n",
      "Epoch 436: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5614 - val_loss: 18.1730\n",
      "Epoch 437/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.0585\n",
      "Epoch 437: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1071 - val_loss: 19.8916\n",
      "Epoch 438/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.9495\n",
      "Epoch 438: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8994 - val_loss: 18.4091\n",
      "Epoch 439/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.4909\n",
      "Epoch 439: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5816 - val_loss: 19.8778\n",
      "Epoch 440/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.5394\n",
      "Epoch 440: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5771 - val_loss: 14.3720\n",
      "Epoch 441/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.2255\n",
      "Epoch 441: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1908 - val_loss: 14.6180\n",
      "Epoch 442/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.2247\n",
      "Epoch 442: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2582 - val_loss: 15.6727\n",
      "Epoch 443/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.6983\n",
      "Epoch 443: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6433 - val_loss: 16.0455\n",
      "Epoch 444/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.9064\n",
      "Epoch 444: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8021 - val_loss: 16.3761\n",
      "Epoch 445/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.9357\n",
      "Epoch 445: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9114 - val_loss: 15.4193\n",
      "Epoch 446/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.4028\n",
      "Epoch 446: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3470 - val_loss: 18.8906\n",
      "Epoch 447/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.3118\n",
      "Epoch 447: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2502 - val_loss: 17.1626\n",
      "Epoch 448/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.0950\n",
      "Epoch 448: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3807 - val_loss: 17.7880\n",
      "Epoch 449/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.4510\n",
      "Epoch 449: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4815 - val_loss: 15.7379\n",
      "Epoch 450/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 4.8517\n",
      "Epoch 450: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2304 - val_loss: 18.3430\n",
      "Epoch 451/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.7141\n",
      "Epoch 451: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5706 - val_loss: 16.9653\n",
      "Epoch 452/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.9662\n",
      "Epoch 452: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0228 - val_loss: 14.0102\n",
      "Epoch 453/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.0954\n",
      "Epoch 453: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0527 - val_loss: 15.1459\n",
      "Epoch 454/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 5.2938\n",
      "Epoch 454: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.2376 - val_loss: 18.0673\n",
      "Epoch 455/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.1760\n",
      "Epoch 455: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.1760 - val_loss: 18.4999\n",
      "Epoch 456/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 4.9555\n",
      "Epoch 456: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.0734 - val_loss: 15.8266\n",
      "Epoch 457/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.3576\n",
      "Epoch 457: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.3497 - val_loss: 16.6231\n",
      "Epoch 458/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 5.3645\n",
      "Epoch 458: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.4002 - val_loss: 14.4816\n",
      "Epoch 459/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.2086\n",
      "Epoch 459: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2294 - val_loss: 17.2001\n",
      "Epoch 460/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.1501\n",
      "Epoch 460: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1150 - val_loss: 17.3735\n",
      "Epoch 461/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.7069\n",
      "Epoch 461: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6719 - val_loss: 17.0787\n",
      "Epoch 462/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.4012\n",
      "Epoch 462: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4012 - val_loss: 15.6799\n",
      "Epoch 463/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.5699\n",
      "Epoch 463: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6047 - val_loss: 16.9496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.5273\n",
      "Epoch 464: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4697 - val_loss: 17.0175\n",
      "Epoch 465/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.1664\n",
      "Epoch 465: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1777 - val_loss: 20.4974\n",
      "Epoch 466/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.2295\n",
      "Epoch 466: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2471 - val_loss: 15.6757\n",
      "Epoch 467/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.1112\n",
      "Epoch 467: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0822 - val_loss: 16.3869\n",
      "Epoch 468/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 5.3097\n",
      "Epoch 468: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3079 - val_loss: 16.4156\n",
      "Epoch 469/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.0000\n",
      "Epoch 469: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0087 - val_loss: 15.9710\n",
      "Epoch 470/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.1266\n",
      "Epoch 470: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1450 - val_loss: 18.4446\n",
      "Epoch 471/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.3375\n",
      "Epoch 471: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2093 - val_loss: 14.5219\n",
      "Epoch 472/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.0566\n",
      "Epoch 472: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0470 - val_loss: 17.7570\n",
      "Epoch 473/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.5014\n",
      "Epoch 473: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4775 - val_loss: 13.5194\n",
      "Epoch 474/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 4.9127\n",
      "Epoch 474: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0691 - val_loss: 16.5809\n",
      "Epoch 475/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.2048\n",
      "Epoch 475: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2226 - val_loss: 16.3662\n",
      "Epoch 476/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.2818\n",
      "Epoch 476: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3796 - val_loss: 16.2589\n",
      "Epoch 477/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.5709\n",
      "Epoch 477: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4489 - val_loss: 15.8187\n",
      "Epoch 478/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 4.9240\n",
      "Epoch 478: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0299 - val_loss: 18.0589\n",
      "Epoch 479/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.6550\n",
      "Epoch 479: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.8239 - val_loss: 19.1665\n",
      "Epoch 480/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 4.8994\n",
      "Epoch 480: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.1319 - val_loss: 16.1022\n",
      "Epoch 481/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.3374\n",
      "Epoch 481: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3223 - val_loss: 17.1055\n",
      "Epoch 482/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.2697\n",
      "Epoch 482: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1620 - val_loss: 14.9587\n",
      "Epoch 483/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.2182\n",
      "Epoch 483: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1948 - val_loss: 18.3353\n",
      "Epoch 484/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 4.6700\n",
      "Epoch 484: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6725 - val_loss: 16.5538\n",
      "Epoch 485/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.2721\n",
      "Epoch 485: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2721 - val_loss: 14.7907\n",
      "Epoch 486/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.2735\n",
      "Epoch 486: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2791 - val_loss: 18.7795\n",
      "Epoch 487/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.1251\n",
      "Epoch 487: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2021 - val_loss: 16.6414\n",
      "Epoch 488/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.4657\n",
      "Epoch 488: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4214 - val_loss: 19.4534\n",
      "Epoch 489/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.0518\n",
      "Epoch 489: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0165 - val_loss: 14.2583\n",
      "Epoch 490/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.7929\n",
      "Epoch 490: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7156 - val_loss: 16.1166\n",
      "Epoch 491/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.4326\n",
      "Epoch 491: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3212 - val_loss: 17.5940\n",
      "Epoch 492/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.4368\n",
      "Epoch 492: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4931 - val_loss: 14.4638\n",
      "Epoch 493/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.7867\n",
      "Epoch 493: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7947 - val_loss: 17.9684\n",
      "Epoch 494/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.1186\n",
      "Epoch 494: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0125 - val_loss: 18.3087\n",
      "Epoch 495/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.1623\n",
      "Epoch 495: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0129 - val_loss: 16.7155\n",
      "Epoch 496/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.6741\n",
      "Epoch 496: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4973 - val_loss: 16.5664\n",
      "Epoch 497/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.0163\n",
      "Epoch 497: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0617 - val_loss: 19.0257\n",
      "Epoch 498/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.4478\n",
      "Epoch 498: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5139 - val_loss: 17.8381\n",
      "Epoch 499/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 5.1514\n",
      "Epoch 499: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1992 - val_loss: 15.6461\n",
      "Epoch 500/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.2035\n",
      "Epoch 500: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2666 - val_loss: 14.4773\n",
      "Epoch 501/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.3051\n",
      "Epoch 501: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3051 - val_loss: 17.3833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 502/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 4.5958\n",
      "Epoch 502: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7879 - val_loss: 15.6831\n",
      "Epoch 503/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.3193\n",
      "Epoch 503: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2605 - val_loss: 18.7835\n",
      "Epoch 504/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.5284\n",
      "Epoch 504: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3961 - val_loss: 16.1465\n",
      "Epoch 505/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.9510\n",
      "Epoch 505: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9510 - val_loss: 19.8291\n",
      "Epoch 506/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 6.0430\n",
      "Epoch 506: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.9138 - val_loss: 19.0896\n",
      "Epoch 507/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 5.4156\n",
      "Epoch 507: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.3340 - val_loss: 17.1297\n",
      "Epoch 508/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.2568\n",
      "Epoch 508: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2568 - val_loss: 16.0615\n",
      "Epoch 509/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 4.9539\n",
      "Epoch 509: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.0217 - val_loss: 17.3387\n",
      "Epoch 510/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.9044\n",
      "Epoch 510: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8742 - val_loss: 18.3435\n",
      "Epoch 511/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.1541\n",
      "Epoch 511: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.1541 - val_loss: 14.6496\n",
      "Epoch 512/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 5.2229\n",
      "Epoch 512: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.3189 - val_loss: 17.1163\n",
      "Epoch 513/700\n",
      "60/84 [====================>.........] - ETA: 0s - loss: 4.8191\n",
      "Epoch 513: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.9014 - val_loss: 20.1156\n",
      "Epoch 514/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.0242\n",
      "Epoch 514: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0339 - val_loss: 17.5450\n",
      "Epoch 515/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 5.0969\n",
      "Epoch 515: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.3729 - val_loss: 15.8510\n",
      "Epoch 516/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.7641\n",
      "Epoch 516: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7520 - val_loss: 16.8052\n",
      "Epoch 517/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.1683\n",
      "Epoch 517: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2026 - val_loss: 19.7559\n",
      "Epoch 518/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.8296\n",
      "Epoch 518: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8345 - val_loss: 16.7102\n",
      "Epoch 519/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 5.2930\n",
      "Epoch 519: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.2852 - val_loss: 16.3934\n",
      "Epoch 520/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 5.0205\n",
      "Epoch 520: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.0228 - val_loss: 16.1034\n",
      "Epoch 521/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.4421\n",
      "Epoch 521: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4636 - val_loss: 16.7786\n",
      "Epoch 522/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 4.6894\n",
      "Epoch 522: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6894 - val_loss: 18.2530\n",
      "Epoch 523/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 5.2935\n",
      "Epoch 523: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.4808 - val_loss: 17.4224\n",
      "Epoch 524/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 5.1899\n",
      "Epoch 524: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.0618 - val_loss: 16.9073\n",
      "Epoch 525/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.6348\n",
      "Epoch 525: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6380 - val_loss: 16.0847\n",
      "Epoch 526/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 4.8041\n",
      "Epoch 526: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8568 - val_loss: 17.3558\n",
      "Epoch 527/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.7346\n",
      "Epoch 527: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.6733 - val_loss: 16.8434\n",
      "Epoch 528/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.9565\n",
      "Epoch 528: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9938 - val_loss: 18.8498\n",
      "Epoch 529/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.1366\n",
      "Epoch 529: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1432 - val_loss: 19.5656\n",
      "Epoch 530/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.2706\n",
      "Epoch 530: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.2706 - val_loss: 13.6627\n",
      "Epoch 531/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.4864\n",
      "Epoch 531: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4556 - val_loss: 17.3992\n",
      "Epoch 532/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.7958\n",
      "Epoch 532: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7680 - val_loss: 15.3103\n",
      "Epoch 533/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 5.1956\n",
      "Epoch 533: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.2993 - val_loss: 17.0843\n",
      "Epoch 534/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.8574\n",
      "Epoch 534: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8574 - val_loss: 14.2342\n",
      "Epoch 535/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.5949\n",
      "Epoch 535: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5949 - val_loss: 18.5865\n",
      "Epoch 536/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 5.5150\n",
      "Epoch 536: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.6365 - val_loss: 17.2758\n",
      "Epoch 537/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 5.0606\n",
      "Epoch 537: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.0999 - val_loss: 17.1900\n",
      "Epoch 538/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 5.5114\n",
      "Epoch 538: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.5659 - val_loss: 13.3758\n",
      "Epoch 539/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.1998\n",
      "Epoch 539: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1510 - val_loss: 16.2448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 540/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 4.9295\n",
      "Epoch 540: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.9671 - val_loss: 19.3483\n",
      "Epoch 541/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 5.0081\n",
      "Epoch 541: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.1649 - val_loss: 15.8637\n",
      "Epoch 542/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 4.7857\n",
      "Epoch 542: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6944 - val_loss: 15.4610\n",
      "Epoch 543/700\n",
      "55/84 [==================>...........] - ETA: 0s - loss: 5.0729\n",
      "Epoch 543: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.1842 - val_loss: 17.4612\n",
      "Epoch 544/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 5.2260\n",
      "Epoch 544: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.2651 - val_loss: 18.7241\n",
      "Epoch 545/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 4.7688\n",
      "Epoch 545: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7688 - val_loss: 19.4526\n",
      "Epoch 546/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.0135\n",
      "Epoch 546: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.9816 - val_loss: 18.4097\n",
      "Epoch 547/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.9940\n",
      "Epoch 547: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9759 - val_loss: 19.3783\n",
      "Epoch 548/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 4.9355\n",
      "Epoch 548: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9355 - val_loss: 19.5015\n",
      "Epoch 549/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.4970\n",
      "Epoch 549: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4710 - val_loss: 19.5171\n",
      "Epoch 550/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 4.9066\n",
      "Epoch 550: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8911 - val_loss: 19.8502\n",
      "Epoch 551/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.8892\n",
      "Epoch 551: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8658 - val_loss: 16.5674\n",
      "Epoch 552/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.3731\n",
      "Epoch 552: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3612 - val_loss: 18.4810\n",
      "Epoch 553/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 4.7287\n",
      "Epoch 553: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9209 - val_loss: 17.5290\n",
      "Epoch 554/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.2265\n",
      "Epoch 554: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3658 - val_loss: 16.9360\n",
      "Epoch 555/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 4.8377\n",
      "Epoch 555: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8406 - val_loss: 16.7684\n",
      "Epoch 556/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 4.8291\n",
      "Epoch 556: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8183 - val_loss: 15.8475\n",
      "Epoch 557/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.2108\n",
      "Epoch 557: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1579 - val_loss: 18.0395\n",
      "Epoch 558/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.0488\n",
      "Epoch 558: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0334 - val_loss: 18.0754\n",
      "Epoch 559/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.4981\n",
      "Epoch 559: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4580 - val_loss: 19.8143\n",
      "Epoch 560/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.5905\n",
      "Epoch 560: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4337 - val_loss: 17.1668\n",
      "Epoch 561/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.3460\n",
      "Epoch 561: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1832 - val_loss: 17.7509\n",
      "Epoch 562/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.3068\n",
      "Epoch 562: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4483 - val_loss: 14.1614\n",
      "Epoch 563/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 5.3378\n",
      "Epoch 563: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.1964 - val_loss: 15.6417\n",
      "Epoch 564/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.9282\n",
      "Epoch 564: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.9091 - val_loss: 15.6202\n",
      "Epoch 565/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.8568\n",
      "Epoch 565: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8380 - val_loss: 18.0300\n",
      "Epoch 566/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 4.7281\n",
      "Epoch 566: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8892 - val_loss: 15.2769\n",
      "Epoch 567/700\n",
      "60/84 [====================>.........] - ETA: 0s - loss: 5.2823\n",
      "Epoch 567: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.4810 - val_loss: 17.8237\n",
      "Epoch 568/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.6451\n",
      "Epoch 568: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5438 - val_loss: 17.7567\n",
      "Epoch 569/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 4.9422\n",
      "Epoch 569: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9081 - val_loss: 17.9815\n",
      "Epoch 570/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.1791\n",
      "Epoch 570: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0774 - val_loss: 17.9570\n",
      "Epoch 571/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 4.8465\n",
      "Epoch 571: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8275 - val_loss: 18.0965\n",
      "Epoch 572/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 4.9746\n",
      "Epoch 572: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1450 - val_loss: 16.4984\n",
      "Epoch 573/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.0353\n",
      "Epoch 573: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0571 - val_loss: 17.1169\n",
      "Epoch 574/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 4.8711\n",
      "Epoch 574: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9174 - val_loss: 19.2228\n",
      "Epoch 575/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 4.8256\n",
      "Epoch 575: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8395 - val_loss: 16.1855\n",
      "Epoch 576/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 4.7937\n",
      "Epoch 576: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8487 - val_loss: 14.8796\n",
      "Epoch 577/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 4.6409\n",
      "Epoch 577: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8389 - val_loss: 14.4601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 578/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.4947\n",
      "Epoch 578: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4361 - val_loss: 17.0658\n",
      "Epoch 579/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.2246\n",
      "Epoch 579: val_loss did not improve from 12.47151\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2850 - val_loss: 18.0285\n",
      "\n",
      " ---------- 3 ---------- \n",
      "\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 22, 8, 360)        3600      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 7, 2, 360)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " reshape_10 (Reshape)        (None, 7, 720)            0         \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 7, 720)            0         \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 180)               648720    \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 180)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 181       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 652,501\n",
      "Trainable params: 652,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 40.8285\n",
      "Epoch 1: val_loss improved from inf to 66.61422, saving model to ./model_save\\4_fold_001-66.6142.hdf5\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 40.7122 - val_loss: 66.6142\n",
      "Epoch 2/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 35.0344\n",
      "Epoch 2: val_loss improved from 66.61422 to 63.76865, saving model to ./model_save\\4_fold_002-63.7687.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 34.2508 - val_loss: 63.7687\n",
      "Epoch 3/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 33.0319\n",
      "Epoch 3: val_loss improved from 63.76865 to 62.19869, saving model to ./model_save\\4_fold_003-62.1987.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 32.1654 - val_loss: 62.1987\n",
      "Epoch 4/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 29.3880\n",
      "Epoch 4: val_loss improved from 62.19869 to 57.05981, saving model to ./model_save\\4_fold_004-57.0598.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 28.6629 - val_loss: 57.0598\n",
      "Epoch 5/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 27.4774\n",
      "Epoch 5: val_loss improved from 57.05981 to 54.82502, saving model to ./model_save\\4_fold_005-54.8250.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 26.9455 - val_loss: 54.8250\n",
      "Epoch 6/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 25.4303\n",
      "Epoch 6: val_loss did not improve from 54.82502\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 25.9496 - val_loss: 54.8491\n",
      "Epoch 7/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 24.5099\n",
      "Epoch 7: val_loss improved from 54.82502 to 52.36193, saving model to ./model_save\\4_fold_007-52.3619.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 24.4189 - val_loss: 52.3619\n",
      "Epoch 8/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 22.3406\n",
      "Epoch 8: val_loss improved from 52.36193 to 49.75698, saving model to ./model_save\\4_fold_008-49.7570.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 22.7440 - val_loss: 49.7570\n",
      "Epoch 9/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 22.3817\n",
      "Epoch 9: val_loss improved from 49.75698 to 49.45438, saving model to ./model_save\\4_fold_009-49.4544.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 22.2885 - val_loss: 49.4544\n",
      "Epoch 10/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 21.0679\n",
      "Epoch 10: val_loss improved from 49.45438 to 48.12744, saving model to ./model_save\\4_fold_010-48.1274.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 21.1174 - val_loss: 48.1274\n",
      "Epoch 11/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 20.0907\n",
      "Epoch 11: val_loss improved from 48.12744 to 46.68848, saving model to ./model_save\\4_fold_011-46.6885.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 20.7377 - val_loss: 46.6885\n",
      "Epoch 12/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 19.4406\n",
      "Epoch 12: val_loss improved from 46.68848 to 46.20562, saving model to ./model_save\\4_fold_012-46.2056.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.8268 - val_loss: 46.2056\n",
      "Epoch 13/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 19.9368\n",
      "Epoch 13: val_loss did not improve from 46.20562\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.7301 - val_loss: 46.7837\n",
      "Epoch 14/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 19.6329\n",
      "Epoch 14: val_loss did not improve from 46.20562\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 19.3144 - val_loss: 46.7450\n",
      "Epoch 15/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 19.1583\n",
      "Epoch 15: val_loss did not improve from 46.20562\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.5966 - val_loss: 46.9036\n",
      "Epoch 16/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 18.0515\n",
      "Epoch 16: val_loss did not improve from 46.20562\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.0024 - val_loss: 47.4343\n",
      "Epoch 17/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 17.8491\n",
      "Epoch 17: val_loss did not improve from 46.20562\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 17.3868 - val_loss: 47.1696\n",
      "Epoch 18/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 17.6666\n",
      "Epoch 18: val_loss improved from 46.20562 to 41.57196, saving model to ./model_save\\4_fold_018-41.5720.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.8150 - val_loss: 41.5720\n",
      "Epoch 19/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 17.6136\n",
      "Epoch 19: val_loss did not improve from 41.57196\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.4228 - val_loss: 49.0618\n",
      "Epoch 20/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 17.0019\n",
      "Epoch 20: val_loss did not improve from 41.57196\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.8068 - val_loss: 45.8921\n",
      "Epoch 21/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 16.7767\n",
      "Epoch 21: val_loss did not improve from 41.57196\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.6135 - val_loss: 43.4915\n",
      "Epoch 22/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 15.5689\n",
      "Epoch 22: val_loss improved from 41.57196 to 41.34721, saving model to ./model_save\\4_fold_022-41.3472.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.6972 - val_loss: 41.3472\n",
      "Epoch 23/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 16.4267\n",
      "Epoch 23: val_loss improved from 41.34721 to 39.65539, saving model to ./model_save\\4_fold_023-39.6554.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.7865 - val_loss: 39.6554\n",
      "Epoch 24/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 15.6736\n",
      "Epoch 24: val_loss did not improve from 39.65539\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.0095 - val_loss: 42.2153\n",
      "Epoch 25/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 16.1975\n",
      "Epoch 25: val_loss did not improve from 39.65539\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.8912 - val_loss: 39.9943\n",
      "Epoch 26/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 15.0279\n",
      "Epoch 26: val_loss improved from 39.65539 to 38.84756, saving model to ./model_save\\4_fold_026-38.8476.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 15.3150 - val_loss: 38.8476\n",
      "Epoch 27/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 14.9480\n",
      "Epoch 27: val_loss did not improve from 38.84756\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.8887 - val_loss: 40.5887\n",
      "Epoch 28/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 14.7680\n",
      "Epoch 28: val_loss did not improve from 38.84756\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.5699 - val_loss: 38.8683\n",
      "Epoch 29/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 14.8040\n",
      "Epoch 29: val_loss did not improve from 38.84756\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.1542 - val_loss: 52.1577\n",
      "Epoch 30/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 14.9975\n",
      "Epoch 30: val_loss did not improve from 38.84756\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 15.0185 - val_loss: 42.4334\n",
      "Epoch 31/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 14.2576\n",
      "Epoch 31: val_loss improved from 38.84756 to 34.67603, saving model to ./model_save\\4_fold_031-34.6760.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.5112 - val_loss: 34.6760\n",
      "Epoch 32/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 14.9807\n",
      "Epoch 32: val_loss improved from 34.67603 to 34.65461, saving model to ./model_save\\4_fold_032-34.6546.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.9188 - val_loss: 34.6546\n",
      "Epoch 33/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 14.8980\n",
      "Epoch 33: val_loss did not improve from 34.65461\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.0197 - val_loss: 39.3500\n",
      "Epoch 34/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 13.5533\n",
      "Epoch 34: val_loss did not improve from 34.65461\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.5106 - val_loss: 36.2566\n",
      "Epoch 35/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 13.0744\n",
      "Epoch 35: val_loss did not improve from 34.65461\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.5909 - val_loss: 36.1820\n",
      "Epoch 36/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 13.0628\n",
      "Epoch 36: val_loss did not improve from 34.65461\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.2833 - val_loss: 38.4998\n",
      "Epoch 37/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 13.3855\n",
      "Epoch 37: val_loss did not improve from 34.65461\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.3701 - val_loss: 37.2524\n",
      "Epoch 38/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 13.2879\n",
      "Epoch 38: val_loss did not improve from 34.65461\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.2867 - val_loss: 36.8741\n",
      "Epoch 39/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 13.8941\n",
      "Epoch 39: val_loss did not improve from 34.65461\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.8921 - val_loss: 39.6465\n",
      "Epoch 40/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 13.8637\n",
      "Epoch 40: val_loss did not improve from 34.65461\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.0684 - val_loss: 35.0046\n",
      "Epoch 41/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 12.6727\n",
      "Epoch 41: val_loss did not improve from 34.65461\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.4168 - val_loss: 35.4237\n",
      "Epoch 42/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 12.8113\n",
      "Epoch 42: val_loss did not improve from 34.65461\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.9964 - val_loss: 35.5029\n",
      "Epoch 43/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 12.4869\n",
      "Epoch 43: val_loss improved from 34.65461 to 34.12102, saving model to ./model_save\\4_fold_043-34.1210.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.1826 - val_loss: 34.1210\n",
      "Epoch 44/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 12.4585\n",
      "Epoch 44: val_loss did not improve from 34.12102\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.7341 - val_loss: 37.6254\n",
      "Epoch 45/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 12.2054\n",
      "Epoch 45: val_loss did not improve from 34.12102\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.2369 - val_loss: 37.8573\n",
      "Epoch 46/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 12.0459\n",
      "Epoch 46: val_loss improved from 34.12102 to 32.60159, saving model to ./model_save\\4_fold_046-32.6016.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.4558 - val_loss: 32.6016\n",
      "Epoch 47/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 13.6321\n",
      "Epoch 47: val_loss did not improve from 32.60159\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.5016 - val_loss: 32.8629\n",
      "Epoch 48/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 13.2238\n",
      "Epoch 48: val_loss did not improve from 32.60159\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.9448 - val_loss: 33.9337\n",
      "Epoch 49/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 12.5145\n",
      "Epoch 49: val_loss improved from 32.60159 to 31.69409, saving model to ./model_save\\4_fold_049-31.6941.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.7003 - val_loss: 31.6941\n",
      "Epoch 50/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 12.5217\n",
      "Epoch 50: val_loss improved from 31.69409 to 30.68292, saving model to ./model_save\\4_fold_050-30.6829.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.6152 - val_loss: 30.6829\n",
      "Epoch 51/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 12.9425\n",
      "Epoch 51: val_loss did not improve from 30.68292\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 12.5536 - val_loss: 32.5074\n",
      "Epoch 52/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 11.7380\n",
      "Epoch 52: val_loss did not improve from 30.68292\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.0016 - val_loss: 40.9011\n",
      "Epoch 53/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 12.7369\n",
      "Epoch 53: val_loss did not improve from 30.68292\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.5216 - val_loss: 31.9444\n",
      "Epoch 54/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 11.6180\n",
      "Epoch 54: val_loss did not improve from 30.68292\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.5599 - val_loss: 36.6602\n",
      "Epoch 55/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 12.0408\n",
      "Epoch 55: val_loss did not improve from 30.68292\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.9401 - val_loss: 31.1067\n",
      "Epoch 56/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 11.0836\n",
      "Epoch 56: val_loss did not improve from 30.68292\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.6340 - val_loss: 34.2608\n",
      "Epoch 57/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 12.1732\n",
      "Epoch 57: val_loss improved from 30.68292 to 29.58843, saving model to ./model_save\\4_fold_057-29.5884.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.0659 - val_loss: 29.5884\n",
      "Epoch 58/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 11.2172\n",
      "Epoch 58: val_loss did not improve from 29.58843\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.4655 - val_loss: 31.3523\n",
      "Epoch 59/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 11.1237\n",
      "Epoch 59: val_loss did not improve from 29.58843\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.7003 - val_loss: 32.2413\n",
      "Epoch 60/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 11.8772\n",
      "Epoch 60: val_loss did not improve from 29.58843\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.7154 - val_loss: 35.7861\n",
      "Epoch 61/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 11.6295\n",
      "Epoch 61: val_loss did not improve from 29.58843\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.5205 - val_loss: 32.6915\n",
      "Epoch 62/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 10.4360\n",
      "Epoch 62: val_loss improved from 29.58843 to 28.59106, saving model to ./model_save\\4_fold_062-28.5911.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 11.2716 - val_loss: 28.5911\n",
      "Epoch 63/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 12.1731\n",
      "Epoch 63: val_loss did not improve from 28.59106\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.7524 - val_loss: 33.1329\n",
      "Epoch 64/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 13.1151\n",
      "Epoch 64: val_loss improved from 28.59106 to 27.75743, saving model to ./model_save\\4_fold_064-27.7574.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.3010 - val_loss: 27.7574\n",
      "Epoch 65/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 11.6854\n",
      "Epoch 65: val_loss did not improve from 27.75743\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.8019 - val_loss: 30.7309\n",
      "Epoch 66/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 11.0499\n",
      "Epoch 66: val_loss did not improve from 27.75743\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.0027 - val_loss: 31.5580\n",
      "Epoch 67/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 11.4476\n",
      "Epoch 67: val_loss did not improve from 27.75743\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.4422 - val_loss: 29.0083\n",
      "Epoch 68/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 11.9457\n",
      "Epoch 68: val_loss did not improve from 27.75743\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.1551 - val_loss: 33.5540\n",
      "Epoch 69/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 11.7313\n",
      "Epoch 69: val_loss did not improve from 27.75743\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.7751 - val_loss: 31.5021\n",
      "Epoch 70/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 11.3402\n",
      "Epoch 70: val_loss did not improve from 27.75743\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.4577 - val_loss: 29.6550\n",
      "Epoch 71/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 11.6318\n",
      "Epoch 71: val_loss did not improve from 27.75743\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.4923 - val_loss: 29.2585\n",
      "Epoch 72/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 10.5442\n",
      "Epoch 72: val_loss did not improve from 27.75743\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.7163 - val_loss: 30.9778\n",
      "Epoch 73/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 11.0923\n",
      "Epoch 73: val_loss improved from 27.75743 to 27.50268, saving model to ./model_save\\4_fold_073-27.5027.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.2678 - val_loss: 27.5027\n",
      "Epoch 74/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 11.2608\n",
      "Epoch 74: val_loss did not improve from 27.50268\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.1633 - val_loss: 31.9556\n",
      "Epoch 75/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 10.4723\n",
      "Epoch 75: val_loss improved from 27.50268 to 27.32297, saving model to ./model_save\\4_fold_075-27.3230.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.9069 - val_loss: 27.3230\n",
      "Epoch 76/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 10.8419\n",
      "Epoch 76: val_loss improved from 27.32297 to 26.63010, saving model to ./model_save\\4_fold_076-26.6301.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.8695 - val_loss: 26.6301\n",
      "Epoch 77/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 10.8624\n",
      "Epoch 77: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.2508 - val_loss: 31.5738\n",
      "Epoch 78/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 11.4625\n",
      "Epoch 78: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.1066 - val_loss: 37.5705\n",
      "Epoch 79/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 10.6307\n",
      "Epoch 79: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.5612 - val_loss: 35.5153\n",
      "Epoch 80/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 11.1551\n",
      "Epoch 80: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.1732 - val_loss: 30.9849\n",
      "Epoch 81/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 11.4553\n",
      "Epoch 81: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.4279 - val_loss: 31.2710\n",
      "Epoch 82/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 10.5041\n",
      "Epoch 82: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.7312 - val_loss: 28.8877\n",
      "Epoch 83/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 10.3050\n",
      "Epoch 83: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.3819 - val_loss: 31.4237\n",
      "Epoch 84/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 10.2013\n",
      "Epoch 84: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.1787 - val_loss: 33.6517\n",
      "Epoch 85/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 10.3448\n",
      "Epoch 85: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.4302 - val_loss: 27.7494\n",
      "Epoch 86/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 10.1343\n",
      "Epoch 86: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.8455 - val_loss: 26.7681\n",
      "Epoch 87/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 10.3700\n",
      "Epoch 87: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.2515 - val_loss: 30.4071\n",
      "Epoch 88/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 9.5438 \n",
      "Epoch 88: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.4998 - val_loss: 30.9429\n",
      "Epoch 89/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 9.7064 \n",
      "Epoch 89: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.6564 - val_loss: 28.8307\n",
      "Epoch 90/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 9.7910\n",
      "Epoch 90: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.0506 - val_loss: 30.2392\n",
      "Epoch 91/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 9.8240 \n",
      "Epoch 91: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.8572 - val_loss: 28.2628\n",
      "Epoch 92/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 8.8966\n",
      "Epoch 92: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9090 - val_loss: 28.9920\n",
      "Epoch 93/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 9.8433\n",
      "Epoch 93: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.7584 - val_loss: 29.6962\n",
      "Epoch 94/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 11.3407\n",
      "Epoch 94: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.8827 - val_loss: 29.4693\n",
      "Epoch 95/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.9186\n",
      "Epoch 95: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2418 - val_loss: 34.2294\n",
      "Epoch 96/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 9.1417\n",
      "Epoch 96: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.3973 - val_loss: 31.3649\n",
      "Epoch 97/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 10.4577\n",
      "Epoch 97: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.2339 - val_loss: 29.3099\n",
      "Epoch 98/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 9.2056\n",
      "Epoch 98: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2880 - val_loss: 29.4354\n",
      "Epoch 99/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 8.9536\n",
      "Epoch 99: val_loss did not improve from 26.63010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1378 - val_loss: 30.7164\n",
      "Epoch 100/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 9.2107\n",
      "Epoch 100: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1973 - val_loss: 32.1843\n",
      "Epoch 101/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 9.1684\n",
      "Epoch 101: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0861 - val_loss: 31.1149\n",
      "Epoch 102/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 9.3075\n",
      "Epoch 102: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1267 - val_loss: 30.2810\n",
      "Epoch 103/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 9.1275\n",
      "Epoch 103: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9864 - val_loss: 28.8486\n",
      "Epoch 104/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 8.8586\n",
      "Epoch 104: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7510 - val_loss: 37.2435\n",
      "Epoch 105/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 9.7898\n",
      "Epoch 105: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.7673 - val_loss: 28.7700\n",
      "Epoch 106/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.5661\n",
      "Epoch 106: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.8804 - val_loss: 28.5537\n",
      "Epoch 107/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 8.8467\n",
      "Epoch 107: val_loss did not improve from 26.63010\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.8384 - val_loss: 28.2000\n",
      "Epoch 108/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 9.1477\n",
      "Epoch 108: val_loss improved from 26.63010 to 26.06591, saving model to ./model_save\\4_fold_108-26.0659.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0364 - val_loss: 26.0659\n",
      "Epoch 109/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 8.8377\n",
      "Epoch 109: val_loss did not improve from 26.06591\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9270 - val_loss: 26.6664\n",
      "Epoch 110/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.3152\n",
      "Epoch 110: val_loss improved from 26.06591 to 25.57467, saving model to ./model_save\\4_fold_110-25.5747.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4213 - val_loss: 25.5747\n",
      "Epoch 111/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 9.2011\n",
      "Epoch 111: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0936 - val_loss: 32.0701\n",
      "Epoch 112/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 9.0332\n",
      "Epoch 112: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.8545 - val_loss: 27.3426\n",
      "Epoch 113/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 9.1873\n",
      "Epoch 113: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0582 - val_loss: 28.4491\n",
      "Epoch 114/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 8.9221\n",
      "Epoch 114: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0876 - val_loss: 28.5882\n",
      "Epoch 115/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 9.3270\n",
      "Epoch 115: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1936 - val_loss: 27.5377\n",
      "Epoch 116/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 9.3841\n",
      "Epoch 116: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.3950 - val_loss: 27.3132\n",
      "Epoch 117/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.7643\n",
      "Epoch 117: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8428 - val_loss: 31.7266\n",
      "Epoch 118/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 9.6800\n",
      "Epoch 118: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.6213 - val_loss: 26.9347\n",
      "Epoch 119/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 9.0441\n",
      "Epoch 119: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2197 - val_loss: 29.0750\n",
      "Epoch 120/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.7558\n",
      "Epoch 120: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6855 - val_loss: 30.6151\n",
      "Epoch 121/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.5099\n",
      "Epoch 121: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6614 - val_loss: 26.2686\n",
      "Epoch 122/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 8.6603\n",
      "Epoch 122: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6496 - val_loss: 30.7488\n",
      "Epoch 123/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.8549\n",
      "Epoch 123: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1729 - val_loss: 27.5593\n",
      "Epoch 124/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 8.4780\n",
      "Epoch 124: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5633 - val_loss: 28.3324\n",
      "Epoch 125/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 8.5647\n",
      "Epoch 125: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.8757 - val_loss: 28.8580\n",
      "Epoch 126/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 8.4659\n",
      "Epoch 126: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5967 - val_loss: 26.4615\n",
      "Epoch 127/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 8.4594\n",
      "Epoch 127: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4205 - val_loss: 30.2777\n",
      "Epoch 128/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 8.0977\n",
      "Epoch 128: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.1919 - val_loss: 32.7421\n",
      "Epoch 129/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 10.0517\n",
      "Epoch 129: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.9352 - val_loss: 29.5803\n",
      "Epoch 130/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 8.0825\n",
      "Epoch 130: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1235 - val_loss: 25.6709\n",
      "Epoch 131/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.9809\n",
      "Epoch 131: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9492 - val_loss: 30.6948\n",
      "Epoch 132/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 8.5577\n",
      "Epoch 132: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7426 - val_loss: 28.1229\n",
      "Epoch 133/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 8.4308\n",
      "Epoch 133: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3802 - val_loss: 29.9239\n",
      "Epoch 134/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.8391\n",
      "Epoch 134: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8139 - val_loss: 28.8348\n",
      "Epoch 135/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 7.3054\n",
      "Epoch 135: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3742 - val_loss: 28.6635\n",
      "Epoch 136/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 7.8432\n",
      "Epoch 136: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9865 - val_loss: 30.9562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 8.3031\n",
      "Epoch 137: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3328 - val_loss: 27.0249\n",
      "Epoch 138/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.7031\n",
      "Epoch 138: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6786 - val_loss: 30.5006\n",
      "Epoch 139/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.9326\n",
      "Epoch 139: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3090 - val_loss: 29.0055\n",
      "Epoch 140/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 7.9984\n",
      "Epoch 140: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9738 - val_loss: 28.2035\n",
      "Epoch 141/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 9.1789\n",
      "Epoch 141: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9828 - val_loss: 31.6813\n",
      "Epoch 142/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.2986\n",
      "Epoch 142: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4602 - val_loss: 27.3571\n",
      "Epoch 143/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.5934\n",
      "Epoch 143: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4928 - val_loss: 29.4265\n",
      "Epoch 144/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 7.8930\n",
      "Epoch 144: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8179 - val_loss: 30.7087\n",
      "Epoch 145/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.9409\n",
      "Epoch 145: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9934 - val_loss: 30.8787\n",
      "Epoch 146/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.9744\n",
      "Epoch 146: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0438 - val_loss: 30.0070\n",
      "Epoch 147/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.7077\n",
      "Epoch 147: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7837 - val_loss: 27.7958\n",
      "Epoch 148/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.8999\n",
      "Epoch 148: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8634 - val_loss: 29.7736\n",
      "Epoch 149/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.4730\n",
      "Epoch 149: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5949 - val_loss: 31.2780\n",
      "Epoch 150/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.0912\n",
      "Epoch 150: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3805 - val_loss: 31.4473\n",
      "Epoch 151/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 7.9109\n",
      "Epoch 151: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9158 - val_loss: 30.5112\n",
      "Epoch 152/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.0291\n",
      "Epoch 152: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1209 - val_loss: 29.4584\n",
      "Epoch 153/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.1269\n",
      "Epoch 153: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9657 - val_loss: 28.3183\n",
      "Epoch 154/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.6253\n",
      "Epoch 154: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7125 - val_loss: 31.3473\n",
      "Epoch 155/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.7637\n",
      "Epoch 155: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7562 - val_loss: 29.0319\n",
      "Epoch 156/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.1424\n",
      "Epoch 156: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3403 - val_loss: 29.7845\n",
      "Epoch 157/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.5721\n",
      "Epoch 157: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5867 - val_loss: 30.7491\n",
      "Epoch 158/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 8.3352\n",
      "Epoch 158: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2462 - val_loss: 28.3108\n",
      "Epoch 159/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.7825\n",
      "Epoch 159: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9587 - val_loss: 31.6448\n",
      "Epoch 160/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.1215\n",
      "Epoch 160: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3204 - val_loss: 26.1383\n",
      "Epoch 161/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.5175\n",
      "Epoch 161: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4496 - val_loss: 30.0129\n",
      "Epoch 162/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.2367\n",
      "Epoch 162: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0062 - val_loss: 29.3317\n",
      "Epoch 163/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 8.0932\n",
      "Epoch 163: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8368 - val_loss: 29.9996\n",
      "Epoch 164/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.1083\n",
      "Epoch 164: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3541 - val_loss: 28.6497\n",
      "Epoch 165/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.3469\n",
      "Epoch 165: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2661 - val_loss: 31.0173\n",
      "Epoch 166/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.9582\n",
      "Epoch 166: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9772 - val_loss: 30.5643\n",
      "Epoch 167/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.2219\n",
      "Epoch 167: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1435 - val_loss: 28.1058\n",
      "Epoch 168/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.0216\n",
      "Epoch 168: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4315 - val_loss: 31.0739\n",
      "Epoch 169/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.4614\n",
      "Epoch 169: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3910 - val_loss: 30.2711\n",
      "Epoch 170/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.8621\n",
      "Epoch 170: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8987 - val_loss: 32.8998\n",
      "Epoch 171/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.2424\n",
      "Epoch 171: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2568 - val_loss: 28.8891\n",
      "Epoch 172/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 8.0789\n",
      "Epoch 172: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9771 - val_loss: 28.4688\n",
      "Epoch 173/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 7.1775\n",
      "Epoch 173: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2689 - val_loss: 31.9232\n",
      "Epoch 174/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.1986\n",
      "Epoch 174: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3435 - val_loss: 27.7962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 7.2537\n",
      "Epoch 175: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5283 - val_loss: 28.0314\n",
      "Epoch 176/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 8.3156\n",
      "Epoch 176: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4382 - val_loss: 26.5868\n",
      "Epoch 177/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.8093\n",
      "Epoch 177: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7733 - val_loss: 31.2655\n",
      "Epoch 178/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.8786\n",
      "Epoch 178: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8194 - val_loss: 29.6435\n",
      "Epoch 179/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.6289\n",
      "Epoch 179: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8721 - val_loss: 29.5944\n",
      "Epoch 180/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 7.7806\n",
      "Epoch 180: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6666 - val_loss: 29.6656\n",
      "Epoch 181/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.9415\n",
      "Epoch 181: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9123 - val_loss: 30.5065\n",
      "Epoch 182/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.6549\n",
      "Epoch 182: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7190 - val_loss: 27.0801\n",
      "Epoch 183/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 8.6884\n",
      "Epoch 183: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7073 - val_loss: 27.5672\n",
      "Epoch 184/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.8724\n",
      "Epoch 184: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9125 - val_loss: 35.2468\n",
      "Epoch 185/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 8.0076\n",
      "Epoch 185: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9669 - val_loss: 27.9593\n",
      "Epoch 186/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.6834\n",
      "Epoch 186: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4214 - val_loss: 28.5557\n",
      "Epoch 187/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.1596\n",
      "Epoch 187: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3025 - val_loss: 28.0412\n",
      "Epoch 188/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 7.4076\n",
      "Epoch 188: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5802 - val_loss: 28.4906\n",
      "Epoch 189/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.2738\n",
      "Epoch 189: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1691 - val_loss: 28.0224\n",
      "Epoch 190/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 7.2513\n",
      "Epoch 190: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2112 - val_loss: 29.2914\n",
      "Epoch 191/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 7.5205\n",
      "Epoch 191: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4988 - val_loss: 28.6616\n",
      "Epoch 192/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 7.5430\n",
      "Epoch 192: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6182 - val_loss: 28.7356\n",
      "Epoch 193/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.9000\n",
      "Epoch 193: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7832 - val_loss: 32.2085\n",
      "Epoch 194/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.1442\n",
      "Epoch 194: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1442 - val_loss: 28.4758\n",
      "Epoch 195/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.7394\n",
      "Epoch 195: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7987 - val_loss: 26.9960\n",
      "Epoch 196/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 7.2970\n",
      "Epoch 196: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2776 - val_loss: 28.8793\n",
      "Epoch 197/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 6.9729\n",
      "Epoch 197: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2676 - val_loss: 28.2342\n",
      "Epoch 198/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.1706\n",
      "Epoch 198: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1399 - val_loss: 30.0970\n",
      "Epoch 199/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.2033\n",
      "Epoch 199: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3313 - val_loss: 28.2614\n",
      "Epoch 200/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.1051\n",
      "Epoch 200: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2828 - val_loss: 30.0140\n",
      "Epoch 201/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.3990\n",
      "Epoch 201: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3270 - val_loss: 26.2003\n",
      "Epoch 202/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 7.2167\n",
      "Epoch 202: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3259 - val_loss: 27.2384\n",
      "Epoch 203/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.5103\n",
      "Epoch 203: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7138 - val_loss: 27.8321\n",
      "Epoch 204/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.4656\n",
      "Epoch 204: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4755 - val_loss: 29.5009\n",
      "Epoch 205/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 7.8881\n",
      "Epoch 205: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 7.9194 - val_loss: 27.5568\n",
      "Epoch 206/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 8.1923\n",
      "Epoch 206: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1872 - val_loss: 37.2849\n",
      "Epoch 207/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.3753\n",
      "Epoch 207: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3825 - val_loss: 28.0011\n",
      "Epoch 208/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 7.0302\n",
      "Epoch 208: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.1619 - val_loss: 31.5717\n",
      "Epoch 209/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.7476\n",
      "Epoch 209: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7403 - val_loss: 29.9001\n",
      "Epoch 210/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.1410\n",
      "Epoch 210: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9997 - val_loss: 27.1371\n",
      "Epoch 211/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.3899\n",
      "Epoch 211: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5648 - val_loss: 30.5094\n",
      "Epoch 212/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.2163\n",
      "Epoch 212: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5472 - val_loss: 30.1516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.3499\n",
      "Epoch 213: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2732 - val_loss: 33.9855\n",
      "Epoch 214/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.0262\n",
      "Epoch 214: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9643 - val_loss: 31.4859\n",
      "Epoch 215/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.8816\n",
      "Epoch 215: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6821 - val_loss: 31.3568\n",
      "Epoch 216/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.3591\n",
      "Epoch 216: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2985 - val_loss: 29.7571\n",
      "Epoch 217/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.0267\n",
      "Epoch 217: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9123 - val_loss: 27.6838\n",
      "Epoch 218/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 6.7386\n",
      "Epoch 218: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8470 - val_loss: 28.2946\n",
      "Epoch 219/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 6.4951\n",
      "Epoch 219: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.6045 - val_loss: 26.8751\n",
      "Epoch 220/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 7.0357\n",
      "Epoch 220: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0861 - val_loss: 29.3313\n",
      "Epoch 221/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.9636\n",
      "Epoch 221: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1401 - val_loss: 28.8473\n",
      "Epoch 222/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.7457\n",
      "Epoch 222: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7457 - val_loss: 29.1498\n",
      "Epoch 223/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 7.2491\n",
      "Epoch 223: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2553 - val_loss: 27.4134\n",
      "Epoch 224/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.5138\n",
      "Epoch 224: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5138 - val_loss: 28.3359\n",
      "Epoch 225/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 7.0163\n",
      "Epoch 225: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0504 - val_loss: 33.3706\n",
      "Epoch 226/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 7.0175\n",
      "Epoch 226: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9452 - val_loss: 28.9091\n",
      "Epoch 227/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.4026\n",
      "Epoch 227: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4958 - val_loss: 29.4033\n",
      "Epoch 228/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.1246\n",
      "Epoch 228: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2976 - val_loss: 30.9296\n",
      "Epoch 229/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.7186\n",
      "Epoch 229: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7186 - val_loss: 28.3374\n",
      "Epoch 230/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.4419\n",
      "Epoch 230: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4419 - val_loss: 28.1455\n",
      "Epoch 231/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.8199\n",
      "Epoch 231: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8308 - val_loss: 29.5602\n",
      "Epoch 232/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.5198\n",
      "Epoch 232: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6214 - val_loss: 30.8173\n",
      "Epoch 233/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.2928\n",
      "Epoch 233: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2928 - val_loss: 26.2103\n",
      "Epoch 234/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 8.7005\n",
      "Epoch 234: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.3330 - val_loss: 28.3334\n",
      "Epoch 235/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.7370\n",
      "Epoch 235: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8163 - val_loss: 29.7889\n",
      "Epoch 236/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 7.0651\n",
      "Epoch 236: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9023 - val_loss: 29.8694\n",
      "Epoch 237/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.1829\n",
      "Epoch 237: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1165 - val_loss: 29.9459\n",
      "Epoch 238/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.7720\n",
      "Epoch 238: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7524 - val_loss: 28.4610\n",
      "Epoch 239/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.9169\n",
      "Epoch 239: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8947 - val_loss: 29.3713\n",
      "Epoch 240/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.4135\n",
      "Epoch 240: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4815 - val_loss: 30.3434\n",
      "Epoch 241/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.5786\n",
      "Epoch 241: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6117 - val_loss: 29.3638\n",
      "Epoch 242/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.2587\n",
      "Epoch 242: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1854 - val_loss: 28.5367\n",
      "Epoch 243/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.9349\n",
      "Epoch 243: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8689 - val_loss: 29.9620\n",
      "Epoch 244/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.8263\n",
      "Epoch 244: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6693 - val_loss: 27.9163\n",
      "Epoch 245/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 7.3083\n",
      "Epoch 245: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2770 - val_loss: 29.6908\n",
      "Epoch 246/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 7.0526\n",
      "Epoch 246: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0300 - val_loss: 27.0004\n",
      "Epoch 247/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.9552\n",
      "Epoch 247: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9338 - val_loss: 30.0603\n",
      "Epoch 248/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.5959\n",
      "Epoch 248: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5976 - val_loss: 26.2309\n",
      "Epoch 249/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.8793\n",
      "Epoch 249: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9906 - val_loss: 29.6009\n",
      "Epoch 250/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.8239\n",
      "Epoch 250: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8146 - val_loss: 29.7487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.6732\n",
      "Epoch 251: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6532 - val_loss: 28.3638\n",
      "Epoch 252/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.7074\n",
      "Epoch 252: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7141 - val_loss: 29.0760\n",
      "Epoch 253/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.8702\n",
      "Epoch 253: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8829 - val_loss: 29.7626\n",
      "Epoch 254/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.1084\n",
      "Epoch 254: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2666 - val_loss: 27.5332\n",
      "Epoch 255/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.1991\n",
      "Epoch 255: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2117 - val_loss: 26.2586\n",
      "Epoch 256/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 7.2041\n",
      "Epoch 256: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2528 - val_loss: 26.4524\n",
      "Epoch 257/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.7488\n",
      "Epoch 257: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7442 - val_loss: 29.8112\n",
      "Epoch 258/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.7624\n",
      "Epoch 258: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7124 - val_loss: 31.3405\n",
      "Epoch 259/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.5850\n",
      "Epoch 259: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5493 - val_loss: 31.3657\n",
      "Epoch 260/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 6.7062\n",
      "Epoch 260: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.5827 - val_loss: 28.4209\n",
      "Epoch 261/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.8603\n",
      "Epoch 261: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7540 - val_loss: 29.4717\n",
      "Epoch 262/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.9950\n",
      "Epoch 262: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9928 - val_loss: 27.7783\n",
      "Epoch 263/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.5867\n",
      "Epoch 263: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5867 - val_loss: 29.0103\n",
      "Epoch 264/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.9601\n",
      "Epoch 264: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0615 - val_loss: 27.0846\n",
      "Epoch 265/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.9124\n",
      "Epoch 265: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9419 - val_loss: 28.8345\n",
      "Epoch 266/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.5178\n",
      "Epoch 266: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4981 - val_loss: 27.3531\n",
      "Epoch 267/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.5851\n",
      "Epoch 267: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4831 - val_loss: 26.5040\n",
      "Epoch 268/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.6968\n",
      "Epoch 268: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5643 - val_loss: 28.2335\n",
      "Epoch 269/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.6004\n",
      "Epoch 269: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6402 - val_loss: 30.4780\n",
      "Epoch 270/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.5837\n",
      "Epoch 270: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4915 - val_loss: 30.6048\n",
      "Epoch 271/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.1373\n",
      "Epoch 271: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0369 - val_loss: 27.3720\n",
      "Epoch 272/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.1668\n",
      "Epoch 272: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2705 - val_loss: 27.5742\n",
      "Epoch 273/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.5548\n",
      "Epoch 273: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5277 - val_loss: 31.0765\n",
      "Epoch 274/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.2438\n",
      "Epoch 274: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2387 - val_loss: 28.0001\n",
      "Epoch 275/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.6643\n",
      "Epoch 275: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6515 - val_loss: 28.8096\n",
      "Epoch 276/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 6.1011\n",
      "Epoch 276: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.1585 - val_loss: 27.5771\n",
      "Epoch 277/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 7.1035\n",
      "Epoch 277: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0595 - val_loss: 28.2305\n",
      "Epoch 278/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.9596\n",
      "Epoch 278: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9861 - val_loss: 28.8927\n",
      "Epoch 279/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.6971\n",
      "Epoch 279: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7502 - val_loss: 26.6043\n",
      "Epoch 280/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.7588\n",
      "Epoch 280: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7588 - val_loss: 30.8124\n",
      "Epoch 281/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 6.3162\n",
      "Epoch 281: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.1249 - val_loss: 28.1045\n",
      "Epoch 282/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.8767\n",
      "Epoch 282: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9869 - val_loss: 29.9975\n",
      "Epoch 283/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.5353\n",
      "Epoch 283: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5818 - val_loss: 29.6539\n",
      "Epoch 284/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 6.0491\n",
      "Epoch 284: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8751 - val_loss: 26.9351\n",
      "Epoch 285/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.6707\n",
      "Epoch 285: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6604 - val_loss: 27.8013\n",
      "Epoch 286/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.4853\n",
      "Epoch 286: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3323 - val_loss: 30.1183\n",
      "Epoch 287/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.2758\n",
      "Epoch 287: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3674 - val_loss: 31.7202\n",
      "Epoch 288/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.4732\n",
      "Epoch 288: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4753 - val_loss: 29.9612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 6.5650\n",
      "Epoch 289: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.6421 - val_loss: 28.6254\n",
      "Epoch 290/700\n",
      "60/84 [====================>.........] - ETA: 0s - loss: 6.8992\n",
      "Epoch 290: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.5675 - val_loss: 29.8497\n",
      "Epoch 291/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.5673\n",
      "Epoch 291: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5892 - val_loss: 28.0257\n",
      "Epoch 292/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.0175\n",
      "Epoch 292: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0124 - val_loss: 27.3791\n",
      "Epoch 293/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.8576\n",
      "Epoch 293: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7824 - val_loss: 28.2292\n",
      "Epoch 294/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.9437\n",
      "Epoch 294: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9437 - val_loss: 28.1714\n",
      "Epoch 295/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.5564\n",
      "Epoch 295: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5060 - val_loss: 25.7781\n",
      "Epoch 296/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.3489\n",
      "Epoch 296: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2777 - val_loss: 26.5850\n",
      "Epoch 297/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.7209\n",
      "Epoch 297: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7132 - val_loss: 25.9295\n",
      "Epoch 298/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.9612\n",
      "Epoch 298: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9020 - val_loss: 26.1213\n",
      "Epoch 299/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.7859\n",
      "Epoch 299: val_loss did not improve from 25.57467\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8285 - val_loss: 27.6749\n",
      "Epoch 300/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.7971\n",
      "Epoch 300: val_loss improved from 25.57467 to 25.49431, saving model to ./model_save\\4_fold_300-25.4943.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8295 - val_loss: 25.4943\n",
      "Epoch 301/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.4467\n",
      "Epoch 301: val_loss did not improve from 25.49431\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5036 - val_loss: 28.4127\n",
      "Epoch 302/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 5.5890\n",
      "Epoch 302: val_loss did not improve from 25.49431\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.7957 - val_loss: 29.3979\n",
      "Epoch 303/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.5773\n",
      "Epoch 303: val_loss did not improve from 25.49431\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5717 - val_loss: 27.9917\n",
      "Epoch 304/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.9815\n",
      "Epoch 304: val_loss did not improve from 25.49431\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9345 - val_loss: 27.0526\n",
      "Epoch 305/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.8062\n",
      "Epoch 305: val_loss did not improve from 25.49431\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0097 - val_loss: 26.4489\n",
      "Epoch 306/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.9468\n",
      "Epoch 306: val_loss did not improve from 25.49431\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8914 - val_loss: 28.9453\n",
      "Epoch 307/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.1995\n",
      "Epoch 307: val_loss did not improve from 25.49431\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2990 - val_loss: 26.8015\n",
      "Epoch 308/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 6.4666\n",
      "Epoch 308: val_loss did not improve from 25.49431\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.6360 - val_loss: 28.8568\n",
      "Epoch 309/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.2046\n",
      "Epoch 309: val_loss did not improve from 25.49431\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2304 - val_loss: 28.3166\n",
      "Epoch 310/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.8705\n",
      "Epoch 310: val_loss did not improve from 25.49431\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8705 - val_loss: 27.8819\n",
      "Epoch 311/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.6467\n",
      "Epoch 311: val_loss did not improve from 25.49431\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6338 - val_loss: 30.0294\n",
      "Epoch 312/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.0162\n",
      "Epoch 312: val_loss did not improve from 25.49431\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0162 - val_loss: 28.7706\n",
      "Epoch 313/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.7313\n",
      "Epoch 313: val_loss did not improve from 25.49431\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7092 - val_loss: 30.0963\n",
      "Epoch 314/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.0150\n",
      "Epoch 314: val_loss improved from 25.49431 to 25.11082, saving model to ./model_save\\4_fold_314-25.1108.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0187 - val_loss: 25.1108\n",
      "Epoch 315/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.4608\n",
      "Epoch 315: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3294 - val_loss: 31.5037\n",
      "Epoch 316/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 7.2625\n",
      "Epoch 316: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 7.3761 - val_loss: 29.0077\n",
      "Epoch 317/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 6.3871\n",
      "Epoch 317: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.6043 - val_loss: 29.0116\n",
      "Epoch 318/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.3622\n",
      "Epoch 318: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2664 - val_loss: 30.8942\n",
      "Epoch 319/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.3348\n",
      "Epoch 319: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4506 - val_loss: 28.7680\n",
      "Epoch 320/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.4357\n",
      "Epoch 320: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4218 - val_loss: 28.9762\n",
      "Epoch 321/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.7099\n",
      "Epoch 321: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8263 - val_loss: 30.9971\n",
      "Epoch 322/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.9783\n",
      "Epoch 322: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0577 - val_loss: 32.6049\n",
      "Epoch 323/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.7048\n",
      "Epoch 323: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6872 - val_loss: 28.6354\n",
      "Epoch 324/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.6030\n",
      "Epoch 324: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6030 - val_loss: 27.8295\n",
      "Epoch 325/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.6961\n",
      "Epoch 325: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6802 - val_loss: 30.2987\n",
      "Epoch 326/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.0608\n",
      "Epoch 326: val_loss did not improve from 25.11082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0286 - val_loss: 28.8214\n",
      "Epoch 327/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.0533\n",
      "Epoch 327: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0471 - val_loss: 28.3221\n",
      "Epoch 328/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.0430\n",
      "Epoch 328: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0745 - val_loss: 31.0032\n",
      "Epoch 329/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.7915\n",
      "Epoch 329: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7915 - val_loss: 31.6120\n",
      "Epoch 330/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 6.0388\n",
      "Epoch 330: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.1664 - val_loss: 28.5142\n",
      "Epoch 331/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.7700\n",
      "Epoch 331: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7486 - val_loss: 28.2564\n",
      "Epoch 332/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 5.5645\n",
      "Epoch 332: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.5938 - val_loss: 29.1051\n",
      "Epoch 333/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.7665\n",
      "Epoch 333: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6807 - val_loss: 31.6265\n",
      "Epoch 334/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 5.9491\n",
      "Epoch 334: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.8392 - val_loss: 29.8840\n",
      "Epoch 335/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.2294\n",
      "Epoch 335: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4234 - val_loss: 30.4299\n",
      "Epoch 336/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 5.7413\n",
      "Epoch 336: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.7928 - val_loss: 29.2573\n",
      "Epoch 337/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.0497\n",
      "Epoch 337: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0532 - val_loss: 28.5729\n",
      "Epoch 338/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.0588\n",
      "Epoch 338: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0821 - val_loss: 28.7991\n",
      "Epoch 339/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.3273\n",
      "Epoch 339: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3273 - val_loss: 31.1870\n",
      "Epoch 340/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.4351\n",
      "Epoch 340: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4798 - val_loss: 30.6399\n",
      "Epoch 341/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.8300\n",
      "Epoch 341: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8300 - val_loss: 28.9944\n",
      "Epoch 342/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 5.9937\n",
      "Epoch 342: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.9541 - val_loss: 27.9199\n",
      "Epoch 343/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.8040\n",
      "Epoch 343: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8036 - val_loss: 30.9262\n",
      "Epoch 344/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 5.3083\n",
      "Epoch 344: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.6881 - val_loss: 30.3923\n",
      "Epoch 345/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.5392\n",
      "Epoch 345: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8147 - val_loss: 33.5869\n",
      "Epoch 346/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.8312\n",
      "Epoch 346: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8312 - val_loss: 27.9480\n",
      "Epoch 347/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.5771\n",
      "Epoch 347: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5487 - val_loss: 29.2504\n",
      "Epoch 348/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.3662\n",
      "Epoch 348: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3662 - val_loss: 29.0062\n",
      "Epoch 349/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.4286\n",
      "Epoch 349: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3732 - val_loss: 29.3209\n",
      "Epoch 350/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.4445\n",
      "Epoch 350: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4282 - val_loss: 29.7291\n",
      "Epoch 351/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.9207\n",
      "Epoch 351: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9612 - val_loss: 28.4003\n",
      "Epoch 352/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.0055\n",
      "Epoch 352: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9673 - val_loss: 29.2136\n",
      "Epoch 353/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.7138\n",
      "Epoch 353: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6919 - val_loss: 30.6577\n",
      "Epoch 354/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.6688\n",
      "Epoch 354: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6910 - val_loss: 28.1803\n",
      "Epoch 355/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 5.7121\n",
      "Epoch 355: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8874 - val_loss: 30.8430\n",
      "Epoch 356/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.1386\n",
      "Epoch 356: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0660 - val_loss: 30.8362\n",
      "Epoch 357/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.5100\n",
      "Epoch 357: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5201 - val_loss: 30.2699\n",
      "Epoch 358/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.1876\n",
      "Epoch 358: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2782 - val_loss: 28.7428\n",
      "Epoch 359/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.2702\n",
      "Epoch 359: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2388 - val_loss: 32.1177\n",
      "Epoch 360/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.4243\n",
      "Epoch 360: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3828 - val_loss: 29.3400\n",
      "Epoch 361/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.8924\n",
      "Epoch 361: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8076 - val_loss: 29.4006\n",
      "Epoch 362/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.5022\n",
      "Epoch 362: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5463 - val_loss: 27.7269\n",
      "Epoch 363/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.5252\n",
      "Epoch 363: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5514 - val_loss: 29.5287\n",
      "Epoch 364/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.2559\n",
      "Epoch 364: val_loss did not improve from 25.11082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2882 - val_loss: 28.4348\n",
      "Epoch 365/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.0023\n",
      "Epoch 365: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9872 - val_loss: 29.9765\n",
      "Epoch 366/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.4270\n",
      "Epoch 366: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3828 - val_loss: 30.2847\n",
      "Epoch 367/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.4354\n",
      "Epoch 367: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4100 - val_loss: 29.8596\n",
      "Epoch 368/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.6255\n",
      "Epoch 368: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6603 - val_loss: 34.0289\n",
      "Epoch 369/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 4.9735\n",
      "Epoch 369: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.3100 - val_loss: 31.1135\n",
      "Epoch 370/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 5.6644\n",
      "Epoch 370: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.4198 - val_loss: 28.4859\n",
      "Epoch 371/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.1927\n",
      "Epoch 371: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2120 - val_loss: 30.6420\n",
      "Epoch 372/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.7729\n",
      "Epoch 372: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7705 - val_loss: 28.4031\n",
      "Epoch 373/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.4489\n",
      "Epoch 373: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4497 - val_loss: 31.8170\n",
      "Epoch 374/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.4104\n",
      "Epoch 374: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4386 - val_loss: 29.4375\n",
      "Epoch 375/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.8978\n",
      "Epoch 375: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9497 - val_loss: 28.6556\n",
      "Epoch 376/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.6426\n",
      "Epoch 376: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5192 - val_loss: 28.6089\n",
      "Epoch 377/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 5.0327\n",
      "Epoch 377: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.2457 - val_loss: 28.5741\n",
      "Epoch 378/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.8114\n",
      "Epoch 378: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8188 - val_loss: 29.4789\n",
      "Epoch 379/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 5.8757\n",
      "Epoch 379: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.7545 - val_loss: 31.5204\n",
      "Epoch 380/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 4.9807\n",
      "Epoch 380: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9807 - val_loss: 28.3123\n",
      "Epoch 381/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.4305\n",
      "Epoch 381: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3850 - val_loss: 27.5995\n",
      "Epoch 382/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.1881\n",
      "Epoch 382: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1217 - val_loss: 28.4539\n",
      "Epoch 383/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.1145\n",
      "Epoch 383: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1145 - val_loss: 28.1598\n",
      "Epoch 384/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.5765\n",
      "Epoch 384: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6580 - val_loss: 29.4938\n",
      "Epoch 385/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.2500\n",
      "Epoch 385: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2525 - val_loss: 28.1458\n",
      "Epoch 386/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.2763\n",
      "Epoch 386: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3071 - val_loss: 30.2026\n",
      "Epoch 387/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.3711\n",
      "Epoch 387: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5024 - val_loss: 31.8786\n",
      "Epoch 388/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.8345\n",
      "Epoch 388: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9064 - val_loss: 28.5927\n",
      "Epoch 389/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.6017\n",
      "Epoch 389: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5815 - val_loss: 29.7071\n",
      "Epoch 390/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.3234\n",
      "Epoch 390: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3787 - val_loss: 28.7185\n",
      "Epoch 391/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 5.4247\n",
      "Epoch 391: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.6708 - val_loss: 28.7204\n",
      "Epoch 392/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.4501\n",
      "Epoch 392: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4408 - val_loss: 31.2407\n",
      "Epoch 393/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.3889\n",
      "Epoch 393: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3997 - val_loss: 30.2239\n",
      "Epoch 394/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.8569\n",
      "Epoch 394: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8569 - val_loss: 30.7485\n",
      "Epoch 395/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 5.4713\n",
      "Epoch 395: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.3805 - val_loss: 31.0620\n",
      "Epoch 396/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.3217\n",
      "Epoch 396: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2733 - val_loss: 30.3248\n",
      "Epoch 397/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.1639\n",
      "Epoch 397: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1905 - val_loss: 29.2497\n",
      "Epoch 398/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.1722\n",
      "Epoch 398: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1994 - val_loss: 30.5969\n",
      "Epoch 399/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.1473\n",
      "Epoch 399: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1473 - val_loss: 30.8714\n",
      "Epoch 400/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.6874\n",
      "Epoch 400: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6299 - val_loss: 28.4635\n",
      "Epoch 401/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.7902\n",
      "Epoch 401: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6953 - val_loss: 28.8638\n",
      "Epoch 402/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.1680\n",
      "Epoch 402: val_loss did not improve from 25.11082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1491 - val_loss: 29.1384\n",
      "Epoch 403/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.4912\n",
      "Epoch 403: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6550 - val_loss: 30.2341\n",
      "Epoch 404/700\n",
      "60/84 [====================>.........] - ETA: 0s - loss: 5.7648\n",
      "Epoch 404: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.6636 - val_loss: 29.5197\n",
      "Epoch 405/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.2792\n",
      "Epoch 405: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1896 - val_loss: 28.9711\n",
      "Epoch 406/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 5.3477\n",
      "Epoch 406: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4952 - val_loss: 29.2510\n",
      "Epoch 407/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.7216\n",
      "Epoch 407: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7059 - val_loss: 30.2317\n",
      "Epoch 408/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.4405\n",
      "Epoch 408: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3881 - val_loss: 29.6561\n",
      "Epoch 409/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 5.1685\n",
      "Epoch 409: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0637 - val_loss: 29.8148\n",
      "Epoch 410/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 4.6527\n",
      "Epoch 410: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6410 - val_loss: 29.7772\n",
      "Epoch 411/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.1065\n",
      "Epoch 411: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0965 - val_loss: 29.9008\n",
      "Epoch 412/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.6130\n",
      "Epoch 412: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6112 - val_loss: 30.2503\n",
      "Epoch 413/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.5902\n",
      "Epoch 413: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4829 - val_loss: 30.4550\n",
      "Epoch 414/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.7380\n",
      "Epoch 414: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7303 - val_loss: 29.9975\n",
      "Epoch 415/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.9730\n",
      "Epoch 415: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0097 - val_loss: 32.0030\n",
      "Epoch 416/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.1306\n",
      "Epoch 416: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1903 - val_loss: 29.5107\n",
      "Epoch 417/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.1743\n",
      "Epoch 417: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1743 - val_loss: 34.1043\n",
      "Epoch 418/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.0115\n",
      "Epoch 418: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0039 - val_loss: 30.9641\n",
      "Epoch 419/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.5845\n",
      "Epoch 419: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5839 - val_loss: 30.8895\n",
      "Epoch 420/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.2705\n",
      "Epoch 420: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2761 - val_loss: 28.7074\n",
      "Epoch 421/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.2641\n",
      "Epoch 421: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2860 - val_loss: 30.7534\n",
      "Epoch 422/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.1166\n",
      "Epoch 422: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1584 - val_loss: 30.0522\n",
      "Epoch 423/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.2923\n",
      "Epoch 423: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2928 - val_loss: 31.0021\n",
      "Epoch 424/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.2604\n",
      "Epoch 424: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2533 - val_loss: 29.3414\n",
      "Epoch 425/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.2672\n",
      "Epoch 425: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2887 - val_loss: 32.3264\n",
      "Epoch 426/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 5.2935\n",
      "Epoch 426: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.7108 - val_loss: 30.7252\n",
      "Epoch 427/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 5.9840\n",
      "Epoch 427: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.0007 - val_loss: 28.7008\n",
      "Epoch 428/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.2216\n",
      "Epoch 428: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1894 - val_loss: 30.8160\n",
      "Epoch 429/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.9969\n",
      "Epoch 429: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0135 - val_loss: 31.0176\n",
      "Epoch 430/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.0601\n",
      "Epoch 430: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0601 - val_loss: 31.0293\n",
      "Epoch 431/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.5109\n",
      "Epoch 431: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4787 - val_loss: 29.9530\n",
      "Epoch 432/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.2178\n",
      "Epoch 432: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2341 - val_loss: 32.5222\n",
      "Epoch 433/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.3729\n",
      "Epoch 433: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3729 - val_loss: 31.0965\n",
      "Epoch 434/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 5.0316\n",
      "Epoch 434: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9332 - val_loss: 30.8921\n",
      "Epoch 435/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 5.4993\n",
      "Epoch 435: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4124 - val_loss: 29.5574\n",
      "Epoch 436/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.1331\n",
      "Epoch 436: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1742 - val_loss: 29.8655\n",
      "Epoch 437/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.0437\n",
      "Epoch 437: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0437 - val_loss: 29.2806\n",
      "Epoch 438/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 5.0134\n",
      "Epoch 438: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.0302 - val_loss: 31.5158\n",
      "Epoch 439/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.9668\n",
      "Epoch 439: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9389 - val_loss: 30.0148\n",
      "Epoch 440/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.4150\n",
      "Epoch 440: val_loss did not improve from 25.11082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3694 - val_loss: 29.9900\n",
      "Epoch 441/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.2757\n",
      "Epoch 441: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2771 - val_loss: 29.3754\n",
      "Epoch 442/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 4.9189\n",
      "Epoch 442: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.9439 - val_loss: 30.8462\n",
      "Epoch 443/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.0278\n",
      "Epoch 443: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0468 - val_loss: 30.2527\n",
      "Epoch 444/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 5.1708\n",
      "Epoch 444: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.2992 - val_loss: 30.8818\n",
      "Epoch 445/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 4.8815\n",
      "Epoch 445: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8112 - val_loss: 28.8994\n",
      "Epoch 446/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 4.8049\n",
      "Epoch 446: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8652 - val_loss: 27.9795\n",
      "Epoch 447/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 5.2656\n",
      "Epoch 447: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.1424 - val_loss: 30.4341\n",
      "Epoch 448/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.2621\n",
      "Epoch 448: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2736 - val_loss: 31.1510\n",
      "Epoch 449/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.1300\n",
      "Epoch 449: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0934 - val_loss: 31.3135\n",
      "Epoch 450/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 4.7552\n",
      "Epoch 450: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7309 - val_loss: 30.4186\n",
      "Epoch 451/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 5.0825\n",
      "Epoch 451: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.2106 - val_loss: 30.0016\n",
      "Epoch 452/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.0936\n",
      "Epoch 452: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0487 - val_loss: 30.5873\n",
      "Epoch 453/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 4.9505\n",
      "Epoch 453: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0146 - val_loss: 31.5366\n",
      "Epoch 454/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.9917\n",
      "Epoch 454: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0626 - val_loss: 29.7048\n",
      "Epoch 455/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 4.7737\n",
      "Epoch 455: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8309 - val_loss: 31.4255\n",
      "Epoch 456/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 5.4008\n",
      "Epoch 456: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.0777 - val_loss: 30.7921\n",
      "Epoch 457/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.1682\n",
      "Epoch 457: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2209 - val_loss: 33.0505\n",
      "Epoch 458/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.1124\n",
      "Epoch 458: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1210 - val_loss: 30.2929\n",
      "Epoch 459/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.0113\n",
      "Epoch 459: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0197 - val_loss: 30.4323\n",
      "Epoch 460/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.8209\n",
      "Epoch 460: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8075 - val_loss: 29.1991\n",
      "Epoch 461/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.2264\n",
      "Epoch 461: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1694 - val_loss: 30.2738\n",
      "Epoch 462/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.3705\n",
      "Epoch 462: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4732 - val_loss: 32.0731\n",
      "Epoch 463/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.4781\n",
      "Epoch 463: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4918 - val_loss: 31.2561\n",
      "Epoch 464/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.3691\n",
      "Epoch 464: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3205 - val_loss: 33.4734\n",
      "Epoch 465/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.1123\n",
      "Epoch 465: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1562 - val_loss: 29.0650\n",
      "Epoch 466/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.4273\n",
      "Epoch 466: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4300 - val_loss: 32.3479\n",
      "Epoch 467/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 4.7985\n",
      "Epoch 467: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.9939 - val_loss: 30.2695\n",
      "Epoch 468/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.1973\n",
      "Epoch 468: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1665 - val_loss: 30.9860\n",
      "Epoch 469/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.8120\n",
      "Epoch 469: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8227 - val_loss: 30.6924\n",
      "Epoch 470/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.1860\n",
      "Epoch 470: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2184 - val_loss: 31.4548\n",
      "Epoch 471/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.0681\n",
      "Epoch 471: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0675 - val_loss: 30.1760\n",
      "Epoch 472/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 4.9627\n",
      "Epoch 472: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9480 - val_loss: 29.0067\n",
      "Epoch 473/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.3499\n",
      "Epoch 473: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3453 - val_loss: 30.8390\n",
      "Epoch 474/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.8204\n",
      "Epoch 474: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8144 - val_loss: 33.3085\n",
      "Epoch 475/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.6542\n",
      "Epoch 475: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6930 - val_loss: 30.0554\n",
      "Epoch 476/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.2222\n",
      "Epoch 476: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2222 - val_loss: 33.2714\n",
      "Epoch 477/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 4.6750\n",
      "Epoch 477: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6750 - val_loss: 28.5862\n",
      "Epoch 478/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 4.7656\n",
      "Epoch 478: val_loss did not improve from 25.11082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9448 - val_loss: 31.8415\n",
      "Epoch 479/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 4.7207\n",
      "Epoch 479: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7419 - val_loss: 30.5522\n",
      "Epoch 480/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.1672\n",
      "Epoch 480: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2423 - val_loss: 32.4159\n",
      "Epoch 481/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.0732\n",
      "Epoch 481: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1123 - val_loss: 30.3111\n",
      "Epoch 482/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.8029\n",
      "Epoch 482: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8092 - val_loss: 29.0926\n",
      "Epoch 483/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.0200\n",
      "Epoch 483: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9722 - val_loss: 28.4976\n",
      "Epoch 484/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.1342\n",
      "Epoch 484: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2052 - val_loss: 30.2395\n",
      "Epoch 485/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 4.5717\n",
      "Epoch 485: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7350 - val_loss: 27.9568\n",
      "Epoch 486/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 4.8675\n",
      "Epoch 486: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9062 - val_loss: 30.4891\n",
      "Epoch 487/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.9724\n",
      "Epoch 487: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9448 - val_loss: 30.5540\n",
      "Epoch 488/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.8081\n",
      "Epoch 488: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8501 - val_loss: 29.8791\n",
      "Epoch 489/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.1560\n",
      "Epoch 489: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1579 - val_loss: 30.0891\n",
      "Epoch 490/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 4.6941\n",
      "Epoch 490: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6827 - val_loss: 30.9288\n",
      "Epoch 491/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 4.8594\n",
      "Epoch 491: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8594 - val_loss: 30.8301\n",
      "Epoch 492/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.9973\n",
      "Epoch 492: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9995 - val_loss: 31.8781\n",
      "Epoch 493/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.2230\n",
      "Epoch 493: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2614 - val_loss: 30.2121\n",
      "Epoch 494/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.5827\n",
      "Epoch 494: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5719 - val_loss: 30.1919\n",
      "Epoch 495/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.8201\n",
      "Epoch 495: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8262 - val_loss: 30.4741\n",
      "Epoch 496/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.2634\n",
      "Epoch 496: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1222 - val_loss: 30.4887\n",
      "Epoch 497/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.6920\n",
      "Epoch 497: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7412 - val_loss: 30.2284\n",
      "Epoch 498/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.9109\n",
      "Epoch 498: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9157 - val_loss: 31.0860\n",
      "Epoch 499/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.3365\n",
      "Epoch 499: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1451 - val_loss: 30.9701\n",
      "Epoch 500/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 4.6956\n",
      "Epoch 500: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7210 - val_loss: 28.6482\n",
      "Epoch 501/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 5.3180\n",
      "Epoch 501: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.5943 - val_loss: 37.0711\n",
      "Epoch 502/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.3661\n",
      "Epoch 502: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3663 - val_loss: 29.2472\n",
      "Epoch 503/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 4.6828\n",
      "Epoch 503: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7366 - val_loss: 30.6655\n",
      "Epoch 504/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.8617\n",
      "Epoch 504: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8626 - val_loss: 28.5796\n",
      "Epoch 505/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.6793\n",
      "Epoch 505: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6996 - val_loss: 30.5167\n",
      "Epoch 506/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.9526\n",
      "Epoch 506: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0245 - val_loss: 31.0947\n",
      "Epoch 507/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.2578\n",
      "Epoch 507: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2600 - val_loss: 30.8693\n",
      "Epoch 508/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.0527\n",
      "Epoch 508: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1242 - val_loss: 34.0318\n",
      "Epoch 509/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 4.6696\n",
      "Epoch 509: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7418 - val_loss: 32.3210\n",
      "Epoch 510/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.6313\n",
      "Epoch 510: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6772 - val_loss: 34.9986\n",
      "Epoch 511/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.9324\n",
      "Epoch 511: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9190 - val_loss: 28.9567\n",
      "Epoch 512/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.8338\n",
      "Epoch 512: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8051 - val_loss: 35.6101\n",
      "Epoch 513/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.1448\n",
      "Epoch 513: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9901 - val_loss: 33.1300\n",
      "Epoch 514/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.9042\n",
      "Epoch 514: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8733 - val_loss: 32.0769\n",
      "Epoch 515/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.6085\n",
      "Epoch 515: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5856 - val_loss: 31.5235\n",
      "Epoch 516/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 4.9628\n",
      "Epoch 516: val_loss did not improve from 25.11082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9628 - val_loss: 29.9110\n",
      "Epoch 517/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.4887\n",
      "Epoch 517: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5529 - val_loss: 28.6552\n",
      "Epoch 518/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.8633\n",
      "Epoch 518: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8779 - val_loss: 31.6341\n",
      "Epoch 519/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.2351\n",
      "Epoch 519: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2431 - val_loss: 33.6178\n",
      "Epoch 520/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.6280\n",
      "Epoch 520: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6097 - val_loss: 31.8867\n",
      "Epoch 521/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 4.5773\n",
      "Epoch 521: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5753 - val_loss: 30.4810\n",
      "Epoch 522/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.9589\n",
      "Epoch 522: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9718 - val_loss: 30.2925\n",
      "Epoch 523/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 4.5045\n",
      "Epoch 523: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5045 - val_loss: 31.8125\n",
      "Epoch 524/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.6613\n",
      "Epoch 524: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6402 - val_loss: 31.0910\n",
      "Epoch 525/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 4.3199\n",
      "Epoch 525: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3561 - val_loss: 32.8327\n",
      "Epoch 526/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 4.8445\n",
      "Epoch 526: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6007 - val_loss: 34.8490\n",
      "Epoch 527/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 5.2600\n",
      "Epoch 527: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.9770 - val_loss: 29.6980\n",
      "Epoch 528/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.8234\n",
      "Epoch 528: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8382 - val_loss: 29.3299\n",
      "Epoch 529/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.8863\n",
      "Epoch 529: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8758 - val_loss: 27.7304\n",
      "Epoch 530/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.0703\n",
      "Epoch 530: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1055 - val_loss: 29.7536\n",
      "Epoch 531/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 4.5825\n",
      "Epoch 531: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6274 - val_loss: 33.4101\n",
      "Epoch 532/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.8417\n",
      "Epoch 532: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8300 - val_loss: 29.7186\n",
      "Epoch 533/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.8035\n",
      "Epoch 533: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7912 - val_loss: 28.7806\n",
      "Epoch 534/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.4804\n",
      "Epoch 534: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4441 - val_loss: 31.2631\n",
      "Epoch 535/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.8777\n",
      "Epoch 535: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8298 - val_loss: 30.0462\n",
      "Epoch 536/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 4.9373\n",
      "Epoch 536: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9563 - val_loss: 31.7804\n",
      "Epoch 537/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.1341\n",
      "Epoch 537: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0998 - val_loss: 29.9223\n",
      "Epoch 538/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 5.0452\n",
      "Epoch 538: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.9220 - val_loss: 30.4382\n",
      "Epoch 539/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 4.7542\n",
      "Epoch 539: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7879 - val_loss: 28.1868\n",
      "Epoch 540/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.5901\n",
      "Epoch 540: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5358 - val_loss: 31.1609\n",
      "Epoch 541/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 4.6851\n",
      "Epoch 541: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6726 - val_loss: 31.4857\n",
      "Epoch 542/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 4.8340\n",
      "Epoch 542: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8435 - val_loss: 30.9388\n",
      "Epoch 543/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 4.9610\n",
      "Epoch 543: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.9346 - val_loss: 29.9045\n",
      "Epoch 544/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 4.8297\n",
      "Epoch 544: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.0219 - val_loss: 31.8851\n",
      "Epoch 545/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 4.8934\n",
      "Epoch 545: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8934 - val_loss: 32.4069\n",
      "Epoch 546/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.5716\n",
      "Epoch 546: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5196 - val_loss: 31.4918\n",
      "Epoch 547/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.7200\n",
      "Epoch 547: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7353 - val_loss: 27.3807\n",
      "Epoch 548/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 4.6044\n",
      "Epoch 548: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6855 - val_loss: 29.4864\n",
      "Epoch 549/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.6970\n",
      "Epoch 549: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6956 - val_loss: 32.0015\n",
      "Epoch 550/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.7135\n",
      "Epoch 550: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7209 - val_loss: 30.8211\n",
      "Epoch 551/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 4.4053\n",
      "Epoch 551: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5456 - val_loss: 30.8139\n",
      "Epoch 552/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 4.6409\n",
      "Epoch 552: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7390 - val_loss: 27.4865\n",
      "Epoch 553/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.1726\n",
      "Epoch 553: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1351 - val_loss: 27.0473\n",
      "Epoch 554/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 4.8965\n",
      "Epoch 554: val_loss did not improve from 25.11082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9155 - val_loss: 32.9532\n",
      "Epoch 555/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.0524\n",
      "Epoch 555: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0524 - val_loss: 32.0533\n",
      "Epoch 556/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.0582\n",
      "Epoch 556: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0354 - val_loss: 35.5986\n",
      "Epoch 557/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 4.6998\n",
      "Epoch 557: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6902 - val_loss: 31.4493\n",
      "Epoch 558/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.8741\n",
      "Epoch 558: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9261 - val_loss: 31.1146\n",
      "Epoch 559/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 4.3926\n",
      "Epoch 559: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4685 - val_loss: 32.5647\n",
      "Epoch 560/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.4899\n",
      "Epoch 560: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4863 - val_loss: 30.5114\n",
      "Epoch 561/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 4.7804\n",
      "Epoch 561: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7469 - val_loss: 30.8747\n",
      "Epoch 562/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 4.8700\n",
      "Epoch 562: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8700 - val_loss: 31.8620\n",
      "Epoch 563/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.6090\n",
      "Epoch 563: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6021 - val_loss: 29.6971\n",
      "Epoch 564/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 4.3253\n",
      "Epoch 564: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4406 - val_loss: 30.5551\n",
      "Epoch 565/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.9377\n",
      "Epoch 565: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9271 - val_loss: 31.1054\n",
      "Epoch 566/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 4.5908\n",
      "Epoch 566: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5248 - val_loss: 31.4951\n",
      "Epoch 567/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 4.5915\n",
      "Epoch 567: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5732 - val_loss: 29.5194\n",
      "Epoch 568/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.2467\n",
      "Epoch 568: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2467 - val_loss: 31.0020\n",
      "Epoch 569/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.8128\n",
      "Epoch 569: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7608 - val_loss: 28.4090\n",
      "Epoch 570/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.4795\n",
      "Epoch 570: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5045 - val_loss: 33.1995\n",
      "Epoch 571/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.1386\n",
      "Epoch 571: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0343 - val_loss: 30.1745\n",
      "Epoch 572/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 4.3660\n",
      "Epoch 572: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4118 - val_loss: 30.3496\n",
      "Epoch 573/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 4.4115\n",
      "Epoch 573: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4268 - val_loss: 29.9179\n",
      "Epoch 574/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 4.4064\n",
      "Epoch 574: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4116 - val_loss: 28.5364\n",
      "Epoch 575/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 4.2995\n",
      "Epoch 575: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3781 - val_loss: 31.9027\n",
      "Epoch 576/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.5789\n",
      "Epoch 576: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5400 - val_loss: 32.9041\n",
      "Epoch 577/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.6644\n",
      "Epoch 577: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6606 - val_loss: 30.2131\n",
      "Epoch 578/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 4.7275\n",
      "Epoch 578: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6602 - val_loss: 32.2253\n",
      "Epoch 579/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.1120\n",
      "Epoch 579: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1229 - val_loss: 29.5182\n",
      "Epoch 580/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.5437\n",
      "Epoch 580: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5176 - val_loss: 31.4348\n",
      "Epoch 581/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.7695\n",
      "Epoch 581: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7748 - val_loss: 30.9494\n",
      "Epoch 582/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 4.4608\n",
      "Epoch 582: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4608 - val_loss: 32.8902\n",
      "Epoch 583/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.8674\n",
      "Epoch 583: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8837 - val_loss: 29.4117\n",
      "Epoch 584/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.7946\n",
      "Epoch 584: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7917 - val_loss: 28.9251\n",
      "Epoch 585/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 4.6727\n",
      "Epoch 585: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6727 - val_loss: 28.8656\n",
      "Epoch 586/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 4.5720\n",
      "Epoch 586: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5478 - val_loss: 30.8734\n",
      "Epoch 587/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 4.9965\n",
      "Epoch 587: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.7432 - val_loss: 29.9961\n",
      "Epoch 588/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 4.7791\n",
      "Epoch 588: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8442 - val_loss: 30.1102\n",
      "Epoch 589/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 4.4988\n",
      "Epoch 589: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8251 - val_loss: 33.0570\n",
      "Epoch 590/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 4.7997\n",
      "Epoch 590: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.6962 - val_loss: 29.2402\n",
      "Epoch 591/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 4.5634\n",
      "Epoch 591: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5414 - val_loss: 30.8863\n",
      "Epoch 592/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 4.1815\n",
      "Epoch 592: val_loss did not improve from 25.11082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 4.2777 - val_loss: 28.1202\n",
      "Epoch 593/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 4.1676\n",
      "Epoch 593: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.2307 - val_loss: 30.6030\n",
      "Epoch 594/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 4.7942\n",
      "Epoch 594: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7653 - val_loss: 30.3812\n",
      "Epoch 595/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 4.5949\n",
      "Epoch 595: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.5381 - val_loss: 29.3756\n",
      "Epoch 596/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 5.3955\n",
      "Epoch 596: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.2309 - val_loss: 32.8474\n",
      "Epoch 597/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.4293\n",
      "Epoch 597: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4284 - val_loss: 28.6549\n",
      "Epoch 598/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.3602\n",
      "Epoch 598: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3632 - val_loss: 29.9516\n",
      "Epoch 599/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 4.4852\n",
      "Epoch 599: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5077 - val_loss: 33.6920\n",
      "Epoch 600/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 4.6016\n",
      "Epoch 600: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4994 - val_loss: 32.1525\n",
      "Epoch 601/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 4.4576\n",
      "Epoch 601: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4382 - val_loss: 31.5340\n",
      "Epoch 602/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 4.5150\n",
      "Epoch 602: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5590 - val_loss: 31.2015\n",
      "Epoch 603/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 4.8793\n",
      "Epoch 603: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8769 - val_loss: 32.0206\n",
      "Epoch 604/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 4.5800\n",
      "Epoch 604: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5543 - val_loss: 30.2891\n",
      "Epoch 605/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 4.7468\n",
      "Epoch 605: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6128 - val_loss: 29.6083\n",
      "Epoch 606/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 4.4063\n",
      "Epoch 606: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3701 - val_loss: 32.1590\n",
      "Epoch 607/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 4.5215\n",
      "Epoch 607: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4600 - val_loss: 30.7626\n",
      "Epoch 608/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 4.9017\n",
      "Epoch 608: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8060 - val_loss: 29.8193\n",
      "Epoch 609/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.2959\n",
      "Epoch 609: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.2888 - val_loss: 29.2767\n",
      "Epoch 610/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 4.2429\n",
      "Epoch 610: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3621 - val_loss: 30.2482\n",
      "Epoch 611/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.0317\n",
      "Epoch 611: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9227 - val_loss: 30.4661\n",
      "Epoch 612/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 4.6079\n",
      "Epoch 612: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6353 - val_loss: 31.0422\n",
      "Epoch 613/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 4.9375\n",
      "Epoch 613: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0717 - val_loss: 32.6081\n",
      "Epoch 614/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 4.4316\n",
      "Epoch 614: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4316 - val_loss: 30.7022\n",
      "Epoch 615/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 4.7544\n",
      "Epoch 615: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5340 - val_loss: 31.4423\n",
      "Epoch 616/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 4.5949\n",
      "Epoch 616: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6397 - val_loss: 31.6930\n",
      "Epoch 617/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 4.7360\n",
      "Epoch 617: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8056 - val_loss: 29.3837\n",
      "Epoch 618/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 4.3401\n",
      "Epoch 618: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4484 - val_loss: 31.1610\n",
      "Epoch 619/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 4.5631\n",
      "Epoch 619: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6222 - val_loss: 31.8444\n",
      "Epoch 620/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 4.7688\n",
      "Epoch 620: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7299 - val_loss: 30.3150\n",
      "Epoch 621/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 4.4955\n",
      "Epoch 621: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8637 - val_loss: 30.2115\n",
      "Epoch 622/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.6746\n",
      "Epoch 622: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 4.6555 - val_loss: 32.6090\n",
      "Epoch 623/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 4.1949\n",
      "Epoch 623: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 4.2554 - val_loss: 31.7009\n",
      "Epoch 624/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 4.2032\n",
      "Epoch 624: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.2059 - val_loss: 29.2637\n",
      "Epoch 625/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 4.6260\n",
      "Epoch 625: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4799 - val_loss: 30.9790\n",
      "Epoch 626/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 4.5810\n",
      "Epoch 626: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6274 - val_loss: 31.3382\n",
      "Epoch 627/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 4.1133\n",
      "Epoch 627: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.2728 - val_loss: 30.3449\n",
      "Epoch 628/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.4232\n",
      "Epoch 628: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4043 - val_loss: 33.5973\n",
      "Epoch 629/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.5283\n",
      "Epoch 629: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6023 - val_loss: 31.0289\n",
      "Epoch 630/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 4.4270\n",
      "Epoch 630: val_loss did not improve from 25.11082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5280 - val_loss: 34.5886\n",
      "Epoch 631/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 4.3331\n",
      "Epoch 631: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4192 - val_loss: 33.3391\n",
      "Epoch 632/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 4.6601\n",
      "Epoch 632: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6173 - val_loss: 31.6179\n",
      "Epoch 633/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 4.4925\n",
      "Epoch 633: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5246 - val_loss: 30.4734\n",
      "Epoch 634/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 4.3566\n",
      "Epoch 634: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3853 - val_loss: 29.9134\n",
      "Epoch 635/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 4.6054\n",
      "Epoch 635: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4638 - val_loss: 31.9932\n",
      "Epoch 636/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 3.8581\n",
      "Epoch 636: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 3.9769 - val_loss: 31.9346\n",
      "Epoch 637/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 4.4934\n",
      "Epoch 637: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4793 - val_loss: 30.9526\n",
      "Epoch 638/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 4.9781\n",
      "Epoch 638: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9983 - val_loss: 31.1735\n",
      "Epoch 639/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.2582\n",
      "Epoch 639: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3181 - val_loss: 31.6750\n",
      "Epoch 640/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 4.3087\n",
      "Epoch 640: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4359 - val_loss: 31.9248\n",
      "Epoch 641/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 4.3846\n",
      "Epoch 641: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4103 - val_loss: 30.8986\n",
      "Epoch 642/700\n",
      "60/84 [====================>.........] - ETA: 0s - loss: 4.2189\n",
      "Epoch 642: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.2898 - val_loss: 30.4936\n",
      "Epoch 643/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 4.7161\n",
      "Epoch 643: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8450 - val_loss: 28.7950\n",
      "Epoch 644/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 4.2524\n",
      "Epoch 644: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.2927 - val_loss: 29.6149\n",
      "Epoch 645/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 4.9830\n",
      "Epoch 645: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8151 - val_loss: 32.8169\n",
      "Epoch 646/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.4725\n",
      "Epoch 646: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4547 - val_loss: 31.0925\n",
      "Epoch 647/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.1387\n",
      "Epoch 647: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.1196 - val_loss: 30.4127\n",
      "Epoch 648/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 4.1610\n",
      "Epoch 648: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.0915 - val_loss: 30.9995\n",
      "Epoch 649/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.3772\n",
      "Epoch 649: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3934 - val_loss: 30.5666\n",
      "Epoch 650/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 4.1697\n",
      "Epoch 650: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3349 - val_loss: 29.4998\n",
      "Epoch 651/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 4.5453\n",
      "Epoch 651: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4148 - val_loss: 30.3345\n",
      "Epoch 652/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 4.3286\n",
      "Epoch 652: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6828 - val_loss: 30.7751\n",
      "Epoch 653/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.7469\n",
      "Epoch 653: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7653 - val_loss: 33.9900\n",
      "Epoch 654/700\n",
      "60/84 [====================>.........] - ETA: 0s - loss: 4.4054\n",
      "Epoch 654: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.2448 - val_loss: 30.5743\n",
      "Epoch 655/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 4.2734\n",
      "Epoch 655: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3444 - val_loss: 31.5614\n",
      "Epoch 656/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 4.4522\n",
      "Epoch 656: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3962 - val_loss: 32.0838\n",
      "Epoch 657/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 5.2103\n",
      "Epoch 657: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1095 - val_loss: 31.0939\n",
      "Epoch 658/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 4.3405\n",
      "Epoch 658: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.2388 - val_loss: 30.2854\n",
      "Epoch 659/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 4.6287\n",
      "Epoch 659: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6495 - val_loss: 29.8241\n",
      "Epoch 660/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.2741\n",
      "Epoch 660: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.2430 - val_loss: 31.9762\n",
      "Epoch 661/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 4.3524\n",
      "Epoch 661: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.2528 - val_loss: 32.1412\n",
      "Epoch 662/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 4.4871\n",
      "Epoch 662: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4664 - val_loss: 31.2242\n",
      "Epoch 663/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 4.1923\n",
      "Epoch 663: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.1946 - val_loss: 29.5228\n",
      "Epoch 664/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 4.7239\n",
      "Epoch 664: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6975 - val_loss: 31.6534\n",
      "Epoch 665/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 4.8561\n",
      "Epoch 665: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8503 - val_loss: 30.9759\n",
      "Epoch 666/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 4.1003\n",
      "Epoch 666: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3479 - val_loss: 31.9514\n",
      "Epoch 667/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 4.4741\n",
      "Epoch 667: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.2715 - val_loss: 31.3009\n",
      "Epoch 668/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 4.4360\n",
      "Epoch 668: val_loss did not improve from 25.11082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3762 - val_loss: 31.2355\n",
      "Epoch 669/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 4.7923\n",
      "Epoch 669: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6791 - val_loss: 32.3068\n",
      "Epoch 670/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 4.4576\n",
      "Epoch 670: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5321 - val_loss: 30.6138\n",
      "Epoch 671/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 4.5079\n",
      "Epoch 671: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4665 - val_loss: 31.5224\n",
      "Epoch 672/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 4.0806\n",
      "Epoch 672: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.0936 - val_loss: 30.5256\n",
      "Epoch 673/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 4.2694\n",
      "Epoch 673: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3087 - val_loss: 33.3744\n",
      "Epoch 674/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.0263\n",
      "Epoch 674: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2707 - val_loss: 30.0985\n",
      "Epoch 675/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 4.8784\n",
      "Epoch 675: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8756 - val_loss: 31.7863\n",
      "Epoch 676/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 4.7333\n",
      "Epoch 676: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6589 - val_loss: 32.0863\n",
      "Epoch 677/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 4.2028\n",
      "Epoch 677: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.1567 - val_loss: 29.5426\n",
      "Epoch 678/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 4.4814\n",
      "Epoch 678: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.4231 - val_loss: 30.8177\n",
      "Epoch 679/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 4.1584\n",
      "Epoch 679: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.2036 - val_loss: 30.3509\n",
      "Epoch 680/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 4.4795\n",
      "Epoch 680: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4914 - val_loss: 30.4864\n",
      "Epoch 681/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 4.0449\n",
      "Epoch 681: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.0445 - val_loss: 30.7922\n",
      "Epoch 682/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 4.1380\n",
      "Epoch 682: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 3.9749 - val_loss: 31.5647\n",
      "Epoch 683/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 4.0843\n",
      "Epoch 683: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.1227 - val_loss: 31.5907\n",
      "Epoch 684/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 4.2728\n",
      "Epoch 684: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.2684 - val_loss: 31.3785\n",
      "Epoch 685/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 4.5688\n",
      "Epoch 685: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6085 - val_loss: 30.6884\n",
      "Epoch 686/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 4.3951\n",
      "Epoch 686: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3913 - val_loss: 30.2517\n",
      "Epoch 687/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 4.3050\n",
      "Epoch 687: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.2460 - val_loss: 30.7171\n",
      "Epoch 688/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 4.1742\n",
      "Epoch 688: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.2779 - val_loss: 31.0484\n",
      "Epoch 689/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 4.2892\n",
      "Epoch 689: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.2832 - val_loss: 30.8571\n",
      "Epoch 690/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 4.7480\n",
      "Epoch 690: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6168 - val_loss: 30.6522\n",
      "Epoch 691/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 4.3316\n",
      "Epoch 691: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4972 - val_loss: 29.8810\n",
      "Epoch 692/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 4.4021\n",
      "Epoch 692: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3770 - val_loss: 30.8670\n",
      "Epoch 693/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 4.3324\n",
      "Epoch 693: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.4796 - val_loss: 30.8109\n",
      "Epoch 694/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.1599\n",
      "Epoch 694: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0396 - val_loss: 31.8954\n",
      "Epoch 695/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 4.2689\n",
      "Epoch 695: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.2836 - val_loss: 30.4815\n",
      "Epoch 696/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.5089\n",
      "Epoch 696: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5123 - val_loss: 29.1095\n",
      "Epoch 697/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 4.1369\n",
      "Epoch 697: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.2322 - val_loss: 31.9642\n",
      "Epoch 698/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 4.4357\n",
      "Epoch 698: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.2975 - val_loss: 29.4440\n",
      "Epoch 699/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 4.2081\n",
      "Epoch 699: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3643 - val_loss: 28.9056\n",
      "Epoch 700/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 4.4420\n",
      "Epoch 700: val_loss did not improve from 25.11082\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.3372 - val_loss: 30.6921\n",
      "\n",
      " ---------- 4 ---------- \n",
      "\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 22, 8, 360)        3600      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 7, 2, 360)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " reshape_11 (Reshape)        (None, 7, 720)            0         \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 7, 720)            0         \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 180)               648720    \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 180)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 181       \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 652,501\n",
      "Trainable params: 652,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 51.1256\n",
      "Epoch 1: val_loss improved from inf to 31.91679, saving model to ./model_save\\5_fold_001-31.9168.hdf5\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 50.6823 - val_loss: 31.9168\n",
      "Epoch 2/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 43.6000\n",
      "Epoch 2: val_loss improved from 31.91679 to 29.94975, saving model to ./model_save\\5_fold_002-29.9497.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 43.8428 - val_loss: 29.9497\n",
      "Epoch 3/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 40.5679\n",
      "Epoch 3: val_loss improved from 29.94975 to 29.61289, saving model to ./model_save\\5_fold_003-29.6129.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 41.2094 - val_loss: 29.6129\n",
      "Epoch 4/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 42.5104\n",
      "Epoch 4: val_loss did not improve from 29.61289\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 41.7589 - val_loss: 29.7277\n",
      "Epoch 5/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 41.3416\n",
      "Epoch 5: val_loss did not improve from 29.61289\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 41.4341 - val_loss: 29.7031\n",
      "Epoch 6/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 39.2704\n",
      "Epoch 6: val_loss improved from 29.61289 to 20.87266, saving model to ./model_save\\5_fold_006-20.8727.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 38.6957 - val_loss: 20.8727\n",
      "Epoch 7/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 35.2727\n",
      "Epoch 7: val_loss improved from 20.87266 to 19.02709, saving model to ./model_save\\5_fold_007-19.0271.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 35.3185 - val_loss: 19.0271\n",
      "Epoch 8/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 34.0397\n",
      "Epoch 8: val_loss did not improve from 19.02709\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 33.8755 - val_loss: 19.1943\n",
      "Epoch 9/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 33.8835\n",
      "Epoch 9: val_loss improved from 19.02709 to 17.17998, saving model to ./model_save\\5_fold_009-17.1800.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 32.7363 - val_loss: 17.1800\n",
      "Epoch 10/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 31.5785\n",
      "Epoch 10: val_loss improved from 17.17998 to 16.45895, saving model to ./model_save\\5_fold_010-16.4590.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 31.6170 - val_loss: 16.4590\n",
      "Epoch 11/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 31.8056\n",
      "Epoch 11: val_loss improved from 16.45895 to 16.16998, saving model to ./model_save\\5_fold_011-16.1700.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 30.9321 - val_loss: 16.1700\n",
      "Epoch 12/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 29.4696\n",
      "Epoch 12: val_loss did not improve from 16.16998\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 29.5382 - val_loss: 18.8638\n",
      "Epoch 13/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 28.7351\n",
      "Epoch 13: val_loss improved from 16.16998 to 14.01337, saving model to ./model_save\\5_fold_013-14.0134.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 28.9628 - val_loss: 14.0134\n",
      "Epoch 14/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 28.6936\n",
      "Epoch 14: val_loss did not improve from 14.01337\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 28.2368 - val_loss: 15.5173\n",
      "Epoch 15/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 26.7330\n",
      "Epoch 15: val_loss improved from 14.01337 to 12.33999, saving model to ./model_save\\5_fold_015-12.3400.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 26.6556 - val_loss: 12.3400\n",
      "Epoch 16/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 27.3905\n",
      "Epoch 16: val_loss improved from 12.33999 to 12.14395, saving model to ./model_save\\5_fold_016-12.1440.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 26.7739 - val_loss: 12.1440\n",
      "Epoch 17/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 24.5398\n",
      "Epoch 17: val_loss did not improve from 12.14395\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 26.1805 - val_loss: 14.9436\n",
      "Epoch 18/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 25.3890\n",
      "Epoch 18: val_loss did not improve from 12.14395\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 26.3475 - val_loss: 14.3226\n",
      "Epoch 19/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 24.6824\n",
      "Epoch 19: val_loss did not improve from 12.14395\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 24.6512 - val_loss: 13.6640\n",
      "Epoch 20/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 21.6043\n",
      "Epoch 20: val_loss improved from 12.14395 to 11.35781, saving model to ./model_save\\5_fold_020-11.3578.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 24.0543 - val_loss: 11.3578\n",
      "Epoch 21/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 24.2176\n",
      "Epoch 21: val_loss improved from 11.35781 to 10.94256, saving model to ./model_save\\5_fold_021-10.9426.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 23.5878 - val_loss: 10.9426\n",
      "Epoch 22/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 24.0110\n",
      "Epoch 22: val_loss improved from 10.94256 to 9.36160, saving model to ./model_save\\5_fold_022-9.3616.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 24.0831 - val_loss: 9.3616\n",
      "Epoch 23/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 22.3609\n",
      "Epoch 23: val_loss did not improve from 9.36160\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 23.0187 - val_loss: 11.1854\n",
      "Epoch 24/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 23.3756\n",
      "Epoch 24: val_loss did not improve from 9.36160\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 22.4172 - val_loss: 11.0827\n",
      "Epoch 25/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 20.4559\n",
      "Epoch 25: val_loss did not improve from 9.36160\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 22.4729 - val_loss: 10.7030\n",
      "Epoch 26/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 20.9472\n",
      "Epoch 26: val_loss improved from 9.36160 to 8.53301, saving model to ./model_save\\5_fold_026-8.5330.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 21.4009 - val_loss: 8.5330\n",
      "Epoch 27/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 21.6352\n",
      "Epoch 27: val_loss did not improve from 8.53301\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 20.9851 - val_loss: 12.6642\n",
      "Epoch 28/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 20.6412\n",
      "Epoch 28: val_loss did not improve from 8.53301\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 21.8880 - val_loss: 9.4486\n",
      "Epoch 29/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 20.3450\n",
      "Epoch 29: val_loss did not improve from 8.53301\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 21.0657 - val_loss: 9.1745\n",
      "Epoch 30/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 21.1033\n",
      "Epoch 30: val_loss improved from 8.53301 to 8.22344, saving model to ./model_save\\5_fold_030-8.2234.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 21.0206 - val_loss: 8.2234\n",
      "Epoch 31/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 19.3409\n",
      "Epoch 31: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.6942 - val_loss: 10.1062\n",
      "Epoch 32/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 19.4901\n",
      "Epoch 32: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.6404 - val_loss: 8.5732\n",
      "Epoch 33/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 19.8570\n",
      "Epoch 33: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.8937 - val_loss: 8.3359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 17.6691\n",
      "Epoch 34: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.2983 - val_loss: 10.6350\n",
      "Epoch 35/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 19.0996\n",
      "Epoch 35: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.1048 - val_loss: 9.3213\n",
      "Epoch 36/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 18.1528\n",
      "Epoch 36: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.4942 - val_loss: 9.5448\n",
      "Epoch 37/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 18.8542\n",
      "Epoch 37: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.9433 - val_loss: 14.5554\n",
      "Epoch 38/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 18.2593\n",
      "Epoch 38: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.6917 - val_loss: 8.4078\n",
      "Epoch 39/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 17.4503\n",
      "Epoch 39: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.9146 - val_loss: 18.8223\n",
      "Epoch 40/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 18.8149\n",
      "Epoch 40: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.3556 - val_loss: 13.4009\n",
      "Epoch 41/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 17.0922\n",
      "Epoch 41: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.4203 - val_loss: 10.1239\n",
      "Epoch 42/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 16.8817\n",
      "Epoch 42: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.2956 - val_loss: 14.8285\n",
      "Epoch 43/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 17.0796\n",
      "Epoch 43: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.0829 - val_loss: 9.7941\n",
      "Epoch 44/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 16.4306\n",
      "Epoch 44: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.3225 - val_loss: 13.6065\n",
      "Epoch 45/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 16.8232\n",
      "Epoch 45: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.5515 - val_loss: 8.5198\n",
      "Epoch 46/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 15.1845\n",
      "Epoch 46: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.2377 - val_loss: 10.7712\n",
      "Epoch 47/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 15.3896\n",
      "Epoch 47: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.4364 - val_loss: 10.5317\n",
      "Epoch 48/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 16.2605\n",
      "Epoch 48: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 16.4556 - val_loss: 9.4156\n",
      "Epoch 49/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 15.7959\n",
      "Epoch 49: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.7129 - val_loss: 9.6585\n",
      "Epoch 50/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 15.1408\n",
      "Epoch 50: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.4185 - val_loss: 8.4565\n",
      "Epoch 51/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 16.0088\n",
      "Epoch 51: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.3549 - val_loss: 11.6889\n",
      "Epoch 52/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 14.3085\n",
      "Epoch 52: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.3394 - val_loss: 9.6163\n",
      "Epoch 53/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 14.5204\n",
      "Epoch 53: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.6379 - val_loss: 10.0796\n",
      "Epoch 54/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 14.7375\n",
      "Epoch 54: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.5482 - val_loss: 10.7925\n",
      "Epoch 55/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 14.3300\n",
      "Epoch 55: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.9485 - val_loss: 10.9182\n",
      "Epoch 56/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 13.8104\n",
      "Epoch 56: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.4285 - val_loss: 14.0550\n",
      "Epoch 57/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 14.0952\n",
      "Epoch 57: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.1248 - val_loss: 11.9528\n",
      "Epoch 58/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 13.6347\n",
      "Epoch 58: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.2360 - val_loss: 10.7849\n",
      "Epoch 59/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 13.8514\n",
      "Epoch 59: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.8493 - val_loss: 11.0505\n",
      "Epoch 60/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 13.9221\n",
      "Epoch 60: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.0436 - val_loss: 18.0696\n",
      "Epoch 61/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 14.1161\n",
      "Epoch 61: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.9440 - val_loss: 12.8468\n",
      "Epoch 62/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 13.3282\n",
      "Epoch 62: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.7795 - val_loss: 10.0198\n",
      "Epoch 63/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 14.2841\n",
      "Epoch 63: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.1207 - val_loss: 13.2666\n",
      "Epoch 64/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 12.9686\n",
      "Epoch 64: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.4565 - val_loss: 11.5181\n",
      "Epoch 65/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 12.1259\n",
      "Epoch 65: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.2544 - val_loss: 11.4546\n",
      "Epoch 66/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 12.3527\n",
      "Epoch 66: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.4693 - val_loss: 10.6290\n",
      "Epoch 67/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 12.6068\n",
      "Epoch 67: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.5787 - val_loss: 11.1871\n",
      "Epoch 68/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 11.4306\n",
      "Epoch 68: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.4856 - val_loss: 11.6717\n",
      "Epoch 69/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 12.7860\n",
      "Epoch 69: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.8492 - val_loss: 12.7382\n",
      "Epoch 70/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 12.0591\n",
      "Epoch 70: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.1280 - val_loss: 12.5283\n",
      "Epoch 71/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 11.3567\n",
      "Epoch 71: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.5274 - val_loss: 10.6900\n",
      "Epoch 72/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/84 [==========================>...] - ETA: 0s - loss: 11.6312\n",
      "Epoch 72: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.9259 - val_loss: 12.8742\n",
      "Epoch 73/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 11.6903\n",
      "Epoch 73: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.4488 - val_loss: 11.6400\n",
      "Epoch 74/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 11.0121\n",
      "Epoch 74: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.1760 - val_loss: 10.4931\n",
      "Epoch 75/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 11.9187\n",
      "Epoch 75: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 11.9203 - val_loss: 12.9162\n",
      "Epoch 76/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 10.7198\n",
      "Epoch 76: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.7000 - val_loss: 10.1381\n",
      "Epoch 77/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 10.8485\n",
      "Epoch 77: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.6065 - val_loss: 11.9234\n",
      "Epoch 78/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 11.4959\n",
      "Epoch 78: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.9197 - val_loss: 14.4579\n",
      "Epoch 79/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 10.0249\n",
      "Epoch 79: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.0249 - val_loss: 11.8686\n",
      "Epoch 80/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 9.9156\n",
      "Epoch 80: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.2397 - val_loss: 9.7608\n",
      "Epoch 81/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 9.6200\n",
      "Epoch 81: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.5699 - val_loss: 10.6956\n",
      "Epoch 82/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 10.2084\n",
      "Epoch 82: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.5448 - val_loss: 10.2489\n",
      "Epoch 83/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 10.5775\n",
      "Epoch 83: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.4114 - val_loss: 10.1002\n",
      "Epoch 84/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 9.4122\n",
      "Epoch 84: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.5232 - val_loss: 13.5554\n",
      "Epoch 85/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 10.7075\n",
      "Epoch 85: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.5082 - val_loss: 10.8242\n",
      "Epoch 86/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 10.4138\n",
      "Epoch 86: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.5661 - val_loss: 9.1352\n",
      "Epoch 87/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 9.9958 \n",
      "Epoch 87: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.7117 - val_loss: 10.4873\n",
      "Epoch 88/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 9.9510\n",
      "Epoch 88: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.3806 - val_loss: 9.6829\n",
      "Epoch 89/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 9.9748\n",
      "Epoch 89: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.9316 - val_loss: 9.3015\n",
      "Epoch 90/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 10.6468\n",
      "Epoch 90: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.2321 - val_loss: 10.3892\n",
      "Epoch 91/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 9.6192\n",
      "Epoch 91: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.9440 - val_loss: 16.3745\n",
      "Epoch 92/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 10.3777\n",
      "Epoch 92: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.0716 - val_loss: 10.2491\n",
      "Epoch 93/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 9.6750\n",
      "Epoch 93: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.5571 - val_loss: 11.1443\n",
      "Epoch 94/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 9.2865\n",
      "Epoch 94: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.3187 - val_loss: 12.7075\n",
      "Epoch 95/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 9.6721 \n",
      "Epoch 95: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.6782 - val_loss: 10.3425\n",
      "Epoch 96/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 9.4294\n",
      "Epoch 96: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.4383 - val_loss: 10.6922\n",
      "Epoch 97/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 9.4648\n",
      "Epoch 97: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1878 - val_loss: 12.0717\n",
      "Epoch 98/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 9.1585\n",
      "Epoch 98: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.8931 - val_loss: 11.0445\n",
      "Epoch 99/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 9.6695\n",
      "Epoch 99: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.7714 - val_loss: 9.5353\n",
      "Epoch 100/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 9.3914\n",
      "Epoch 100: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.6405 - val_loss: 13.0132\n",
      "Epoch 101/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 9.5235\n",
      "Epoch 101: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.3419 - val_loss: 11.2461\n",
      "Epoch 102/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 8.9448\n",
      "Epoch 102: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9303 - val_loss: 10.3787\n",
      "Epoch 103/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 9.1610\n",
      "Epoch 103: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1550 - val_loss: 8.6814\n",
      "Epoch 104/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 10.6664\n",
      "Epoch 104: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.8256 - val_loss: 12.7040\n",
      "Epoch 105/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 9.3296\n",
      "Epoch 105: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.3064 - val_loss: 9.1253\n",
      "Epoch 106/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 9.4569\n",
      "Epoch 106: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2671 - val_loss: 9.1736\n",
      "Epoch 107/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.9035\n",
      "Epoch 107: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9889 - val_loss: 10.8128\n",
      "Epoch 108/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 8.9209\n",
      "Epoch 108: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9119 - val_loss: 8.4806\n",
      "Epoch 109/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.7093\n",
      "Epoch 109: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4375 - val_loss: 8.7969\n",
      "Epoch 110/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/84 [==========================>...] - ETA: 0s - loss: 9.0903\n",
      "Epoch 110: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0209 - val_loss: 9.1882\n",
      "Epoch 111/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 8.2901\n",
      "Epoch 111: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2770 - val_loss: 10.5967\n",
      "Epoch 112/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 8.2373\n",
      "Epoch 112: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2904 - val_loss: 9.9096\n",
      "Epoch 113/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 9.5148\n",
      "Epoch 113: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.4625 - val_loss: 9.2332\n",
      "Epoch 114/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 8.6908\n",
      "Epoch 114: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6396 - val_loss: 8.5401\n",
      "Epoch 115/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 9.2582\n",
      "Epoch 115: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2400 - val_loss: 9.6458\n",
      "Epoch 116/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 8.6242\n",
      "Epoch 116: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6025 - val_loss: 9.2518\n",
      "Epoch 117/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 8.5320\n",
      "Epoch 117: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4808 - val_loss: 10.6274\n",
      "Epoch 118/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 8.7033\n",
      "Epoch 118: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5311 - val_loss: 11.2492\n",
      "Epoch 119/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 8.9373\n",
      "Epoch 119: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0247 - val_loss: 8.5392\n",
      "Epoch 120/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 9.5821\n",
      "Epoch 120: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.4073 - val_loss: 9.0430\n",
      "Epoch 121/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 8.6889\n",
      "Epoch 121: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7800 - val_loss: 9.1611\n",
      "Epoch 122/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 8.5006\n",
      "Epoch 122: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5356 - val_loss: 10.0060\n",
      "Epoch 123/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.9877\n",
      "Epoch 123: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9778 - val_loss: 9.1915\n",
      "Epoch 124/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 9.0610\n",
      "Epoch 124: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9263 - val_loss: 10.4663\n",
      "Epoch 125/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 9.2328\n",
      "Epoch 125: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0227 - val_loss: 9.5676\n",
      "Epoch 126/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.0082\n",
      "Epoch 126: val_loss did not improve from 8.22344\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1743 - val_loss: 8.8645\n",
      "Epoch 127/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 8.4333\n",
      "Epoch 127: val_loss improved from 8.22344 to 7.94949, saving model to ./model_save\\5_fold_127-7.9495.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4617 - val_loss: 7.9495\n",
      "Epoch 128/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 8.4730\n",
      "Epoch 128: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4905 - val_loss: 8.7452\n",
      "Epoch 129/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 8.5027\n",
      "Epoch 129: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5648 - val_loss: 9.3766\n",
      "Epoch 130/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 10.1924\n",
      "Epoch 130: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.9566 - val_loss: 9.2558\n",
      "Epoch 131/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 8.5035\n",
      "Epoch 131: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2018 - val_loss: 10.9301\n",
      "Epoch 132/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 8.2268\n",
      "Epoch 132: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1121 - val_loss: 11.1065\n",
      "Epoch 133/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.8702\n",
      "Epoch 133: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8702 - val_loss: 11.3528\n",
      "Epoch 134/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.2585\n",
      "Epoch 134: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1005 - val_loss: 8.9396\n",
      "Epoch 135/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.9800\n",
      "Epoch 135: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3155 - val_loss: 9.6439\n",
      "Epoch 136/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 8.0647\n",
      "Epoch 136: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0074 - val_loss: 8.1914\n",
      "Epoch 137/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.7744\n",
      "Epoch 137: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9228 - val_loss: 9.6490\n",
      "Epoch 138/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 8.2074\n",
      "Epoch 138: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2122 - val_loss: 9.4312\n",
      "Epoch 139/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 8.6532\n",
      "Epoch 139: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5194 - val_loss: 10.1678\n",
      "Epoch 140/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 8.3689\n",
      "Epoch 140: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2602 - val_loss: 10.4866\n",
      "Epoch 141/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 8.3741\n",
      "Epoch 141: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3878 - val_loss: 14.3774\n",
      "Epoch 142/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 12.9228\n",
      "Epoch 142: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.1753 - val_loss: 9.2557\n",
      "Epoch 143/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 8.3130\n",
      "Epoch 143: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2781 - val_loss: 10.1164\n",
      "Epoch 144/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.0607\n",
      "Epoch 144: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8328 - val_loss: 9.8473\n",
      "Epoch 145/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 8.6200\n",
      "Epoch 145: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1840 - val_loss: 9.0439\n",
      "Epoch 146/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 7.4279\n",
      "Epoch 146: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7123 - val_loss: 9.9089\n",
      "Epoch 147/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.6451\n",
      "Epoch 147: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3613 - val_loss: 10.0863\n",
      "Epoch 148/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/84 [===========================>..] - ETA: 0s - loss: 8.5273\n",
      "Epoch 148: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5003 - val_loss: 10.7647\n",
      "Epoch 149/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.8658\n",
      "Epoch 149: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7171 - val_loss: 10.6653\n",
      "Epoch 150/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.4762\n",
      "Epoch 150: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5467 - val_loss: 10.1690\n",
      "Epoch 151/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.4367\n",
      "Epoch 151: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4841 - val_loss: 11.4531\n",
      "Epoch 152/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 7.8663\n",
      "Epoch 152: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7936 - val_loss: 8.6900\n",
      "Epoch 153/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 7.4208\n",
      "Epoch 153: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6152 - val_loss: 8.1828\n",
      "Epoch 154/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.8316\n",
      "Epoch 154: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9741 - val_loss: 11.3296\n",
      "Epoch 155/700\n",
      "61/84 [====================>.........] - ETA: 0s - loss: 7.9998\n",
      "Epoch 155: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2296 - val_loss: 9.5600\n",
      "Epoch 156/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.4852\n",
      "Epoch 156: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5265 - val_loss: 10.8336\n",
      "Epoch 157/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 7.6873\n",
      "Epoch 157: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5053 - val_loss: 9.3891\n",
      "Epoch 158/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 7.7791\n",
      "Epoch 158: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7516 - val_loss: 9.1969\n",
      "Epoch 159/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.6939\n",
      "Epoch 159: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6939 - val_loss: 9.6537\n",
      "Epoch 160/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.6459\n",
      "Epoch 160: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8123 - val_loss: 9.3997\n",
      "Epoch 161/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.7594\n",
      "Epoch 161: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7594 - val_loss: 8.7406\n",
      "Epoch 162/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.7253\n",
      "Epoch 162: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8041 - val_loss: 9.4482\n",
      "Epoch 163/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 7.5104\n",
      "Epoch 163: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5404 - val_loss: 10.3262\n",
      "Epoch 164/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.3717\n",
      "Epoch 164: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5045 - val_loss: 8.9927\n",
      "Epoch 165/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 7.1018\n",
      "Epoch 165: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1442 - val_loss: 10.3218\n",
      "Epoch 166/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 8.1483\n",
      "Epoch 166: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9146 - val_loss: 9.4105\n",
      "Epoch 167/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.8112\n",
      "Epoch 167: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7324 - val_loss: 9.1906\n",
      "Epoch 168/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.5756\n",
      "Epoch 168: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6433 - val_loss: 10.3723\n",
      "Epoch 169/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.1128\n",
      "Epoch 169: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1128 - val_loss: 8.4400\n",
      "Epoch 170/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.0990\n",
      "Epoch 170: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.1218 - val_loss: 8.6256\n",
      "Epoch 171/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.8426\n",
      "Epoch 171: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7772 - val_loss: 12.3910\n",
      "Epoch 172/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 8.2760\n",
      "Epoch 172: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1761 - val_loss: 10.1806\n",
      "Epoch 173/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 7.8029\n",
      "Epoch 173: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8423 - val_loss: 9.0709\n",
      "Epoch 174/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.7694\n",
      "Epoch 174: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7000 - val_loss: 9.5220\n",
      "Epoch 175/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 8.1192\n",
      "Epoch 175: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0636 - val_loss: 9.6228\n",
      "Epoch 176/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 7.7011\n",
      "Epoch 176: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7554 - val_loss: 8.3081\n",
      "Epoch 177/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.3463\n",
      "Epoch 177: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5053 - val_loss: 11.0885\n",
      "Epoch 178/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.9631\n",
      "Epoch 178: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8502 - val_loss: 9.3167\n",
      "Epoch 179/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 7.6341\n",
      "Epoch 179: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7933 - val_loss: 9.2092\n",
      "Epoch 180/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.1997\n",
      "Epoch 180: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3816 - val_loss: 10.0600\n",
      "Epoch 181/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.5798\n",
      "Epoch 181: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7193 - val_loss: 8.8644\n",
      "Epoch 182/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.9099\n",
      "Epoch 182: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7999 - val_loss: 8.6639\n",
      "Epoch 183/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.1110\n",
      "Epoch 183: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0692 - val_loss: 10.1185\n",
      "Epoch 184/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 7.4146\n",
      "Epoch 184: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3904 - val_loss: 9.9988\n",
      "Epoch 185/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.4537\n",
      "Epoch 185: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4750 - val_loss: 10.4361\n",
      "Epoch 186/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/84 [========================>.....] - ETA: 0s - loss: 7.0745\n",
      "Epoch 186: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0277 - val_loss: 9.8606\n",
      "Epoch 187/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 7.5598\n",
      "Epoch 187: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3263 - val_loss: 9.4965\n",
      "Epoch 188/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.6642\n",
      "Epoch 188: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7806 - val_loss: 9.5047\n",
      "Epoch 189/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 7.7343\n",
      "Epoch 189: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7774 - val_loss: 10.1524\n",
      "Epoch 190/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 8.5873\n",
      "Epoch 190: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4625 - val_loss: 8.5761\n",
      "Epoch 191/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.5119\n",
      "Epoch 191: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5567 - val_loss: 9.9948\n",
      "Epoch 192/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.5784\n",
      "Epoch 192: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5784 - val_loss: 10.8998\n",
      "Epoch 193/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 7.3504\n",
      "Epoch 193: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2613 - val_loss: 9.5608\n",
      "Epoch 194/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.0793\n",
      "Epoch 194: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0793 - val_loss: 10.1393\n",
      "Epoch 195/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.0233\n",
      "Epoch 195: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0162 - val_loss: 10.4880\n",
      "Epoch 196/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.2335\n",
      "Epoch 196: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0983 - val_loss: 8.7838\n",
      "Epoch 197/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.0100\n",
      "Epoch 197: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1527 - val_loss: 10.5240\n",
      "Epoch 198/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 6.9352\n",
      "Epoch 198: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9331 - val_loss: 9.4368\n",
      "Epoch 199/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.8972\n",
      "Epoch 199: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8630 - val_loss: 9.3520\n",
      "Epoch 200/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.2095\n",
      "Epoch 200: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2030 - val_loss: 9.1044\n",
      "Epoch 201/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.9146\n",
      "Epoch 201: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8992 - val_loss: 9.7682\n",
      "Epoch 202/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.0765\n",
      "Epoch 202: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9593 - val_loss: 10.2602\n",
      "Epoch 203/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.3866\n",
      "Epoch 203: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3597 - val_loss: 10.6525\n",
      "Epoch 204/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.7141\n",
      "Epoch 204: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0780 - val_loss: 8.8772\n",
      "Epoch 205/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.1899\n",
      "Epoch 205: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2291 - val_loss: 10.9818\n",
      "Epoch 206/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.8786\n",
      "Epoch 206: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1575 - val_loss: 9.7623\n",
      "Epoch 207/700\n",
      "61/84 [====================>.........] - ETA: 0s - loss: 7.8471\n",
      "Epoch 207: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7286 - val_loss: 10.5367\n",
      "Epoch 208/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.7305\n",
      "Epoch 208: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7267 - val_loss: 9.3880\n",
      "Epoch 209/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.7813\n",
      "Epoch 209: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8256 - val_loss: 9.8985\n",
      "Epoch 210/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.9668\n",
      "Epoch 210: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1088 - val_loss: 10.0456\n",
      "Epoch 211/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.7338\n",
      "Epoch 211: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7222 - val_loss: 10.0304\n",
      "Epoch 212/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.9159\n",
      "Epoch 212: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8413 - val_loss: 9.8935\n",
      "Epoch 213/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.9443\n",
      "Epoch 213: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9844 - val_loss: 9.2872\n",
      "Epoch 214/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.7071\n",
      "Epoch 214: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6500 - val_loss: 9.7101\n",
      "Epoch 215/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.9954\n",
      "Epoch 215: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9541 - val_loss: 9.6559\n",
      "Epoch 216/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.4580\n",
      "Epoch 216: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4648 - val_loss: 10.3665\n",
      "Epoch 217/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.9467\n",
      "Epoch 217: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0593 - val_loss: 10.1849\n",
      "Epoch 218/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 7.3192\n",
      "Epoch 218: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1140 - val_loss: 10.6566\n",
      "Epoch 219/700\n",
      "61/84 [====================>.........] - ETA: 0s - loss: 6.4824\n",
      "Epoch 219: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6559 - val_loss: 9.8163\n",
      "Epoch 220/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.0229\n",
      "Epoch 220: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0763 - val_loss: 10.3859\n",
      "Epoch 221/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 7.2955\n",
      "Epoch 221: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2624 - val_loss: 12.0184\n",
      "Epoch 222/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.2654\n",
      "Epoch 222: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3895 - val_loss: 10.5842\n",
      "Epoch 223/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.8657\n",
      "Epoch 223: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0866 - val_loss: 9.2266\n",
      "Epoch 224/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/84 [===========================>..] - ETA: 0s - loss: 7.7312\n",
      "Epoch 224: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6848 - val_loss: 10.9366\n",
      "Epoch 225/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.9084\n",
      "Epoch 225: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8806 - val_loss: 11.0078\n",
      "Epoch 226/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 7.0634\n",
      "Epoch 226: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9574 - val_loss: 10.4484\n",
      "Epoch 227/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.2042\n",
      "Epoch 227: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0924 - val_loss: 10.3879\n",
      "Epoch 228/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.6833\n",
      "Epoch 228: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8841 - val_loss: 10.6514\n",
      "Epoch 229/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.5433\n",
      "Epoch 229: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6303 - val_loss: 9.9676\n",
      "Epoch 230/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.0776\n",
      "Epoch 230: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9789 - val_loss: 10.7259\n",
      "Epoch 231/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.5023\n",
      "Epoch 231: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5120 - val_loss: 10.5204\n",
      "Epoch 232/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.4597\n",
      "Epoch 232: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5212 - val_loss: 9.3512\n",
      "Epoch 233/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.8194\n",
      "Epoch 233: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7109 - val_loss: 9.4255\n",
      "Epoch 234/700\n",
      "60/84 [====================>.........] - ETA: 0s - loss: 6.8574\n",
      "Epoch 234: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6263 - val_loss: 9.8831\n",
      "Epoch 235/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.0593\n",
      "Epoch 235: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0593 - val_loss: 10.2040\n",
      "Epoch 236/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.0905\n",
      "Epoch 236: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0619 - val_loss: 10.5407\n",
      "Epoch 237/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.2917\n",
      "Epoch 237: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4074 - val_loss: 9.6923\n",
      "Epoch 238/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.6941\n",
      "Epoch 238: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7252 - val_loss: 10.0031\n",
      "Epoch 239/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.1833\n",
      "Epoch 239: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0083 - val_loss: 10.8061\n",
      "Epoch 240/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.4691\n",
      "Epoch 240: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3466 - val_loss: 9.7122\n",
      "Epoch 241/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.0273\n",
      "Epoch 241: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8038 - val_loss: 11.2935\n",
      "Epoch 242/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 6.5721\n",
      "Epoch 242: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7781 - val_loss: 9.2898\n",
      "Epoch 243/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.0517\n",
      "Epoch 243: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2019 - val_loss: 9.8615\n",
      "Epoch 244/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.5651\n",
      "Epoch 244: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7059 - val_loss: 10.2307\n",
      "Epoch 245/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.4309\n",
      "Epoch 245: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8069 - val_loss: 9.9241\n",
      "Epoch 246/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.9695\n",
      "Epoch 246: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9884 - val_loss: 10.7215\n",
      "Epoch 247/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.8540\n",
      "Epoch 247: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8957 - val_loss: 9.8586\n",
      "Epoch 248/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.3408\n",
      "Epoch 248: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2749 - val_loss: 10.0680\n",
      "Epoch 249/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.7835\n",
      "Epoch 249: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7736 - val_loss: 10.9716\n",
      "Epoch 250/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.5787\n",
      "Epoch 250: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6280 - val_loss: 10.3671\n",
      "Epoch 251/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.8451\n",
      "Epoch 251: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7888 - val_loss: 9.9335\n",
      "Epoch 252/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.2052\n",
      "Epoch 252: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3217 - val_loss: 9.9345\n",
      "Epoch 253/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.9092\n",
      "Epoch 253: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9865 - val_loss: 10.6808\n",
      "Epoch 254/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.4939\n",
      "Epoch 254: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7543 - val_loss: 8.7007\n",
      "Epoch 255/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.0969\n",
      "Epoch 255: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1841 - val_loss: 11.5128\n",
      "Epoch 256/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.5404\n",
      "Epoch 256: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4707 - val_loss: 10.3352\n",
      "Epoch 257/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.9438\n",
      "Epoch 257: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9304 - val_loss: 10.1330\n",
      "Epoch 258/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.7764\n",
      "Epoch 258: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8648 - val_loss: 11.1458\n",
      "Epoch 259/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.5642\n",
      "Epoch 259: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5776 - val_loss: 10.2695\n",
      "Epoch 260/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 7.1379\n",
      "Epoch 260: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0895 - val_loss: 11.7044\n",
      "Epoch 261/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.6228\n",
      "Epoch 261: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5383 - val_loss: 9.5222\n",
      "Epoch 262/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/84 [==========================>...] - ETA: 0s - loss: 6.1266\n",
      "Epoch 262: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0473 - val_loss: 9.8870\n",
      "Epoch 263/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.0404\n",
      "Epoch 263: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5275 - val_loss: 9.9768\n",
      "Epoch 264/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.1097\n",
      "Epoch 264: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0330 - val_loss: 11.3293\n",
      "Epoch 265/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.3722\n",
      "Epoch 265: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3575 - val_loss: 9.6193\n",
      "Epoch 266/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.7781\n",
      "Epoch 266: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6148 - val_loss: 10.6678\n",
      "Epoch 267/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.0530\n",
      "Epoch 267: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0666 - val_loss: 10.4612\n",
      "Epoch 268/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.6929\n",
      "Epoch 268: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6207 - val_loss: 9.8845\n",
      "Epoch 269/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.5997\n",
      "Epoch 269: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5385 - val_loss: 11.0705\n",
      "Epoch 270/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.7979\n",
      "Epoch 270: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6298 - val_loss: 10.6789\n",
      "Epoch 271/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.7223\n",
      "Epoch 271: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7802 - val_loss: 11.4009\n",
      "Epoch 272/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.9039\n",
      "Epoch 272: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6756 - val_loss: 10.8162\n",
      "Epoch 273/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.4440\n",
      "Epoch 273: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4741 - val_loss: 10.3581\n",
      "Epoch 274/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.4416\n",
      "Epoch 274: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3002 - val_loss: 9.6105\n",
      "Epoch 275/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.5969\n",
      "Epoch 275: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4473 - val_loss: 10.5580\n",
      "Epoch 276/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.3533\n",
      "Epoch 276: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5409 - val_loss: 11.1124\n",
      "Epoch 277/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.5222\n",
      "Epoch 277: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3160 - val_loss: 10.6131\n",
      "Epoch 278/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.5730\n",
      "Epoch 278: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3922 - val_loss: 10.1045\n",
      "Epoch 279/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.3432\n",
      "Epoch 279: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3424 - val_loss: 9.9530\n",
      "Epoch 280/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.3038\n",
      "Epoch 280: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3201 - val_loss: 10.1492\n",
      "Epoch 281/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.9692\n",
      "Epoch 281: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0288 - val_loss: 12.8248\n",
      "Epoch 282/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.8749\n",
      "Epoch 282: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8714 - val_loss: 11.6947\n",
      "Epoch 283/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.1942\n",
      "Epoch 283: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2632 - val_loss: 10.3495\n",
      "Epoch 284/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.6345\n",
      "Epoch 284: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6406 - val_loss: 10.1988\n",
      "Epoch 285/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.0433\n",
      "Epoch 285: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0433 - val_loss: 10.1752\n",
      "Epoch 286/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.1484\n",
      "Epoch 286: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1215 - val_loss: 10.8562\n",
      "Epoch 287/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.3038\n",
      "Epoch 287: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2589 - val_loss: 9.5820\n",
      "Epoch 288/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.5398\n",
      "Epoch 288: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6041 - val_loss: 10.1818\n",
      "Epoch 289/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.7496\n",
      "Epoch 289: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5628 - val_loss: 10.1114\n",
      "Epoch 290/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.9522\n",
      "Epoch 290: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9202 - val_loss: 9.8994\n",
      "Epoch 291/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.2368\n",
      "Epoch 291: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2133 - val_loss: 10.5897\n",
      "Epoch 292/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.1018\n",
      "Epoch 292: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2168 - val_loss: 9.9734\n",
      "Epoch 293/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.7560\n",
      "Epoch 293: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7471 - val_loss: 9.8610\n",
      "Epoch 294/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.3338\n",
      "Epoch 294: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3941 - val_loss: 9.7517\n",
      "Epoch 295/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.0352\n",
      "Epoch 295: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2801 - val_loss: 10.1192\n",
      "Epoch 296/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.0389\n",
      "Epoch 296: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2207 - val_loss: 10.9500\n",
      "Epoch 297/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.6080\n",
      "Epoch 297: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4957 - val_loss: 11.5457\n",
      "Epoch 298/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.5274\n",
      "Epoch 298: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4252 - val_loss: 10.7889\n",
      "Epoch 299/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.6407\n",
      "Epoch 299: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6229 - val_loss: 10.6680\n",
      "Epoch 300/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/84 [==========================>...] - ETA: 0s - loss: 6.0159\n",
      "Epoch 300: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8866 - val_loss: 10.0016\n",
      "Epoch 301/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 6.5869\n",
      "Epoch 301: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5803 - val_loss: 10.5958\n",
      "Epoch 302/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.4173\n",
      "Epoch 302: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3146 - val_loss: 10.2605\n",
      "Epoch 303/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.2209\n",
      "Epoch 303: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0763 - val_loss: 10.4837\n",
      "Epoch 304/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.4593\n",
      "Epoch 304: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4219 - val_loss: 10.8128\n",
      "Epoch 305/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.1495\n",
      "Epoch 305: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1114 - val_loss: 11.3201\n",
      "Epoch 306/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.6209\n",
      "Epoch 306: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4860 - val_loss: 10.0864\n",
      "Epoch 307/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.9706\n",
      "Epoch 307: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2431 - val_loss: 11.1115\n",
      "Epoch 308/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.3105\n",
      "Epoch 308: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3378 - val_loss: 10.7106\n",
      "Epoch 309/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.1133\n",
      "Epoch 309: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9855 - val_loss: 11.0049\n",
      "Epoch 310/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.7777\n",
      "Epoch 310: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7274 - val_loss: 11.0311\n",
      "Epoch 311/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.9657\n",
      "Epoch 311: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9450 - val_loss: 10.9272\n",
      "Epoch 312/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.1997\n",
      "Epoch 312: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0804 - val_loss: 10.0196\n",
      "Epoch 313/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.7233\n",
      "Epoch 313: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7449 - val_loss: 10.1087\n",
      "Epoch 314/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.7619\n",
      "Epoch 314: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0127 - val_loss: 10.8193\n",
      "Epoch 315/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.0024\n",
      "Epoch 315: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9450 - val_loss: 11.1710\n",
      "Epoch 316/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.9984\n",
      "Epoch 316: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0166 - val_loss: 11.5588\n",
      "Epoch 317/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.8145\n",
      "Epoch 317: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6454 - val_loss: 10.2751\n",
      "Epoch 318/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.0887\n",
      "Epoch 318: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2684 - val_loss: 9.9420\n",
      "Epoch 319/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.5601\n",
      "Epoch 319: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6556 - val_loss: 10.5172\n",
      "Epoch 320/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.5973\n",
      "Epoch 320: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4666 - val_loss: 11.4585\n",
      "Epoch 321/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.4408\n",
      "Epoch 321: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6109 - val_loss: 10.0212\n",
      "Epoch 322/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.4744\n",
      "Epoch 322: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7547 - val_loss: 10.4407\n",
      "Epoch 323/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.0044\n",
      "Epoch 323: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0282 - val_loss: 10.3681\n",
      "Epoch 324/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.0559\n",
      "Epoch 324: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2592 - val_loss: 10.9696\n",
      "Epoch 325/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.0269\n",
      "Epoch 325: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3029 - val_loss: 10.1309\n",
      "Epoch 326/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.0980\n",
      "Epoch 326: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1141 - val_loss: 10.6935\n",
      "Epoch 327/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.0703\n",
      "Epoch 327: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0696 - val_loss: 10.9965\n",
      "Epoch 328/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.0269\n",
      "Epoch 328: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9117 - val_loss: 9.9664\n",
      "Epoch 329/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.9909\n",
      "Epoch 329: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8572 - val_loss: 10.8869\n",
      "Epoch 330/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.3274\n",
      "Epoch 330: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3350 - val_loss: 9.6883\n",
      "Epoch 331/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.3848\n",
      "Epoch 331: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3838 - val_loss: 10.7942\n",
      "Epoch 332/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.1145\n",
      "Epoch 332: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1470 - val_loss: 10.3557\n",
      "Epoch 333/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.6864\n",
      "Epoch 333: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7179 - val_loss: 9.3427\n",
      "Epoch 334/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.0303\n",
      "Epoch 334: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1065 - val_loss: 10.5116\n",
      "Epoch 335/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.4150\n",
      "Epoch 335: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4541 - val_loss: 9.9393\n",
      "Epoch 336/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.0282\n",
      "Epoch 336: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0713 - val_loss: 10.6428\n",
      "Epoch 337/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.9357\n",
      "Epoch 337: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8927 - val_loss: 11.6241\n",
      "Epoch 338/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/84 [===========================>..] - ETA: 0s - loss: 6.4407\n",
      "Epoch 338: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3988 - val_loss: 10.2724\n",
      "Epoch 339/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.1745\n",
      "Epoch 339: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1817 - val_loss: 11.0678\n",
      "Epoch 340/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.1600\n",
      "Epoch 340: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1633 - val_loss: 10.0818\n",
      "Epoch 341/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.6941\n",
      "Epoch 341: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8639 - val_loss: 11.2481\n",
      "Epoch 342/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.0297\n",
      "Epoch 342: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0297 - val_loss: 10.5145\n",
      "Epoch 343/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.1591\n",
      "Epoch 343: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3183 - val_loss: 10.5819\n",
      "Epoch 344/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.8507\n",
      "Epoch 344: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7654 - val_loss: 10.8827\n",
      "Epoch 345/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.1885\n",
      "Epoch 345: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2421 - val_loss: 9.9178\n",
      "Epoch 346/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 6.1640\n",
      "Epoch 346: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0660 - val_loss: 11.2488\n",
      "Epoch 347/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.9383\n",
      "Epoch 347: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9797 - val_loss: 10.6372\n",
      "Epoch 348/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.9425\n",
      "Epoch 348: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1394 - val_loss: 10.0444\n",
      "Epoch 349/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.1318\n",
      "Epoch 349: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1163 - val_loss: 10.3320\n",
      "Epoch 350/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.9228\n",
      "Epoch 350: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7230 - val_loss: 11.5321\n",
      "Epoch 351/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.9978\n",
      "Epoch 351: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0309 - val_loss: 10.4990\n",
      "Epoch 352/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.3421\n",
      "Epoch 352: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0490 - val_loss: 10.2364\n",
      "Epoch 353/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.3985\n",
      "Epoch 353: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4352 - val_loss: 9.9437\n",
      "Epoch 354/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.7778\n",
      "Epoch 354: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8189 - val_loss: 11.2428\n",
      "Epoch 355/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.7169\n",
      "Epoch 355: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8349 - val_loss: 11.3524\n",
      "Epoch 356/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.7127\n",
      "Epoch 356: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6788 - val_loss: 10.8378\n",
      "Epoch 357/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.4815\n",
      "Epoch 357: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3815 - val_loss: 12.2563\n",
      "Epoch 358/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.6971\n",
      "Epoch 358: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6971 - val_loss: 11.3288\n",
      "Epoch 359/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.5259\n",
      "Epoch 359: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3044 - val_loss: 9.7574\n",
      "Epoch 360/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.0190\n",
      "Epoch 360: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9362 - val_loss: 10.9049\n",
      "Epoch 361/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 5.4565\n",
      "Epoch 361: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7339 - val_loss: 10.0482\n",
      "Epoch 362/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.2732\n",
      "Epoch 362: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1217 - val_loss: 10.1060\n",
      "Epoch 363/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.2613\n",
      "Epoch 363: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2856 - val_loss: 10.0370\n",
      "Epoch 364/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.7700\n",
      "Epoch 364: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7698 - val_loss: 10.8752\n",
      "Epoch 365/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 7.1413\n",
      "Epoch 365: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7440 - val_loss: 10.8975\n",
      "Epoch 366/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 6.0110\n",
      "Epoch 366: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9141 - val_loss: 10.6919\n",
      "Epoch 367/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.8775\n",
      "Epoch 367: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7953 - val_loss: 10.3423\n",
      "Epoch 368/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.7763\n",
      "Epoch 368: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8641 - val_loss: 10.1083\n",
      "Epoch 369/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.4053\n",
      "Epoch 369: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4028 - val_loss: 11.3688\n",
      "Epoch 370/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.8036\n",
      "Epoch 370: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8605 - val_loss: 10.7889\n",
      "Epoch 371/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.7462\n",
      "Epoch 371: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7338 - val_loss: 10.6775\n",
      "Epoch 372/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.0961\n",
      "Epoch 372: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0812 - val_loss: 11.1016\n",
      "Epoch 373/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 5.7225\n",
      "Epoch 373: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6933 - val_loss: 10.0227\n",
      "Epoch 374/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.6578\n",
      "Epoch 374: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6579 - val_loss: 10.0410\n",
      "Epoch 375/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.8184\n",
      "Epoch 375: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8050 - val_loss: 10.8700\n",
      "Epoch 376/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/84 [========================>.....] - ETA: 0s - loss: 5.8182\n",
      "Epoch 376: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7520 - val_loss: 11.1956\n",
      "Epoch 377/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.5098\n",
      "Epoch 377: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6351 - val_loss: 10.6164\n",
      "Epoch 378/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.8141\n",
      "Epoch 378: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6017 - val_loss: 10.1688\n",
      "Epoch 379/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.3756\n",
      "Epoch 379: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4692 - val_loss: 10.6071\n",
      "Epoch 380/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.8235\n",
      "Epoch 380: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7996 - val_loss: 10.6977\n",
      "Epoch 381/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.4012\n",
      "Epoch 381: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2376 - val_loss: 10.5340\n",
      "Epoch 382/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.5146\n",
      "Epoch 382: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5075 - val_loss: 10.8836\n",
      "Epoch 383/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.8257\n",
      "Epoch 383: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7958 - val_loss: 10.5994\n",
      "Epoch 384/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.5629\n",
      "Epoch 384: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4942 - val_loss: 10.6015\n",
      "Epoch 385/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.0145\n",
      "Epoch 385: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0946 - val_loss: 11.1491\n",
      "Epoch 386/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.3776\n",
      "Epoch 386: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3641 - val_loss: 10.0526\n",
      "Epoch 387/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.4323\n",
      "Epoch 387: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4984 - val_loss: 10.1632\n",
      "Epoch 388/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.5019\n",
      "Epoch 388: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6030 - val_loss: 11.6149\n",
      "Epoch 389/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.3496\n",
      "Epoch 389: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5286 - val_loss: 13.8269\n",
      "Epoch 390/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.7358\n",
      "Epoch 390: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7155 - val_loss: 10.8962\n",
      "Epoch 391/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.3061\n",
      "Epoch 391: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5949 - val_loss: 11.1235\n",
      "Epoch 392/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.0487\n",
      "Epoch 392: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0707 - val_loss: 10.7573\n",
      "Epoch 393/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.0791\n",
      "Epoch 393: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9293 - val_loss: 10.1291\n",
      "Epoch 394/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.9189\n",
      "Epoch 394: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9347 - val_loss: 10.0613\n",
      "Epoch 395/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.4943\n",
      "Epoch 395: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4943 - val_loss: 10.0197\n",
      "Epoch 396/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.7723\n",
      "Epoch 396: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6346 - val_loss: 9.4622\n",
      "Epoch 397/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.1452\n",
      "Epoch 397: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4899 - val_loss: 11.5054\n",
      "Epoch 398/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.8148\n",
      "Epoch 398: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7129 - val_loss: 11.7537\n",
      "Epoch 399/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.0079\n",
      "Epoch 399: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8614 - val_loss: 10.9631\n",
      "Epoch 400/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.7307\n",
      "Epoch 400: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8239 - val_loss: 10.6162\n",
      "Epoch 401/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.8861\n",
      "Epoch 401: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8681 - val_loss: 10.4445\n",
      "Epoch 402/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.4877\n",
      "Epoch 402: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3884 - val_loss: 10.0749\n",
      "Epoch 403/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.8432\n",
      "Epoch 403: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8220 - val_loss: 10.9566\n",
      "Epoch 404/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.7730\n",
      "Epoch 404: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8256 - val_loss: 11.1697\n",
      "Epoch 405/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.5261\n",
      "Epoch 405: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4465 - val_loss: 10.9765\n",
      "Epoch 406/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.6646\n",
      "Epoch 406: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6631 - val_loss: 11.0899\n",
      "Epoch 407/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.0255\n",
      "Epoch 407: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0968 - val_loss: 10.7745\n",
      "Epoch 408/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.4788\n",
      "Epoch 408: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3006 - val_loss: 10.9199\n",
      "Epoch 409/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.8177\n",
      "Epoch 409: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7532 - val_loss: 11.2375\n",
      "Epoch 410/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 5.3468\n",
      "Epoch 410: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5714 - val_loss: 10.1461\n",
      "Epoch 411/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.2255\n",
      "Epoch 411: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9764 - val_loss: 10.6554\n",
      "Epoch 412/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.1554\n",
      "Epoch 412: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4607 - val_loss: 11.3820\n",
      "Epoch 413/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.9270\n",
      "Epoch 413: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8924 - val_loss: 11.1133\n",
      "Epoch 414/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/84 [=====================>........] - ETA: 0s - loss: 5.5192\n",
      "Epoch 414: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5641 - val_loss: 10.4189\n",
      "Epoch 415/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.4142\n",
      "Epoch 415: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5443 - val_loss: 10.7539\n",
      "Epoch 416/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.1993\n",
      "Epoch 416: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2798 - val_loss: 10.3615\n",
      "Epoch 417/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.6507\n",
      "Epoch 417: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6672 - val_loss: 11.1488\n",
      "Epoch 418/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.3758\n",
      "Epoch 418: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3827 - val_loss: 10.4341\n",
      "Epoch 419/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 5.0252\n",
      "Epoch 419: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4261 - val_loss: 11.1328\n",
      "Epoch 420/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.6776\n",
      "Epoch 420: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6917 - val_loss: 10.3088\n",
      "Epoch 421/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.2195\n",
      "Epoch 421: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3685 - val_loss: 10.0055\n",
      "Epoch 422/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.8126\n",
      "Epoch 422: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8126 - val_loss: 10.0225\n",
      "Epoch 423/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.5262\n",
      "Epoch 423: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3991 - val_loss: 10.8502\n",
      "Epoch 424/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.4925\n",
      "Epoch 424: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5450 - val_loss: 10.8890\n",
      "Epoch 425/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.5630\n",
      "Epoch 425: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5469 - val_loss: 11.0946\n",
      "Epoch 426/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.4486\n",
      "Epoch 426: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1598 - val_loss: 9.6403\n",
      "Epoch 427/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 6.0958\n",
      "Epoch 427: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8013 - val_loss: 10.2245\n",
      "Epoch 428/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.4150\n",
      "Epoch 428: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3242 - val_loss: 10.4932\n",
      "Epoch 429/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.5913\n",
      "Epoch 429: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5730 - val_loss: 10.8320\n",
      "Epoch 430/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.6169\n",
      "Epoch 430: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6681 - val_loss: 11.2993\n",
      "Epoch 431/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.4563\n",
      "Epoch 431: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4282 - val_loss: 10.7585\n",
      "Epoch 432/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.4746\n",
      "Epoch 432: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2752 - val_loss: 9.4074\n",
      "Epoch 433/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.0472\n",
      "Epoch 433: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1586 - val_loss: 10.5005\n",
      "Epoch 434/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.2508\n",
      "Epoch 434: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1843 - val_loss: 10.6687\n",
      "Epoch 435/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.3016\n",
      "Epoch 435: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4437 - val_loss: 10.3719\n",
      "Epoch 436/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.2717\n",
      "Epoch 436: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2717 - val_loss: 10.9308\n",
      "Epoch 437/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.6907\n",
      "Epoch 437: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5547 - val_loss: 9.9973\n",
      "Epoch 438/700\n",
      "60/84 [====================>.........] - ETA: 0s - loss: 5.3586\n",
      "Epoch 438: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2698 - val_loss: 9.7973\n",
      "Epoch 439/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.8443\n",
      "Epoch 439: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7969 - val_loss: 11.5125\n",
      "Epoch 440/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.3340\n",
      "Epoch 440: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2594 - val_loss: 10.8005\n",
      "Epoch 441/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.1387\n",
      "Epoch 441: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1402 - val_loss: 10.2515\n",
      "Epoch 442/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.7692\n",
      "Epoch 442: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9329 - val_loss: 10.7378\n",
      "Epoch 443/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.0668\n",
      "Epoch 443: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1006 - val_loss: 10.2930\n",
      "Epoch 444/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.8134\n",
      "Epoch 444: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8368 - val_loss: 10.5559\n",
      "Epoch 445/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 5.5185\n",
      "Epoch 445: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6920 - val_loss: 10.0537\n",
      "Epoch 446/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.0557\n",
      "Epoch 446: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1670 - val_loss: 10.3866\n",
      "Epoch 447/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 4.9580\n",
      "Epoch 447: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9276 - val_loss: 10.0750\n",
      "Epoch 448/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.8804\n",
      "Epoch 448: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8473 - val_loss: 10.3702\n",
      "Epoch 449/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.6867\n",
      "Epoch 449: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6758 - val_loss: 10.3208\n",
      "Epoch 450/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 5.6635\n",
      "Epoch 450: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7198 - val_loss: 11.1937\n",
      "Epoch 451/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.8488\n",
      "Epoch 451: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8689 - val_loss: 11.7457\n",
      "Epoch 452/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/84 [=====================>........] - ETA: 0s - loss: 5.8149\n",
      "Epoch 452: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0873 - val_loss: 12.4611\n",
      "Epoch 453/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.5575\n",
      "Epoch 453: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5799 - val_loss: 9.5283\n",
      "Epoch 454/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.3180\n",
      "Epoch 454: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3245 - val_loss: 11.0239\n",
      "Epoch 455/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.1864\n",
      "Epoch 455: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2116 - val_loss: 10.6548\n",
      "Epoch 456/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.4439\n",
      "Epoch 456: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3638 - val_loss: 10.9039\n",
      "Epoch 457/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.3070\n",
      "Epoch 457: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2213 - val_loss: 10.6169\n",
      "Epoch 458/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.8942\n",
      "Epoch 458: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0891 - val_loss: 10.6049\n",
      "Epoch 459/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.6963\n",
      "Epoch 459: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3718 - val_loss: 10.1215\n",
      "Epoch 460/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.2954\n",
      "Epoch 460: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3004 - val_loss: 11.1110\n",
      "Epoch 461/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.6130\n",
      "Epoch 461: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7616 - val_loss: 10.0979\n",
      "Epoch 462/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.2725\n",
      "Epoch 462: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2725 - val_loss: 9.9530\n",
      "Epoch 463/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.7845\n",
      "Epoch 463: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7311 - val_loss: 10.3482\n",
      "Epoch 464/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.3943\n",
      "Epoch 464: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4023 - val_loss: 10.7515\n",
      "Epoch 465/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 6.0762\n",
      "Epoch 465: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8314 - val_loss: 10.3334\n",
      "Epoch 466/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.2569\n",
      "Epoch 466: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2541 - val_loss: 10.7870\n",
      "Epoch 467/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.1291\n",
      "Epoch 467: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2374 - val_loss: 10.5759\n",
      "Epoch 468/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.2685\n",
      "Epoch 468: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2243 - val_loss: 10.4110\n",
      "Epoch 469/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.5081\n",
      "Epoch 469: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5278 - val_loss: 10.9379\n",
      "Epoch 470/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.4372\n",
      "Epoch 470: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4795 - val_loss: 10.9407\n",
      "Epoch 471/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.1499\n",
      "Epoch 471: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 5.0775 - val_loss: 10.2629\n",
      "Epoch 472/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.3403\n",
      "Epoch 472: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 5.3403 - val_loss: 10.8152\n",
      "Epoch 473/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.5540\n",
      "Epoch 473: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5134 - val_loss: 10.5813\n",
      "Epoch 474/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.6320\n",
      "Epoch 474: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7306 - val_loss: 10.3284\n",
      "Epoch 475/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.8831\n",
      "Epoch 475: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7447 - val_loss: 10.6462\n",
      "Epoch 476/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.4956\n",
      "Epoch 476: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4077 - val_loss: 10.0239\n",
      "Epoch 477/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 4.9155\n",
      "Epoch 477: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8742 - val_loss: 10.5026\n",
      "Epoch 478/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.4563\n",
      "Epoch 478: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4416 - val_loss: 10.2037\n",
      "Epoch 479/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.5432\n",
      "Epoch 479: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5610 - val_loss: 9.9476\n",
      "Epoch 480/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.6258\n",
      "Epoch 480: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5838 - val_loss: 9.8952\n",
      "Epoch 481/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.4651\n",
      "Epoch 481: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5883 - val_loss: 10.7625\n",
      "Epoch 482/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.3023\n",
      "Epoch 482: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1495 - val_loss: 10.1452\n",
      "Epoch 483/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 4.8933\n",
      "Epoch 483: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8665 - val_loss: 10.3588\n",
      "Epoch 484/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.5421\n",
      "Epoch 484: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6369 - val_loss: 10.5772\n",
      "Epoch 485/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.8988\n",
      "Epoch 485: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7320 - val_loss: 9.9756\n",
      "Epoch 486/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.0196\n",
      "Epoch 486: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0379 - val_loss: 10.9882\n",
      "Epoch 487/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.6262\n",
      "Epoch 487: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5634 - val_loss: 10.9867\n",
      "Epoch 488/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 4.8296\n",
      "Epoch 488: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9413 - val_loss: 11.1690\n",
      "Epoch 489/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.7192\n",
      "Epoch 489: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7115 - val_loss: 11.2475\n",
      "Epoch 490/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/84 [===========================>..] - ETA: 0s - loss: 5.3010\n",
      "Epoch 490: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3225 - val_loss: 11.1640\n",
      "Epoch 491/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.1890\n",
      "Epoch 491: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2400 - val_loss: 12.2995\n",
      "Epoch 492/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.2570\n",
      "Epoch 492: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3681 - val_loss: 10.6962\n",
      "Epoch 493/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.2472\n",
      "Epoch 493: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2116 - val_loss: 10.2076\n",
      "Epoch 494/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.3094\n",
      "Epoch 494: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1547 - val_loss: 11.0310\n",
      "Epoch 495/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.3857\n",
      "Epoch 495: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3631 - val_loss: 11.0957\n",
      "Epoch 496/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.1894\n",
      "Epoch 496: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2746 - val_loss: 10.9195\n",
      "Epoch 497/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.6530\n",
      "Epoch 497: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6571 - val_loss: 10.5931\n",
      "Epoch 498/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 4.8967\n",
      "Epoch 498: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8817 - val_loss: 10.6996\n",
      "Epoch 499/700\n",
      "61/84 [====================>.........] - ETA: 0s - loss: 5.4993\n",
      "Epoch 499: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5763 - val_loss: 10.8188\n",
      "Epoch 500/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.1357\n",
      "Epoch 500: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1837 - val_loss: 10.1125\n",
      "Epoch 501/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 4.7684\n",
      "Epoch 501: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8736 - val_loss: 12.5349\n",
      "Epoch 502/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.3216\n",
      "Epoch 502: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3257 - val_loss: 10.8772\n",
      "Epoch 503/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.4671\n",
      "Epoch 503: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5270 - val_loss: 10.7273\n",
      "Epoch 504/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.2292\n",
      "Epoch 504: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1093 - val_loss: 10.0564\n",
      "Epoch 505/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.3112\n",
      "Epoch 505: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3113 - val_loss: 10.4035\n",
      "Epoch 506/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.2576\n",
      "Epoch 506: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2602 - val_loss: 10.5915\n",
      "Epoch 507/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.6218\n",
      "Epoch 507: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8214 - val_loss: 10.6717\n",
      "Epoch 508/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.3485\n",
      "Epoch 508: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2535 - val_loss: 10.3671\n",
      "Epoch 509/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.4338\n",
      "Epoch 509: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2869 - val_loss: 11.2937\n",
      "Epoch 510/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.3244\n",
      "Epoch 510: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3244 - val_loss: 9.9985\n",
      "Epoch 511/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.3950\n",
      "Epoch 511: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6224 - val_loss: 10.9081\n",
      "Epoch 512/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.7669\n",
      "Epoch 512: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6130 - val_loss: 9.8711\n",
      "Epoch 513/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 5.3747\n",
      "Epoch 513: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3797 - val_loss: 10.5923\n",
      "Epoch 514/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.1359\n",
      "Epoch 514: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1305 - val_loss: 10.6092\n",
      "Epoch 515/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.4556\n",
      "Epoch 515: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4551 - val_loss: 10.1531\n",
      "Epoch 516/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.4941\n",
      "Epoch 516: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5088 - val_loss: 11.0718\n",
      "Epoch 517/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.7274\n",
      "Epoch 517: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5273 - val_loss: 11.2549\n",
      "Epoch 518/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.1993\n",
      "Epoch 518: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2245 - val_loss: 10.8505\n",
      "Epoch 519/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 4.8461\n",
      "Epoch 519: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8102 - val_loss: 10.7854\n",
      "Epoch 520/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.1543\n",
      "Epoch 520: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0994 - val_loss: 10.3503\n",
      "Epoch 521/700\n",
      "61/84 [====================>.........] - ETA: 0s - loss: 5.3389\n",
      "Epoch 521: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3399 - val_loss: 10.2757\n",
      "Epoch 522/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.2444\n",
      "Epoch 522: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2845 - val_loss: 11.1636\n",
      "Epoch 523/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.4427\n",
      "Epoch 523: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5133 - val_loss: 10.3443\n",
      "Epoch 524/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.2396\n",
      "Epoch 524: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1764 - val_loss: 11.4144\n",
      "Epoch 525/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 4.8926\n",
      "Epoch 525: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9195 - val_loss: 10.5553\n",
      "Epoch 526/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.8425\n",
      "Epoch 526: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7835 - val_loss: 10.8984\n",
      "Epoch 527/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.7466\n",
      "Epoch 527: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6837 - val_loss: 10.5875\n",
      "Epoch 528/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/84 [======================>.......] - ETA: 0s - loss: 4.9356\n",
      "Epoch 528: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1107 - val_loss: 10.6325\n",
      "Epoch 529/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 5.0727\n",
      "Epoch 529: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0674 - val_loss: 10.6033\n",
      "Epoch 530/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.2336\n",
      "Epoch 530: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2766 - val_loss: 10.9065\n",
      "Epoch 531/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.2306\n",
      "Epoch 531: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2372 - val_loss: 10.9797\n",
      "Epoch 532/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.5063\n",
      "Epoch 532: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5176 - val_loss: 10.7294\n",
      "Epoch 533/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 4.8132\n",
      "Epoch 533: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8503 - val_loss: 11.0546\n",
      "Epoch 534/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.4689\n",
      "Epoch 534: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3586 - val_loss: 10.5401\n",
      "Epoch 535/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.2882\n",
      "Epoch 535: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3249 - val_loss: 11.6807\n",
      "Epoch 536/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.5121\n",
      "Epoch 536: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4810 - val_loss: 10.4280\n",
      "Epoch 537/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.1333\n",
      "Epoch 537: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1201 - val_loss: 10.9542\n",
      "Epoch 538/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.3654\n",
      "Epoch 538: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4136 - val_loss: 10.5091\n",
      "Epoch 539/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.6109\n",
      "Epoch 539: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5293 - val_loss: 10.9632\n",
      "Epoch 540/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.4069\n",
      "Epoch 540: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4318 - val_loss: 10.3373\n",
      "Epoch 541/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.1781\n",
      "Epoch 541: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1924 - val_loss: 11.2378\n",
      "Epoch 542/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 4.8277\n",
      "Epoch 542: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8573 - val_loss: 10.6656\n",
      "Epoch 543/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.0951\n",
      "Epoch 543: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0951 - val_loss: 10.1479\n",
      "Epoch 544/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.7715\n",
      "Epoch 544: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7468 - val_loss: 10.5016\n",
      "Epoch 545/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.1544\n",
      "Epoch 545: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1544 - val_loss: 10.6581\n",
      "Epoch 546/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 4.9122\n",
      "Epoch 546: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1241 - val_loss: 11.2532\n",
      "Epoch 547/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.3461\n",
      "Epoch 547: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3381 - val_loss: 10.2748\n",
      "Epoch 548/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 4.9121\n",
      "Epoch 548: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9432 - val_loss: 10.5000\n",
      "Epoch 549/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 4.8806\n",
      "Epoch 549: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9923 - val_loss: 10.8365\n",
      "Epoch 550/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.5810\n",
      "Epoch 550: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5647 - val_loss: 11.1911\n",
      "Epoch 551/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.3471\n",
      "Epoch 551: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3390 - val_loss: 10.0253\n",
      "Epoch 552/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.2974\n",
      "Epoch 552: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.3516 - val_loss: 11.2313\n",
      "Epoch 553/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.1520\n",
      "Epoch 553: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1377 - val_loss: 10.5610\n",
      "Epoch 554/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 4.8000\n",
      "Epoch 554: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8645 - val_loss: 10.9098\n",
      "Epoch 555/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 5.2281\n",
      "Epoch 555: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9610 - val_loss: 10.5254\n",
      "Epoch 556/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 4.7934\n",
      "Epoch 556: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8268 - val_loss: 10.6335\n",
      "Epoch 557/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 4.8974\n",
      "Epoch 557: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8828 - val_loss: 11.7566\n",
      "Epoch 558/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.0360\n",
      "Epoch 558: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2244 - val_loss: 10.9777\n",
      "Epoch 559/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.6963\n",
      "Epoch 559: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6150 - val_loss: 10.4942\n",
      "Epoch 560/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 4.9257\n",
      "Epoch 560: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9864 - val_loss: 10.4468\n",
      "Epoch 561/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.0937\n",
      "Epoch 561: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0274 - val_loss: 10.2410\n",
      "Epoch 562/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 4.9571\n",
      "Epoch 562: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8925 - val_loss: 11.0874\n",
      "Epoch 563/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.1521\n",
      "Epoch 563: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1023 - val_loss: 9.9641\n",
      "Epoch 564/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.4082\n",
      "Epoch 564: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4316 - val_loss: 11.7069\n",
      "Epoch 565/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.2522\n",
      "Epoch 565: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1901 - val_loss: 12.2491\n",
      "Epoch 566/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/84 [=======================>......] - ETA: 0s - loss: 5.4126\n",
      "Epoch 566: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4326 - val_loss: 11.6678\n",
      "Epoch 567/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.0487\n",
      "Epoch 567: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7699 - val_loss: 10.7447\n",
      "Epoch 568/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.5757\n",
      "Epoch 568: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4694 - val_loss: 10.0656\n",
      "Epoch 569/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 4.8360\n",
      "Epoch 569: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7819 - val_loss: 10.6102\n",
      "Epoch 570/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.2769\n",
      "Epoch 570: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0794 - val_loss: 10.5518\n",
      "Epoch 571/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 4.8389\n",
      "Epoch 571: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 4.8266 - val_loss: 9.8919\n",
      "Epoch 572/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 5.0912\n",
      "Epoch 572: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0050 - val_loss: 9.5164\n",
      "Epoch 573/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.2139\n",
      "Epoch 573: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1175 - val_loss: 10.4952\n",
      "Epoch 574/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 4.7398\n",
      "Epoch 574: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9180 - val_loss: 9.3147\n",
      "Epoch 575/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.1534\n",
      "Epoch 575: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1489 - val_loss: 10.7533\n",
      "Epoch 576/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.0990\n",
      "Epoch 576: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1743 - val_loss: 10.2394\n",
      "Epoch 577/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.1309\n",
      "Epoch 577: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0434 - val_loss: 10.9754\n",
      "Epoch 578/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.0808\n",
      "Epoch 578: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0337 - val_loss: 10.1917\n",
      "Epoch 579/700\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 5.2740\n",
      "Epoch 579: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.1654 - val_loss: 11.1828\n",
      "Epoch 580/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.5810\n",
      "Epoch 580: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.5637 - val_loss: 11.4788\n",
      "Epoch 581/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.2723\n",
      "Epoch 581: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1426 - val_loss: 10.8500\n",
      "Epoch 582/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.2336\n",
      "Epoch 582: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.3469 - val_loss: 10.2735\n",
      "Epoch 583/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.1541\n",
      "Epoch 583: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0907 - val_loss: 11.0053\n",
      "Epoch 584/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 4.8608\n",
      "Epoch 584: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0768 - val_loss: 10.5305\n",
      "Epoch 585/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.3835\n",
      "Epoch 585: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3064 - val_loss: 11.5907\n",
      "Epoch 586/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.2516\n",
      "Epoch 586: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.0696 - val_loss: 11.3794\n",
      "Epoch 587/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.2494\n",
      "Epoch 587: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4404 - val_loss: 10.7265\n",
      "Epoch 588/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 4.8940\n",
      "Epoch 588: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9377 - val_loss: 10.2437\n",
      "Epoch 589/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 4.7043\n",
      "Epoch 589: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9150 - val_loss: 10.5385\n",
      "Epoch 590/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.0532\n",
      "Epoch 590: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1448 - val_loss: 11.4209\n",
      "Epoch 591/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.0304\n",
      "Epoch 591: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9537 - val_loss: 10.6751\n",
      "Epoch 592/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 4.8525\n",
      "Epoch 592: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8673 - val_loss: 11.6712\n",
      "Epoch 593/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 4.6599\n",
      "Epoch 593: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7804 - val_loss: 10.0371\n",
      "Epoch 594/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.3611\n",
      "Epoch 594: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.4211 - val_loss: 10.6520\n",
      "Epoch 595/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 4.5229\n",
      "Epoch 595: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6180 - val_loss: 10.6520\n",
      "Epoch 596/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.1454\n",
      "Epoch 596: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2289 - val_loss: 10.1831\n",
      "Epoch 597/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 4.8080\n",
      "Epoch 597: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7527 - val_loss: 10.5933\n",
      "Epoch 598/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 4.6285\n",
      "Epoch 598: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7963 - val_loss: 11.2560\n",
      "Epoch 599/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.7438\n",
      "Epoch 599: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7132 - val_loss: 10.4302\n",
      "Epoch 600/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 4.8855\n",
      "Epoch 600: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7884 - val_loss: 10.7483\n",
      "Epoch 601/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.1357\n",
      "Epoch 601: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0944 - val_loss: 10.0081\n",
      "Epoch 602/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 4.8615\n",
      "Epoch 602: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8422 - val_loss: 9.9999\n",
      "Epoch 603/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 4.7196\n",
      "Epoch 603: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.6657 - val_loss: 9.4801\n",
      "Epoch 604/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/84 [============================>.] - ETA: 0s - loss: 5.9584\n",
      "Epoch 604: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9004 - val_loss: 10.3807\n",
      "Epoch 605/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.1254\n",
      "Epoch 605: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0990 - val_loss: 11.4143\n",
      "Epoch 606/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.4217\n",
      "Epoch 606: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3860 - val_loss: 11.0200\n",
      "Epoch 607/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.6499\n",
      "Epoch 607: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3847 - val_loss: 10.0275\n",
      "Epoch 608/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.1104\n",
      "Epoch 608: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1132 - val_loss: 9.4362\n",
      "Epoch 609/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 4.8486\n",
      "Epoch 609: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8688 - val_loss: 11.3284\n",
      "Epoch 610/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.1374\n",
      "Epoch 610: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0629 - val_loss: 10.1901\n",
      "Epoch 611/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 5.1440\n",
      "Epoch 611: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1466 - val_loss: 11.7663\n",
      "Epoch 612/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 4.5790\n",
      "Epoch 612: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.5925 - val_loss: 10.6476\n",
      "Epoch 613/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.0086\n",
      "Epoch 613: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.0082 - val_loss: 11.1094\n",
      "Epoch 614/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.1316\n",
      "Epoch 614: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3453 - val_loss: 10.4268\n",
      "Epoch 615/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.1466\n",
      "Epoch 615: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0782 - val_loss: 10.3226\n",
      "Epoch 616/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.2147\n",
      "Epoch 616: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1149 - val_loss: 10.8455\n",
      "Epoch 617/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.1614\n",
      "Epoch 617: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1527 - val_loss: 10.6779\n",
      "Epoch 618/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 4.7233\n",
      "Epoch 618: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8330 - val_loss: 10.0036\n",
      "Epoch 619/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 4.7249\n",
      "Epoch 619: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7530 - val_loss: 10.9950\n",
      "Epoch 620/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.4334\n",
      "Epoch 620: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2727 - val_loss: 10.7354\n",
      "Epoch 621/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 4.6106\n",
      "Epoch 621: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7741 - val_loss: 11.2800\n",
      "Epoch 622/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.0783\n",
      "Epoch 622: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0458 - val_loss: 10.9295\n",
      "Epoch 623/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 4.9770\n",
      "Epoch 623: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0659 - val_loss: 10.7114\n",
      "Epoch 624/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 4.9207\n",
      "Epoch 624: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.8896 - val_loss: 10.3503\n",
      "Epoch 625/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.1345\n",
      "Epoch 625: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2328 - val_loss: 10.3748\n",
      "Epoch 626/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 4.9959\n",
      "Epoch 626: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1562 - val_loss: 10.3892\n",
      "Epoch 627/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.1085\n",
      "Epoch 627: val_loss did not improve from 7.94949\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0601 - val_loss: 10.4837\n",
      "\n",
      " ---------- 5 ---------- \n",
      "\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 22, 8, 360)        3600      \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 7, 2, 360)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " reshape_12 (Reshape)        (None, 7, 720)            0         \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 7, 720)            0         \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 180)               648720    \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 180)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 181       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 652,501\n",
      "Trainable params: 652,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 52.6883\n",
      "Epoch 1: val_loss improved from inf to 21.93086, saving model to ./model_save\\6_fold_001-21.9309.hdf5\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 51.8176 - val_loss: 21.9309\n",
      "Epoch 2/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 45.1077\n",
      "Epoch 2: val_loss improved from 21.93086 to 21.55211, saving model to ./model_save\\6_fold_002-21.5521.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 45.0067 - val_loss: 21.5521\n",
      "Epoch 3/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 44.2309\n",
      "Epoch 3: val_loss did not improve from 21.55211\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 42.8393 - val_loss: 22.0624\n",
      "Epoch 4/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 41.2044\n",
      "Epoch 4: val_loss improved from 21.55211 to 15.61799, saving model to ./model_save\\6_fold_004-15.6180.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 41.0104 - val_loss: 15.6180\n",
      "Epoch 5/700\n",
      "60/84 [====================>.........] - ETA: 0s - loss: 36.7799\n",
      "Epoch 5: val_loss did not improve from 15.61799\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 37.5618 - val_loss: 16.0921\n",
      "Epoch 6/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 35.2043\n",
      "Epoch 6: val_loss improved from 15.61799 to 14.26824, saving model to ./model_save\\6_fold_006-14.2682.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 35.2660 - val_loss: 14.2682\n",
      "Epoch 7/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 33.5573\n",
      "Epoch 7: val_loss improved from 14.26824 to 14.02987, saving model to ./model_save\\6_fold_007-14.0299.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 34.5937 - val_loss: 14.0299\n",
      "Epoch 8/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 33.1190\n",
      "Epoch 8: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 32.8514 - val_loss: 15.7287\n",
      "Epoch 9/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 32.5524\n",
      "Epoch 9: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 30.8473 - val_loss: 16.0812\n",
      "Epoch 10/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 30.5072\n",
      "Epoch 10: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 30.4231 - val_loss: 15.8074\n",
      "Epoch 11/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 29.2112\n",
      "Epoch 11: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 29.4331 - val_loss: 16.3352\n",
      "Epoch 12/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 28.3186\n",
      "Epoch 12: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 28.0266 - val_loss: 17.0998\n",
      "Epoch 13/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 26.8802\n",
      "Epoch 13: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 26.3710 - val_loss: 17.0122\n",
      "Epoch 14/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 25.1876\n",
      "Epoch 14: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 25.6829 - val_loss: 16.5893\n",
      "Epoch 15/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 24.0805\n",
      "Epoch 15: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 25.5131 - val_loss: 18.6747\n",
      "Epoch 16/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 24.6956\n",
      "Epoch 16: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 24.6786 - val_loss: 19.7542\n",
      "Epoch 17/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 23.9210\n",
      "Epoch 17: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 23.5184 - val_loss: 17.0605\n",
      "Epoch 18/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 23.4350\n",
      "Epoch 18: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 22.8417 - val_loss: 17.6321\n",
      "Epoch 19/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 22.4451\n",
      "Epoch 19: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 22.6971 - val_loss: 18.3925\n",
      "Epoch 20/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 22.0772\n",
      "Epoch 20: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 21.4005 - val_loss: 16.8300\n",
      "Epoch 21/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 22.6630\n",
      "Epoch 21: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 21.9234 - val_loss: 17.7041\n",
      "Epoch 22/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 21.1448\n",
      "Epoch 22: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 21.0106 - val_loss: 18.4752\n",
      "Epoch 23/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 22.8168\n",
      "Epoch 23: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 21.5670 - val_loss: 19.9938\n",
      "Epoch 24/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 21.2806\n",
      "Epoch 24: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 20.6606 - val_loss: 17.4993\n",
      "Epoch 25/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 21.0829\n",
      "Epoch 25: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 20.6781 - val_loss: 19.8722\n",
      "Epoch 26/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 19.6687\n",
      "Epoch 26: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.7390 - val_loss: 19.5011\n",
      "Epoch 27/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 19.0501\n",
      "Epoch 27: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.3047 - val_loss: 18.3494\n",
      "Epoch 28/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 19.5264\n",
      "Epoch 28: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.6613 - val_loss: 19.2078\n",
      "Epoch 29/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 18.6672\n",
      "Epoch 29: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.5020 - val_loss: 21.4973\n",
      "Epoch 30/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 18.7358\n",
      "Epoch 30: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.2355 - val_loss: 21.9464\n",
      "Epoch 31/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 18.7545\n",
      "Epoch 31: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.8032 - val_loss: 19.3456\n",
      "Epoch 32/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 18.0761\n",
      "Epoch 32: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.1781 - val_loss: 20.0111\n",
      "Epoch 33/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 17.4835\n",
      "Epoch 33: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.3003 - val_loss: 21.0333\n",
      "Epoch 34/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 17.9080\n",
      "Epoch 34: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.6979 - val_loss: 21.5642\n",
      "Epoch 35/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 16.0237\n",
      "Epoch 35: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.9578 - val_loss: 19.3621\n",
      "Epoch 36/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 18.2286\n",
      "Epoch 36: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.5646 - val_loss: 22.1889\n",
      "Epoch 37/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 16.9903\n",
      "Epoch 37: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.5928 - val_loss: 19.3101\n",
      "Epoch 38/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 17.1678\n",
      "Epoch 38: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.2781 - val_loss: 20.0998\n",
      "Epoch 39/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 17.0124\n",
      "Epoch 39: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.4875 - val_loss: 20.0814\n",
      "Epoch 40/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 16.2789\n",
      "Epoch 40: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.9163 - val_loss: 20.1084\n",
      "Epoch 41/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 18.0307\n",
      "Epoch 41: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.0260 - val_loss: 24.3862\n",
      "Epoch 42/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 15.7881\n",
      "Epoch 42: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.7853 - val_loss: 23.2208\n",
      "Epoch 43/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 16.1761\n",
      "Epoch 43: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.1987 - val_loss: 21.8313\n",
      "Epoch 44/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 16.1304\n",
      "Epoch 44: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.6545 - val_loss: 19.8576\n",
      "Epoch 45/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 15.8025\n",
      "Epoch 45: val_loss did not improve from 14.02987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 16.0752 - val_loss: 18.4798\n",
      "Epoch 46/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 15.4834\n",
      "Epoch 46: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.2834 - val_loss: 21.8466\n",
      "Epoch 47/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 15.6588\n",
      "Epoch 47: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.9419 - val_loss: 29.1495\n",
      "Epoch 48/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 15.9187\n",
      "Epoch 48: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.9089 - val_loss: 22.5043\n",
      "Epoch 49/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 14.4164\n",
      "Epoch 49: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.1091 - val_loss: 23.3566\n",
      "Epoch 50/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 14.8360\n",
      "Epoch 50: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.4115 - val_loss: 21.9353\n",
      "Epoch 51/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 14.8112\n",
      "Epoch 51: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.6429 - val_loss: 18.4377\n",
      "Epoch 52/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 14.8022\n",
      "Epoch 52: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.8126 - val_loss: 23.8284\n",
      "Epoch 53/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 14.1735\n",
      "Epoch 53: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.1058 - val_loss: 21.1073\n",
      "Epoch 54/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 14.7920\n",
      "Epoch 54: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.6868 - val_loss: 20.4692\n",
      "Epoch 55/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 14.2431\n",
      "Epoch 55: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.4420 - val_loss: 20.0444\n",
      "Epoch 56/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 14.1915\n",
      "Epoch 56: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.9853 - val_loss: 26.1269\n",
      "Epoch 57/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 14.3097\n",
      "Epoch 57: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.2189 - val_loss: 25.7936\n",
      "Epoch 58/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 14.0341\n",
      "Epoch 58: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.7629 - val_loss: 21.6681\n",
      "Epoch 59/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 13.2881\n",
      "Epoch 59: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.2708 - val_loss: 25.2112\n",
      "Epoch 60/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 13.8261\n",
      "Epoch 60: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.7781 - val_loss: 20.9722\n",
      "Epoch 61/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 14.5476\n",
      "Epoch 61: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.2008 - val_loss: 19.7860\n",
      "Epoch 62/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 14.9657\n",
      "Epoch 62: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.2892 - val_loss: 24.1133\n",
      "Epoch 63/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 13.2966\n",
      "Epoch 63: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.0045 - val_loss: 22.3669\n",
      "Epoch 64/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 13.0938\n",
      "Epoch 64: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.9119 - val_loss: 23.2510\n",
      "Epoch 65/700\n",
      "60/84 [====================>.........] - ETA: 0s - loss: 13.4686\n",
      "Epoch 65: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.9539 - val_loss: 25.5528\n",
      "Epoch 66/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 13.6688\n",
      "Epoch 66: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.0580 - val_loss: 27.9312\n",
      "Epoch 67/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 12.3393\n",
      "Epoch 67: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.9390 - val_loss: 23.0812\n",
      "Epoch 68/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 12.5879\n",
      "Epoch 68: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.2074 - val_loss: 22.6721\n",
      "Epoch 69/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 12.2296\n",
      "Epoch 69: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.2931 - val_loss: 20.9882\n",
      "Epoch 70/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 12.9797\n",
      "Epoch 70: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.9312 - val_loss: 22.4919\n",
      "Epoch 71/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 13.1016\n",
      "Epoch 71: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.1776 - val_loss: 20.7342\n",
      "Epoch 72/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 13.4861\n",
      "Epoch 72: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.5099 - val_loss: 25.2233\n",
      "Epoch 73/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 11.9547\n",
      "Epoch 73: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.9411 - val_loss: 25.6873\n",
      "Epoch 74/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 12.6696\n",
      "Epoch 74: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.3418 - val_loss: 20.9240\n",
      "Epoch 75/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 12.8031\n",
      "Epoch 75: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.7644 - val_loss: 20.7138\n",
      "Epoch 76/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 13.1996\n",
      "Epoch 76: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.1161 - val_loss: 18.8030\n",
      "Epoch 77/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 13.7108\n",
      "Epoch 77: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.2065 - val_loss: 19.8246\n",
      "Epoch 78/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 13.4724\n",
      "Epoch 78: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.4921 - val_loss: 23.1929\n",
      "Epoch 79/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 11.8160\n",
      "Epoch 79: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.1779 - val_loss: 21.0665\n",
      "Epoch 80/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 11.1986\n",
      "Epoch 80: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.7263 - val_loss: 18.7468\n",
      "Epoch 81/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 12.1749\n",
      "Epoch 81: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.2172 - val_loss: 22.1183\n",
      "Epoch 82/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 13.0443\n",
      "Epoch 82: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.7771 - val_loss: 21.1400\n",
      "Epoch 83/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 11.3792\n",
      "Epoch 83: val_loss did not improve from 14.02987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 11.7627 - val_loss: 23.9761\n",
      "Epoch 84/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 11.5855\n",
      "Epoch 84: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.1097 - val_loss: 22.7966\n",
      "Epoch 85/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 10.8704\n",
      "Epoch 85: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.7655 - val_loss: 16.5726\n",
      "Epoch 86/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 11.1527\n",
      "Epoch 86: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.0364 - val_loss: 22.8758\n",
      "Epoch 87/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 12.0277\n",
      "Epoch 87: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.8832 - val_loss: 27.8065\n",
      "Epoch 88/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 12.0533\n",
      "Epoch 88: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.9831 - val_loss: 18.5194\n",
      "Epoch 89/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 11.7041\n",
      "Epoch 89: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.3305 - val_loss: 21.1037\n",
      "Epoch 90/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 11.9811\n",
      "Epoch 90: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.5239 - val_loss: 24.2413\n",
      "Epoch 91/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 11.0399\n",
      "Epoch 91: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.0879 - val_loss: 17.9992\n",
      "Epoch 92/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 11.0662\n",
      "Epoch 92: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.0727 - val_loss: 19.4614\n",
      "Epoch 93/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 10.7928\n",
      "Epoch 93: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.9932 - val_loss: 25.7318\n",
      "Epoch 94/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 10.7795\n",
      "Epoch 94: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.9788 - val_loss: 19.5326\n",
      "Epoch 95/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 10.5872\n",
      "Epoch 95: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.4222 - val_loss: 24.2723\n",
      "Epoch 96/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 11.8604\n",
      "Epoch 96: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.0978 - val_loss: 24.0004\n",
      "Epoch 97/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 10.9240\n",
      "Epoch 97: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.8888 - val_loss: 16.2428\n",
      "Epoch 98/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 10.6419\n",
      "Epoch 98: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.9300 - val_loss: 23.1895\n",
      "Epoch 99/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 11.2257\n",
      "Epoch 99: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.9356 - val_loss: 20.0620\n",
      "Epoch 100/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 10.0536\n",
      "Epoch 100: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.0112 - val_loss: 21.5298\n",
      "Epoch 101/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 10.7071\n",
      "Epoch 101: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.6368 - val_loss: 24.3450\n",
      "Epoch 102/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 11.1169\n",
      "Epoch 102: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.0293 - val_loss: 23.1601\n",
      "Epoch 103/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 11.5736\n",
      "Epoch 103: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.5151 - val_loss: 19.6251\n",
      "Epoch 104/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 10.3761\n",
      "Epoch 104: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.3610 - val_loss: 22.2202\n",
      "Epoch 105/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 9.9869\n",
      "Epoch 105: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.0686 - val_loss: 20.8109\n",
      "Epoch 106/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 10.7444\n",
      "Epoch 106: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.8699 - val_loss: 18.1080\n",
      "Epoch 107/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 10.3375\n",
      "Epoch 107: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.3579 - val_loss: 20.3667\n",
      "Epoch 108/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 10.0221\n",
      "Epoch 108: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.3937 - val_loss: 21.9996\n",
      "Epoch 109/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 10.5419\n",
      "Epoch 109: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.4032 - val_loss: 21.7346\n",
      "Epoch 110/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 10.5063\n",
      "Epoch 110: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.2802 - val_loss: 19.2917\n",
      "Epoch 111/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 11.3205\n",
      "Epoch 111: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.9781 - val_loss: 20.9286\n",
      "Epoch 112/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 9.3731\n",
      "Epoch 112: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.7125 - val_loss: 22.7243\n",
      "Epoch 113/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 10.5995\n",
      "Epoch 113: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.5705 - val_loss: 23.7159\n",
      "Epoch 114/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 9.4120\n",
      "Epoch 114: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2578 - val_loss: 22.0563\n",
      "Epoch 115/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 9.7831\n",
      "Epoch 115: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.7973 - val_loss: 21.1390\n",
      "Epoch 116/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 10.5566\n",
      "Epoch 116: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.7213 - val_loss: 20.9207\n",
      "Epoch 117/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 9.9346\n",
      "Epoch 117: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.9476 - val_loss: 20.6415\n",
      "Epoch 118/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 9.8760\n",
      "Epoch 118: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.7057 - val_loss: 23.0528\n",
      "Epoch 119/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 9.8892 \n",
      "Epoch 119: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.9254 - val_loss: 23.5814\n",
      "Epoch 120/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 10.2677\n",
      "Epoch 120: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.0637 - val_loss: 18.5676\n",
      "Epoch 121/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 9.7849 \n",
      "Epoch 121: val_loss did not improve from 14.02987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 9.5060 - val_loss: 23.0000\n",
      "Epoch 122/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 9.6374\n",
      "Epoch 122: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.5586 - val_loss: 20.9020\n",
      "Epoch 123/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.7802\n",
      "Epoch 123: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.8289 - val_loss: 18.8694\n",
      "Epoch 124/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 9.5376\n",
      "Epoch 124: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.5774 - val_loss: 17.5646\n",
      "Epoch 125/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 9.1241\n",
      "Epoch 125: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.3353 - val_loss: 20.8341\n",
      "Epoch 126/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 9.3193\n",
      "Epoch 126: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.3592 - val_loss: 22.4948\n",
      "Epoch 127/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 9.7392\n",
      "Epoch 127: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.6690 - val_loss: 19.1816\n",
      "Epoch 128/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 10.1268\n",
      "Epoch 128: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.0538 - val_loss: 18.1723\n",
      "Epoch 129/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 9.2781\n",
      "Epoch 129: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2781 - val_loss: 25.4899\n",
      "Epoch 130/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 9.4640\n",
      "Epoch 130: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2682 - val_loss: 20.6392\n",
      "Epoch 131/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 9.0829\n",
      "Epoch 131: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1210 - val_loss: 25.5259\n",
      "Epoch 132/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 9.6687 \n",
      "Epoch 132: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.4735 - val_loss: 21.3722\n",
      "Epoch 133/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 9.6279\n",
      "Epoch 133: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.5348 - val_loss: 20.2146\n",
      "Epoch 134/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.8639\n",
      "Epoch 134: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9984 - val_loss: 26.7551\n",
      "Epoch 135/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 10.4735\n",
      "Epoch 135: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.3582 - val_loss: 24.3479\n",
      "Epoch 136/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 9.6467\n",
      "Epoch 136: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.4031 - val_loss: 20.9305\n",
      "Epoch 137/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 8.9075\n",
      "Epoch 137: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9191 - val_loss: 21.8742\n",
      "Epoch 138/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 9.4181\n",
      "Epoch 138: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2073 - val_loss: 22.4595\n",
      "Epoch 139/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 9.6748\n",
      "Epoch 139: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.6066 - val_loss: 23.4097\n",
      "Epoch 140/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 10.0672\n",
      "Epoch 140: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.6713 - val_loss: 21.5779\n",
      "Epoch 141/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 9.4704\n",
      "Epoch 141: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.5196 - val_loss: 20.5363\n",
      "Epoch 142/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 9.4632\n",
      "Epoch 142: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.8633 - val_loss: 18.2775\n",
      "Epoch 143/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 9.3115\n",
      "Epoch 143: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1107 - val_loss: 22.0251\n",
      "Epoch 144/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.7852\n",
      "Epoch 144: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4861 - val_loss: 20.5974\n",
      "Epoch 145/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 8.2537\n",
      "Epoch 145: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3086 - val_loss: 25.5427\n",
      "Epoch 146/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 10.2442\n",
      "Epoch 146: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.2250 - val_loss: 22.6190\n",
      "Epoch 147/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 9.1099\n",
      "Epoch 147: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1469 - val_loss: 22.3979\n",
      "Epoch 148/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.2073\n",
      "Epoch 148: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5811 - val_loss: 22.6120\n",
      "Epoch 149/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 9.4107\n",
      "Epoch 149: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.5350 - val_loss: 20.2600\n",
      "Epoch 150/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 10.6357\n",
      "Epoch 150: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 10.6202 - val_loss: 23.3203\n",
      "Epoch 151/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 9.8205\n",
      "Epoch 151: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.4144 - val_loss: 21.8050\n",
      "Epoch 152/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 8.5134\n",
      "Epoch 152: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7404 - val_loss: 20.2944\n",
      "Epoch 153/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 9.0885\n",
      "Epoch 153: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9825 - val_loss: 21.6712\n",
      "Epoch 154/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 8.8368\n",
      "Epoch 154: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9248 - val_loss: 20.6196\n",
      "Epoch 155/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.4597\n",
      "Epoch 155: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7102 - val_loss: 20.2978\n",
      "Epoch 156/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 8.7797\n",
      "Epoch 156: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7797 - val_loss: 19.9712\n",
      "Epoch 157/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 9.3102\n",
      "Epoch 157: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.3102 - val_loss: 22.7143\n",
      "Epoch 158/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 8.7782\n",
      "Epoch 158: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7962 - val_loss: 22.4810\n",
      "Epoch 159/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 9.1520\n",
      "Epoch 159: val_loss did not improve from 14.02987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 9.4249 - val_loss: 20.3112\n",
      "Epoch 160/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 8.6182\n",
      "Epoch 160: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5356 - val_loss: 21.1087\n",
      "Epoch 161/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.6804\n",
      "Epoch 161: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9377 - val_loss: 22.0153\n",
      "Epoch 162/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 8.9914\n",
      "Epoch 162: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.8451 - val_loss: 20.2386\n",
      "Epoch 163/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 8.3058\n",
      "Epoch 163: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3536 - val_loss: 19.5809\n",
      "Epoch 164/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 8.5235\n",
      "Epoch 164: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4899 - val_loss: 19.5403\n",
      "Epoch 165/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 7.9538\n",
      "Epoch 165: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3169 - val_loss: 26.1273\n",
      "Epoch 166/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 9.0047\n",
      "Epoch 166: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9536 - val_loss: 20.2099\n",
      "Epoch 167/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 8.7124\n",
      "Epoch 167: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6878 - val_loss: 22.0435\n",
      "Epoch 168/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 8.5552\n",
      "Epoch 168: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5428 - val_loss: 22.7631\n",
      "Epoch 169/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 8.5484\n",
      "Epoch 169: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9085 - val_loss: 19.8032\n",
      "Epoch 170/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 8.6649\n",
      "Epoch 170: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.8045 - val_loss: 20.3533\n",
      "Epoch 171/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 9.2730\n",
      "Epoch 171: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7498 - val_loss: 21.6263\n",
      "Epoch 172/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 8.2952\n",
      "Epoch 172: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4980 - val_loss: 22.2136\n",
      "Epoch 173/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 8.5487\n",
      "Epoch 173: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3974 - val_loss: 23.5153\n",
      "Epoch 174/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 9.3520\n",
      "Epoch 174: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2530 - val_loss: 21.7239\n",
      "Epoch 175/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 8.3293\n",
      "Epoch 175: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3705 - val_loss: 22.0957\n",
      "Epoch 176/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 8.7622\n",
      "Epoch 176: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1410 - val_loss: 20.4484\n",
      "Epoch 177/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.5293\n",
      "Epoch 177: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3124 - val_loss: 20.1719\n",
      "Epoch 178/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 9.8129\n",
      "Epoch 178: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.7664 - val_loss: 19.2160\n",
      "Epoch 179/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 8.2210\n",
      "Epoch 179: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9969 - val_loss: 22.5711\n",
      "Epoch 180/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 8.5283\n",
      "Epoch 180: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4888 - val_loss: 18.8194\n",
      "Epoch 181/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 8.2940\n",
      "Epoch 181: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4638 - val_loss: 23.7021\n",
      "Epoch 182/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.0541\n",
      "Epoch 182: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1272 - val_loss: 19.0939\n",
      "Epoch 183/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 9.1078\n",
      "Epoch 183: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1668 - val_loss: 20.1524\n",
      "Epoch 184/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 8.3678\n",
      "Epoch 184: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 8.6238 - val_loss: 21.1372\n",
      "Epoch 185/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 8.5292\n",
      "Epoch 185: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6273 - val_loss: 21.8008\n",
      "Epoch 186/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 8.6880\n",
      "Epoch 186: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0422 - val_loss: 21.3079\n",
      "Epoch 187/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 7.6823\n",
      "Epoch 187: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5919 - val_loss: 21.6355\n",
      "Epoch 188/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.3324\n",
      "Epoch 188: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4243 - val_loss: 23.8588\n",
      "Epoch 189/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 8.0538\n",
      "Epoch 189: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4146 - val_loss: 21.4162\n",
      "Epoch 190/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 9.2805\n",
      "Epoch 190: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2625 - val_loss: 20.4832\n",
      "Epoch 191/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 8.6705\n",
      "Epoch 191: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6759 - val_loss: 18.9690\n",
      "Epoch 192/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 8.3755\n",
      "Epoch 192: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3755 - val_loss: 20.9781\n",
      "Epoch 193/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.8984\n",
      "Epoch 193: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9610 - val_loss: 21.0284\n",
      "Epoch 194/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.4968\n",
      "Epoch 194: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4968 - val_loss: 18.3618\n",
      "Epoch 195/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 9.6223 \n",
      "Epoch 195: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1538 - val_loss: 21.3498\n",
      "Epoch 196/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 7.9636\n",
      "Epoch 196: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3521 - val_loss: 24.4103\n",
      "Epoch 197/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 9.0402\n",
      "Epoch 197: val_loss did not improve from 14.02987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 8.8986 - val_loss: 18.7690\n",
      "Epoch 198/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 9.0608\n",
      "Epoch 198: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6954 - val_loss: 19.3376\n",
      "Epoch 199/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.2594\n",
      "Epoch 199: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4268 - val_loss: 19.9457\n",
      "Epoch 200/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 7.6727\n",
      "Epoch 200: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9425 - val_loss: 26.2526\n",
      "Epoch 201/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.0720\n",
      "Epoch 201: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3146 - val_loss: 23.3962\n",
      "Epoch 202/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 8.6237\n",
      "Epoch 202: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4780 - val_loss: 22.6910\n",
      "Epoch 203/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 8.6654\n",
      "Epoch 203: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6833 - val_loss: 23.8601\n",
      "Epoch 204/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 8.5852\n",
      "Epoch 204: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5852 - val_loss: 22.2083\n",
      "Epoch 205/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 7.8733\n",
      "Epoch 205: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0093 - val_loss: 21.2900\n",
      "Epoch 206/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 9.3844\n",
      "Epoch 206: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0849 - val_loss: 24.1752\n",
      "Epoch 207/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.7089\n",
      "Epoch 207: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9328 - val_loss: 24.1287\n",
      "Epoch 208/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.3713\n",
      "Epoch 208: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2359 - val_loss: 22.9530\n",
      "Epoch 209/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.8972\n",
      "Epoch 209: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7595 - val_loss: 22.9990\n",
      "Epoch 210/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.9661\n",
      "Epoch 210: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9164 - val_loss: 22.4153\n",
      "Epoch 211/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 8.1210\n",
      "Epoch 211: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4439 - val_loss: 22.9727\n",
      "Epoch 212/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 8.3961\n",
      "Epoch 212: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3001 - val_loss: 20.8880\n",
      "Epoch 213/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 7.9129\n",
      "Epoch 213: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9098 - val_loss: 20.6839\n",
      "Epoch 214/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 7.8026\n",
      "Epoch 214: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7485 - val_loss: 21.9048\n",
      "Epoch 215/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.8798\n",
      "Epoch 215: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7857 - val_loss: 22.8909\n",
      "Epoch 216/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.6295\n",
      "Epoch 216: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7408 - val_loss: 19.6946\n",
      "Epoch 217/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 7.9230\n",
      "Epoch 217: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8979 - val_loss: 21.2390\n",
      "Epoch 218/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.8175\n",
      "Epoch 218: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6510 - val_loss: 22.5652\n",
      "Epoch 219/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.2287\n",
      "Epoch 219: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2648 - val_loss: 24.0147\n",
      "Epoch 220/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.8350\n",
      "Epoch 220: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8350 - val_loss: 22.9342\n",
      "Epoch 221/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 8.6577\n",
      "Epoch 221: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7554 - val_loss: 20.2393\n",
      "Epoch 222/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 8.0395\n",
      "Epoch 222: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9760 - val_loss: 24.7724\n",
      "Epoch 223/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.9804\n",
      "Epoch 223: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8962 - val_loss: 22.6381\n",
      "Epoch 224/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 7.1480\n",
      "Epoch 224: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1587 - val_loss: 21.5204\n",
      "Epoch 225/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 7.7526\n",
      "Epoch 225: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6998 - val_loss: 21.6794\n",
      "Epoch 226/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 8.0531\n",
      "Epoch 226: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9708 - val_loss: 19.2581\n",
      "Epoch 227/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 7.8428\n",
      "Epoch 227: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6749 - val_loss: 21.9815\n",
      "Epoch 228/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.6674\n",
      "Epoch 228: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5713 - val_loss: 21.9290\n",
      "Epoch 229/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.8094\n",
      "Epoch 229: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7373 - val_loss: 23.2495\n",
      "Epoch 230/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.4886\n",
      "Epoch 230: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7066 - val_loss: 21.0062\n",
      "Epoch 231/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 7.1614\n",
      "Epoch 231: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2692 - val_loss: 21.3291\n",
      "Epoch 232/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 7.8090\n",
      "Epoch 232: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0024 - val_loss: 23.4193\n",
      "Epoch 233/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 7.2919\n",
      "Epoch 233: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2620 - val_loss: 20.2142\n",
      "Epoch 234/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.9657\n",
      "Epoch 234: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9255 - val_loss: 22.0580\n",
      "Epoch 235/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.4578\n",
      "Epoch 235: val_loss did not improve from 14.02987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4561 - val_loss: 20.7391\n",
      "Epoch 236/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.4557\n",
      "Epoch 236: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4385 - val_loss: 22.4168\n",
      "Epoch 237/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 7.9039\n",
      "Epoch 237: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7035 - val_loss: 23.8783\n",
      "Epoch 238/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.6691\n",
      "Epoch 238: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6189 - val_loss: 22.5774\n",
      "Epoch 239/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 7.6438\n",
      "Epoch 239: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5249 - val_loss: 23.1322\n",
      "Epoch 240/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 7.6763\n",
      "Epoch 240: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7609 - val_loss: 24.0125\n",
      "Epoch 241/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.7695\n",
      "Epoch 241: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5900 - val_loss: 23.2788\n",
      "Epoch 242/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.2369\n",
      "Epoch 242: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1217 - val_loss: 26.0230\n",
      "Epoch 243/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 8.3244\n",
      "Epoch 243: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2237 - val_loss: 19.9901\n",
      "Epoch 244/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.6447\n",
      "Epoch 244: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5430 - val_loss: 21.6459\n",
      "Epoch 245/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 7.6869\n",
      "Epoch 245: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6267 - val_loss: 20.5336\n",
      "Epoch 246/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.9051\n",
      "Epoch 246: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9802 - val_loss: 24.8891\n",
      "Epoch 247/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.2651\n",
      "Epoch 247: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2225 - val_loss: 22.3252\n",
      "Epoch 248/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 7.6745\n",
      "Epoch 248: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5812 - val_loss: 19.7489\n",
      "Epoch 249/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.5586\n",
      "Epoch 249: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4103 - val_loss: 21.6707\n",
      "Epoch 250/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 7.5202\n",
      "Epoch 250: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5244 - val_loss: 24.2406\n",
      "Epoch 251/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.7345\n",
      "Epoch 251: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7345 - val_loss: 22.5894\n",
      "Epoch 252/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.7402\n",
      "Epoch 252: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7012 - val_loss: 20.3037\n",
      "Epoch 253/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.0075\n",
      "Epoch 253: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3832 - val_loss: 24.4154\n",
      "Epoch 254/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 7.3663\n",
      "Epoch 254: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3255 - val_loss: 23.9165\n",
      "Epoch 255/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.2323\n",
      "Epoch 255: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3116 - val_loss: 21.6593\n",
      "Epoch 256/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 7.4961\n",
      "Epoch 256: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4074 - val_loss: 23.5468\n",
      "Epoch 257/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.9960\n",
      "Epoch 257: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9960 - val_loss: 24.3704\n",
      "Epoch 258/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.1970\n",
      "Epoch 258: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2608 - val_loss: 21.2354\n",
      "Epoch 259/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 7.3030\n",
      "Epoch 259: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2764 - val_loss: 22.0062\n",
      "Epoch 260/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.1760\n",
      "Epoch 260: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1598 - val_loss: 20.9206\n",
      "Epoch 261/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.1416\n",
      "Epoch 261: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1804 - val_loss: 22.0022\n",
      "Epoch 262/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 7.0634\n",
      "Epoch 262: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3803 - val_loss: 22.5673\n",
      "Epoch 263/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.1733\n",
      "Epoch 263: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2215 - val_loss: 22.7590\n",
      "Epoch 264/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 7.4850\n",
      "Epoch 264: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4113 - val_loss: 21.8857\n",
      "Epoch 265/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 7.5631\n",
      "Epoch 265: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3420 - val_loss: 23.3197\n",
      "Epoch 266/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.2074\n",
      "Epoch 266: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1472 - val_loss: 23.6886\n",
      "Epoch 267/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.1849\n",
      "Epoch 267: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2678 - val_loss: 22.3890\n",
      "Epoch 268/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.2135\n",
      "Epoch 268: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2135 - val_loss: 24.5336\n",
      "Epoch 269/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.1481\n",
      "Epoch 269: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5276 - val_loss: 22.3817\n",
      "Epoch 270/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 8.5965\n",
      "Epoch 270: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.4062 - val_loss: 22.1755\n",
      "Epoch 271/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 6.7679\n",
      "Epoch 271: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7888 - val_loss: 24.1765\n",
      "Epoch 272/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.5356\n",
      "Epoch 272: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8207 - val_loss: 25.6353\n",
      "Epoch 273/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.1436\n",
      "Epoch 273: val_loss did not improve from 14.02987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2208 - val_loss: 19.2679\n",
      "Epoch 274/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.9074\n",
      "Epoch 274: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7629 - val_loss: 21.2335\n",
      "Epoch 275/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.2217\n",
      "Epoch 275: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3476 - val_loss: 21.2518\n",
      "Epoch 276/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.8050\n",
      "Epoch 276: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9310 - val_loss: 21.2531\n",
      "Epoch 277/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.7102\n",
      "Epoch 277: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6442 - val_loss: 20.8631\n",
      "Epoch 278/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.4213\n",
      "Epoch 278: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3047 - val_loss: 25.7431\n",
      "Epoch 279/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.0922\n",
      "Epoch 279: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9953 - val_loss: 21.0176\n",
      "Epoch 280/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 7.2791\n",
      "Epoch 280: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3517 - val_loss: 20.1406\n",
      "Epoch 281/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.8663\n",
      "Epoch 281: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8999 - val_loss: 22.2278\n",
      "Epoch 282/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.1801\n",
      "Epoch 282: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2797 - val_loss: 23.4181\n",
      "Epoch 283/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.0180\n",
      "Epoch 283: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0688 - val_loss: 24.4465\n",
      "Epoch 284/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.7741\n",
      "Epoch 284: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7564 - val_loss: 25.0044\n",
      "Epoch 285/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.9591\n",
      "Epoch 285: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0048 - val_loss: 21.9554\n",
      "Epoch 286/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.8593\n",
      "Epoch 286: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9180 - val_loss: 21.9003\n",
      "Epoch 287/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.0462\n",
      "Epoch 287: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0432 - val_loss: 20.6789\n",
      "Epoch 288/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.7608\n",
      "Epoch 288: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7310 - val_loss: 20.9610\n",
      "Epoch 289/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.2843\n",
      "Epoch 289: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.2429 - val_loss: 22.8095\n",
      "Epoch 290/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.2665\n",
      "Epoch 290: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.2388 - val_loss: 20.2549\n",
      "Epoch 291/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.4927\n",
      "Epoch 291: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5397 - val_loss: 20.1572\n",
      "Epoch 292/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.0850\n",
      "Epoch 292: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0850 - val_loss: 22.3242\n",
      "Epoch 293/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 7.0126\n",
      "Epoch 293: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2174 - val_loss: 20.4527\n",
      "Epoch 294/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.6401\n",
      "Epoch 294: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5200 - val_loss: 23.4835\n",
      "Epoch 295/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.2179\n",
      "Epoch 295: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2809 - val_loss: 20.8391\n",
      "Epoch 296/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.0910\n",
      "Epoch 296: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8918 - val_loss: 23.4477\n",
      "Epoch 297/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.8671\n",
      "Epoch 297: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9921 - val_loss: 21.4929\n",
      "Epoch 298/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 6.7955\n",
      "Epoch 298: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6922 - val_loss: 21.5067\n",
      "Epoch 299/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.5218\n",
      "Epoch 299: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4898 - val_loss: 21.0193\n",
      "Epoch 300/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.3760\n",
      "Epoch 300: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4322 - val_loss: 21.5444\n",
      "Epoch 301/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 6.3899\n",
      "Epoch 301: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5052 - val_loss: 21.0452\n",
      "Epoch 302/700\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 6.2849\n",
      "Epoch 302: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3469 - val_loss: 21.7861\n",
      "Epoch 303/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 7.6882\n",
      "Epoch 303: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5464 - val_loss: 21.3499\n",
      "Epoch 304/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 6.2440\n",
      "Epoch 304: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4858 - val_loss: 19.8981\n",
      "Epoch 305/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.6987\n",
      "Epoch 305: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9251 - val_loss: 20.9075\n",
      "Epoch 306/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.6520\n",
      "Epoch 306: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7939 - val_loss: 22.7599\n",
      "Epoch 307/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.7070\n",
      "Epoch 307: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6804 - val_loss: 25.6381\n",
      "Epoch 308/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.5036\n",
      "Epoch 308: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8443 - val_loss: 20.3824\n",
      "Epoch 309/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.9166\n",
      "Epoch 309: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9166 - val_loss: 21.7825\n",
      "Epoch 310/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 7.0171\n",
      "Epoch 310: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9892 - val_loss: 20.7142\n",
      "Epoch 311/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.9648\n",
      "Epoch 311: val_loss did not improve from 14.02987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9875 - val_loss: 19.7695\n",
      "Epoch 312/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 6.0883\n",
      "Epoch 312: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0515 - val_loss: 22.8241\n",
      "Epoch 313/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.7493\n",
      "Epoch 313: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7335 - val_loss: 21.2241\n",
      "Epoch 314/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 6.0028\n",
      "Epoch 314: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1489 - val_loss: 21.9653\n",
      "Epoch 315/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.6655\n",
      "Epoch 315: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8127 - val_loss: 20.9683\n",
      "Epoch 316/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 7.2061\n",
      "Epoch 316: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2046 - val_loss: 21.2778\n",
      "Epoch 317/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.5003\n",
      "Epoch 317: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5003 - val_loss: 22.9828\n",
      "Epoch 318/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 6.8475\n",
      "Epoch 318: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6911 - val_loss: 20.6194\n",
      "Epoch 319/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.8352\n",
      "Epoch 319: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7740 - val_loss: 17.5227\n",
      "Epoch 320/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.0704\n",
      "Epoch 320: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9937 - val_loss: 19.9244\n",
      "Epoch 321/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.5048\n",
      "Epoch 321: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5765 - val_loss: 19.7823\n",
      "Epoch 322/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 7.1005\n",
      "Epoch 322: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9416 - val_loss: 19.5069\n",
      "Epoch 323/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.7049\n",
      "Epoch 323: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7046 - val_loss: 20.2924\n",
      "Epoch 324/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.6251\n",
      "Epoch 324: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6996 - val_loss: 19.3477\n",
      "Epoch 325/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.9403\n",
      "Epoch 325: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9401 - val_loss: 19.4087\n",
      "Epoch 326/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.2177\n",
      "Epoch 326: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2177 - val_loss: 21.4741\n",
      "Epoch 327/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.9702\n",
      "Epoch 327: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9423 - val_loss: 21.8714\n",
      "Epoch 328/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.8459\n",
      "Epoch 328: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8459 - val_loss: 20.3863\n",
      "Epoch 329/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.2651\n",
      "Epoch 329: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2571 - val_loss: 19.6579\n",
      "Epoch 330/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.4467\n",
      "Epoch 330: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2905 - val_loss: 21.9160\n",
      "Epoch 331/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.8579\n",
      "Epoch 331: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8323 - val_loss: 18.7244\n",
      "Epoch 332/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.5270\n",
      "Epoch 332: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5267 - val_loss: 19.7524\n",
      "Epoch 333/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.7732\n",
      "Epoch 333: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6078 - val_loss: 19.1122\n",
      "Epoch 334/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.6783\n",
      "Epoch 334: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4293 - val_loss: 18.6085\n",
      "Epoch 335/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.6477\n",
      "Epoch 335: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6517 - val_loss: 19.2784\n",
      "Epoch 336/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.4335\n",
      "Epoch 336: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2351 - val_loss: 21.3039\n",
      "Epoch 337/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.0292\n",
      "Epoch 337: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1340 - val_loss: 20.7080\n",
      "Epoch 338/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.8868\n",
      "Epoch 338: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0530 - val_loss: 20.1837\n",
      "Epoch 339/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.2515\n",
      "Epoch 339: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2521 - val_loss: 20.7791\n",
      "Epoch 340/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.7287\n",
      "Epoch 340: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5891 - val_loss: 20.9137\n",
      "Epoch 341/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.7367\n",
      "Epoch 341: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8542 - val_loss: 20.5086\n",
      "Epoch 342/700\n",
      "59/84 [====================>.........] - ETA: 0s - loss: 6.2052\n",
      "Epoch 342: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2388 - val_loss: 19.2945\n",
      "Epoch 343/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.7123\n",
      "Epoch 343: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4516 - val_loss: 19.8483\n",
      "Epoch 344/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.1018\n",
      "Epoch 344: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2178 - val_loss: 21.4564\n",
      "Epoch 345/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.1382\n",
      "Epoch 345: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1274 - val_loss: 21.6128\n",
      "Epoch 346/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.8894\n",
      "Epoch 346: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7141 - val_loss: 21.7681\n",
      "Epoch 347/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.7972\n",
      "Epoch 347: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8966 - val_loss: 19.0619\n",
      "Epoch 348/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 5.5188\n",
      "Epoch 348: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0338 - val_loss: 19.0595\n",
      "Epoch 349/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.8644\n",
      "Epoch 349: val_loss did not improve from 14.02987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9863 - val_loss: 19.7925\n",
      "Epoch 350/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.7573\n",
      "Epoch 350: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7670 - val_loss: 22.3969\n",
      "Epoch 351/700\n",
      "57/84 [===================>..........] - ETA: 0s - loss: 6.8841\n",
      "Epoch 351: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9821 - val_loss: 19.9830\n",
      "Epoch 352/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.3350\n",
      "Epoch 352: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2547 - val_loss: 18.3969\n",
      "Epoch 353/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.2451\n",
      "Epoch 353: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3769 - val_loss: 21.7891\n",
      "Epoch 354/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.0448\n",
      "Epoch 354: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9688 - val_loss: 21.3777\n",
      "Epoch 355/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.4415\n",
      "Epoch 355: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4878 - val_loss: 20.1774\n",
      "Epoch 356/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.7378\n",
      "Epoch 356: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6614 - val_loss: 20.4176\n",
      "Epoch 357/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.8218\n",
      "Epoch 357: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8630 - val_loss: 20.7930\n",
      "Epoch 358/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.5709\n",
      "Epoch 358: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5346 - val_loss: 21.0863\n",
      "Epoch 359/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.2124\n",
      "Epoch 359: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9124 - val_loss: 19.7897\n",
      "Epoch 360/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.2553\n",
      "Epoch 360: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3032 - val_loss: 20.6393\n",
      "Epoch 361/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.4686\n",
      "Epoch 361: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3042 - val_loss: 19.5728\n",
      "Epoch 362/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.1666\n",
      "Epoch 362: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9357 - val_loss: 19.3754\n",
      "Epoch 363/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.0401\n",
      "Epoch 363: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0040 - val_loss: 18.7169\n",
      "Epoch 364/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.6779\n",
      "Epoch 364: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9170 - val_loss: 19.3245\n",
      "Epoch 365/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.1836\n",
      "Epoch 365: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1836 - val_loss: 19.9040\n",
      "Epoch 366/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.9941\n",
      "Epoch 366: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2432 - val_loss: 18.8173\n",
      "Epoch 367/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.6391\n",
      "Epoch 367: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6558 - val_loss: 20.2476\n",
      "Epoch 368/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.8673\n",
      "Epoch 368: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8355 - val_loss: 19.8586\n",
      "Epoch 369/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.3292\n",
      "Epoch 369: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3554 - val_loss: 21.1132\n",
      "Epoch 370/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 5.9586\n",
      "Epoch 370: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1033 - val_loss: 22.5354\n",
      "Epoch 371/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.1010\n",
      "Epoch 371: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1020 - val_loss: 17.9387\n",
      "Epoch 372/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.9555\n",
      "Epoch 372: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0974 - val_loss: 21.3461\n",
      "Epoch 373/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.9136\n",
      "Epoch 373: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3615 - val_loss: 18.2127\n",
      "Epoch 374/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.9068\n",
      "Epoch 374: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9770 - val_loss: 20.4509\n",
      "Epoch 375/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.1650\n",
      "Epoch 375: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1554 - val_loss: 20.4581\n",
      "Epoch 376/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.5975\n",
      "Epoch 376: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5747 - val_loss: 19.0063\n",
      "Epoch 377/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.8973\n",
      "Epoch 377: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8960 - val_loss: 19.5593\n",
      "Epoch 378/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.5769\n",
      "Epoch 378: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6390 - val_loss: 17.6786\n",
      "Epoch 379/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.9820\n",
      "Epoch 379: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0913 - val_loss: 20.3529\n",
      "Epoch 380/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.7980\n",
      "Epoch 380: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9332 - val_loss: 17.9695\n",
      "Epoch 381/700\n",
      "60/84 [====================>.........] - ETA: 0s - loss: 6.1361\n",
      "Epoch 381: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0230 - val_loss: 19.3688\n",
      "Epoch 382/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.9887\n",
      "Epoch 382: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9879 - val_loss: 21.0655\n",
      "Epoch 383/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.6680\n",
      "Epoch 383: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5649 - val_loss: 19.0500\n",
      "Epoch 384/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.4249\n",
      "Epoch 384: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2662 - val_loss: 19.6797\n",
      "Epoch 385/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.1770\n",
      "Epoch 385: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3984 - val_loss: 21.8230\n",
      "Epoch 386/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.6696\n",
      "Epoch 386: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7331 - val_loss: 19.9329\n",
      "Epoch 387/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.6270\n",
      "Epoch 387: val_loss did not improve from 14.02987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7397 - val_loss: 19.2243\n",
      "Epoch 388/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.9535\n",
      "Epoch 388: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1038 - val_loss: 18.6053\n",
      "Epoch 389/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.5247\n",
      "Epoch 389: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8450 - val_loss: 15.8008\n",
      "Epoch 390/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.1732\n",
      "Epoch 390: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0996 - val_loss: 18.6436\n",
      "Epoch 391/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.9943\n",
      "Epoch 391: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0972 - val_loss: 19.6619\n",
      "Epoch 392/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.8707\n",
      "Epoch 392: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2900 - val_loss: 19.0692\n",
      "Epoch 393/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.8569\n",
      "Epoch 393: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6424 - val_loss: 18.5527\n",
      "Epoch 394/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.5343\n",
      "Epoch 394: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6423 - val_loss: 20.0903\n",
      "Epoch 395/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 6.0070\n",
      "Epoch 395: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8968 - val_loss: 18.6717\n",
      "Epoch 396/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.1950\n",
      "Epoch 396: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9784 - val_loss: 19.3822\n",
      "Epoch 397/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.9773\n",
      "Epoch 397: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9280 - val_loss: 18.4589\n",
      "Epoch 398/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 7.1924\n",
      "Epoch 398: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2118 - val_loss: 20.5019\n",
      "Epoch 399/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.0355\n",
      "Epoch 399: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0025 - val_loss: 18.8625\n",
      "Epoch 400/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.5430\n",
      "Epoch 400: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.5217 - val_loss: 18.6195\n",
      "Epoch 401/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.0039\n",
      "Epoch 401: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9587 - val_loss: 16.6569\n",
      "Epoch 402/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 5.9928\n",
      "Epoch 402: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0545 - val_loss: 20.4826\n",
      "Epoch 403/700\n",
      "61/84 [====================>.........] - ETA: 0s - loss: 5.5719\n",
      "Epoch 403: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5435 - val_loss: 20.6320\n",
      "Epoch 404/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.7468\n",
      "Epoch 404: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9197 - val_loss: 20.2221\n",
      "Epoch 405/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.6594\n",
      "Epoch 405: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7805 - val_loss: 20.3465\n",
      "Epoch 406/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.7338\n",
      "Epoch 406: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9313 - val_loss: 18.2782\n",
      "Epoch 407/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.4263\n",
      "Epoch 407: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4834 - val_loss: 17.6204\n",
      "Epoch 408/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.4032\n",
      "Epoch 408: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4565 - val_loss: 19.3093\n",
      "Epoch 409/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.1835\n",
      "Epoch 409: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1854 - val_loss: 17.5777\n",
      "Epoch 410/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.2679\n",
      "Epoch 410: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3111 - val_loss: 18.5046\n",
      "Epoch 411/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.9206\n",
      "Epoch 411: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0285 - val_loss: 17.8823\n",
      "Epoch 412/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.4053\n",
      "Epoch 412: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4330 - val_loss: 19.1566\n",
      "Epoch 413/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.1014\n",
      "Epoch 413: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0792 - val_loss: 17.2846\n",
      "Epoch 414/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.7796\n",
      "Epoch 414: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0887 - val_loss: 19.4621\n",
      "Epoch 415/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.3019\n",
      "Epoch 415: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1758 - val_loss: 21.2733\n",
      "Epoch 416/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.1212\n",
      "Epoch 416: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0340 - val_loss: 19.6895\n",
      "Epoch 417/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.3081\n",
      "Epoch 417: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1613 - val_loss: 20.2525\n",
      "Epoch 418/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.8722\n",
      "Epoch 418: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0202 - val_loss: 19.9251\n",
      "Epoch 419/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.1308\n",
      "Epoch 419: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0141 - val_loss: 18.1974\n",
      "Epoch 420/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.3308\n",
      "Epoch 420: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3286 - val_loss: 16.3739\n",
      "Epoch 421/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.7801\n",
      "Epoch 421: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7790 - val_loss: 17.0548\n",
      "Epoch 422/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.9135\n",
      "Epoch 422: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9261 - val_loss: 17.7933\n",
      "Epoch 423/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.9024\n",
      "Epoch 423: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9706 - val_loss: 17.2578\n",
      "Epoch 424/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.3348\n",
      "Epoch 424: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2968 - val_loss: 20.6453\n",
      "Epoch 425/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.7435\n",
      "Epoch 425: val_loss did not improve from 14.02987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8256 - val_loss: 15.8211\n",
      "Epoch 426/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.0379\n",
      "Epoch 426: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9684 - val_loss: 17.7032\n",
      "Epoch 427/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.6242\n",
      "Epoch 427: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7444 - val_loss: 21.0709\n",
      "Epoch 428/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.5992\n",
      "Epoch 428: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5403 - val_loss: 21.6916\n",
      "Epoch 429/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.8323\n",
      "Epoch 429: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9386 - val_loss: 17.7291\n",
      "Epoch 430/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.8000\n",
      "Epoch 430: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7060 - val_loss: 18.3552\n",
      "Epoch 431/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.0681\n",
      "Epoch 431: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9546 - val_loss: 18.7644\n",
      "Epoch 432/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.7737\n",
      "Epoch 432: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7474 - val_loss: 19.7119\n",
      "Epoch 433/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.2984\n",
      "Epoch 433: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3421 - val_loss: 19.5950\n",
      "Epoch 434/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.8841\n",
      "Epoch 434: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9352 - val_loss: 19.0701\n",
      "Epoch 435/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.6849\n",
      "Epoch 435: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6669 - val_loss: 17.9955\n",
      "Epoch 436/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.5995\n",
      "Epoch 436: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6113 - val_loss: 17.9868\n",
      "Epoch 437/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.2141\n",
      "Epoch 437: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1570 - val_loss: 19.6919\n",
      "Epoch 438/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.9566\n",
      "Epoch 438: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8918 - val_loss: 19.1778\n",
      "Epoch 439/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.9517\n",
      "Epoch 439: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9552 - val_loss: 19.2911\n",
      "Epoch 440/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.0927\n",
      "Epoch 440: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0593 - val_loss: 19.4543\n",
      "Epoch 441/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 6.1162\n",
      "Epoch 441: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9874 - val_loss: 20.6146\n",
      "Epoch 442/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.2225\n",
      "Epoch 442: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2048 - val_loss: 19.6572\n",
      "Epoch 443/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.7551\n",
      "Epoch 443: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7842 - val_loss: 18.6483\n",
      "Epoch 444/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.5021\n",
      "Epoch 444: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6598 - val_loss: 19.7978\n",
      "Epoch 445/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.0902\n",
      "Epoch 445: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0724 - val_loss: 19.9648\n",
      "Epoch 446/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.9736\n",
      "Epoch 446: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7987 - val_loss: 19.6762\n",
      "Epoch 447/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.7817\n",
      "Epoch 447: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7289 - val_loss: 19.1076\n",
      "Epoch 448/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.1381\n",
      "Epoch 448: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2656 - val_loss: 20.1166\n",
      "Epoch 449/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.5943\n",
      "Epoch 449: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7668 - val_loss: 21.1715\n",
      "Epoch 450/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.0625\n",
      "Epoch 450: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0098 - val_loss: 21.6683\n",
      "Epoch 451/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.6308\n",
      "Epoch 451: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5186 - val_loss: 17.7266\n",
      "Epoch 452/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.1548\n",
      "Epoch 452: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2103 - val_loss: 17.7191\n",
      "Epoch 453/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.9411\n",
      "Epoch 453: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8509 - val_loss: 18.3117\n",
      "Epoch 454/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.9012\n",
      "Epoch 454: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8726 - val_loss: 17.4420\n",
      "Epoch 455/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.6146\n",
      "Epoch 455: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5880 - val_loss: 19.6911\n",
      "Epoch 456/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.6069\n",
      "Epoch 456: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5934 - val_loss: 19.3914\n",
      "Epoch 457/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.5153\n",
      "Epoch 457: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4785 - val_loss: 21.1687\n",
      "Epoch 458/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.1303\n",
      "Epoch 458: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0780 - val_loss: 18.9337\n",
      "Epoch 459/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.4843\n",
      "Epoch 459: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5583 - val_loss: 21.2397\n",
      "Epoch 460/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.9439\n",
      "Epoch 460: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9509 - val_loss: 18.9494\n",
      "Epoch 461/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.2246\n",
      "Epoch 461: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2923 - val_loss: 19.3844\n",
      "Epoch 462/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.7517\n",
      "Epoch 462: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5811 - val_loss: 20.0367\n",
      "Epoch 463/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.8899\n",
      "Epoch 463: val_loss did not improve from 14.02987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8730 - val_loss: 18.4637\n",
      "Epoch 464/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.2002\n",
      "Epoch 464: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9770 - val_loss: 18.7680\n",
      "Epoch 465/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.6342\n",
      "Epoch 465: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9119 - val_loss: 18.1317\n",
      "Epoch 466/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.6282\n",
      "Epoch 466: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6438 - val_loss: 19.4239\n",
      "Epoch 467/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.8630\n",
      "Epoch 467: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8607 - val_loss: 19.3501\n",
      "Epoch 468/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.6951\n",
      "Epoch 468: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6620 - val_loss: 18.3298\n",
      "Epoch 469/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.3268\n",
      "Epoch 469: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3645 - val_loss: 20.2083\n",
      "Epoch 470/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.3020\n",
      "Epoch 470: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.3065 - val_loss: 19.9594\n",
      "Epoch 471/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.5783\n",
      "Epoch 471: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5509 - val_loss: 18.6820\n",
      "Epoch 472/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.8198\n",
      "Epoch 472: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7651 - val_loss: 18.6712\n",
      "Epoch 473/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.9064\n",
      "Epoch 473: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8034 - val_loss: 19.0278\n",
      "Epoch 474/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.4783\n",
      "Epoch 474: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4355 - val_loss: 19.2568\n",
      "Epoch 475/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.5681\n",
      "Epoch 475: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5687 - val_loss: 19.8808\n",
      "Epoch 476/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.0113\n",
      "Epoch 476: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9938 - val_loss: 18.4920\n",
      "Epoch 477/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.6575\n",
      "Epoch 477: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7417 - val_loss: 22.0850\n",
      "Epoch 478/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.2601\n",
      "Epoch 478: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2880 - val_loss: 19.8871\n",
      "Epoch 479/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.6380\n",
      "Epoch 479: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6022 - val_loss: 17.8013\n",
      "Epoch 480/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.2484\n",
      "Epoch 480: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4233 - val_loss: 20.1019\n",
      "Epoch 481/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.7215\n",
      "Epoch 481: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6418 - val_loss: 19.6006\n",
      "Epoch 482/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.7428\n",
      "Epoch 482: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6322 - val_loss: 17.8419\n",
      "Epoch 483/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.2538\n",
      "Epoch 483: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2536 - val_loss: 19.2983\n",
      "Epoch 484/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.1328\n",
      "Epoch 484: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1806 - val_loss: 19.3540\n",
      "Epoch 485/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.7964\n",
      "Epoch 485: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9733 - val_loss: 19.7184\n",
      "Epoch 486/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.7130\n",
      "Epoch 486: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8622 - val_loss: 19.1633\n",
      "Epoch 487/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.8603\n",
      "Epoch 487: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9502 - val_loss: 17.9627\n",
      "Epoch 488/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.8334\n",
      "Epoch 488: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8426 - val_loss: 17.2413\n",
      "Epoch 489/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.5726\n",
      "Epoch 489: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7318 - val_loss: 21.2535\n",
      "Epoch 490/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.0304\n",
      "Epoch 490: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1999 - val_loss: 21.0877\n",
      "Epoch 491/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.5118\n",
      "Epoch 491: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4799 - val_loss: 19.2904\n",
      "Epoch 492/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 5.3465\n",
      "Epoch 492: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4782 - val_loss: 17.4741\n",
      "Epoch 493/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.9597\n",
      "Epoch 493: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8717 - val_loss: 20.8091\n",
      "Epoch 494/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.3092\n",
      "Epoch 494: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2031 - val_loss: 18.1939\n",
      "Epoch 495/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.1699\n",
      "Epoch 495: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2236 - val_loss: 19.0688\n",
      "Epoch 496/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.2654\n",
      "Epoch 496: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3346 - val_loss: 19.0296\n",
      "Epoch 497/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.7537\n",
      "Epoch 497: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8095 - val_loss: 18.6818\n",
      "Epoch 498/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.3448\n",
      "Epoch 498: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5071 - val_loss: 20.4988\n",
      "Epoch 499/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.6365\n",
      "Epoch 499: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7367 - val_loss: 18.9354\n",
      "Epoch 500/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.6390\n",
      "Epoch 500: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6980 - val_loss: 20.1486\n",
      "Epoch 501/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.3111\n",
      "Epoch 501: val_loss did not improve from 14.02987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4909 - val_loss: 19.3582\n",
      "Epoch 502/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.2357\n",
      "Epoch 502: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2652 - val_loss: 16.9005\n",
      "Epoch 503/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.9023\n",
      "Epoch 503: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8522 - val_loss: 16.7903\n",
      "Epoch 504/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.6955\n",
      "Epoch 504: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6646 - val_loss: 16.1960\n",
      "Epoch 505/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 6.6113\n",
      "Epoch 505: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7155 - val_loss: 20.2704\n",
      "Epoch 506/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.7468\n",
      "Epoch 506: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6207 - val_loss: 18.6974\n",
      "Epoch 507/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.1922\n",
      "Epoch 507: val_loss did not improve from 14.02987\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2067 - val_loss: 19.2980\n",
      "\n",
      " ---------- 6 ---------- \n",
      "\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_13 (Conv2D)          (None, 22, 8, 360)        3600      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 7, 2, 360)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " reshape_13 (Reshape)        (None, 7, 720)            0         \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 7, 720)            0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 180)               648720    \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 180)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 181       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 652,501\n",
      "Trainable params: 652,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 52.7450\n",
      "Epoch 1: val_loss improved from inf to 25.44355, saving model to ./model_save\\7_fold_001-25.4435.hdf5\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 51.8120 - val_loss: 25.4435\n",
      "Epoch 2/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 43.8924\n",
      "Epoch 2: val_loss improved from 25.44355 to 24.04225, saving model to ./model_save\\7_fold_002-24.0423.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 44.5602 - val_loss: 24.0423\n",
      "Epoch 3/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 42.3728\n",
      "Epoch 3: val_loss improved from 24.04225 to 23.64120, saving model to ./model_save\\7_fold_003-23.6412.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 42.0946 - val_loss: 23.6412\n",
      "Epoch 4/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 40.1616\n",
      "Epoch 4: val_loss improved from 23.64120 to 15.39976, saving model to ./model_save\\7_fold_004-15.3998.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 39.7982 - val_loss: 15.3998\n",
      "Epoch 5/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 36.3046\n",
      "Epoch 5: val_loss improved from 15.39976 to 14.57521, saving model to ./model_save\\7_fold_005-14.5752.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 37.1617 - val_loss: 14.5752\n",
      "Epoch 6/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 35.2419\n",
      "Epoch 6: val_loss improved from 14.57521 to 14.13536, saving model to ./model_save\\7_fold_006-14.1354.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 35.4964 - val_loss: 14.1354\n",
      "Epoch 7/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 35.2301\n",
      "Epoch 7: val_loss improved from 14.13536 to 13.12876, saving model to ./model_save\\7_fold_007-13.1288.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 34.2940 - val_loss: 13.1288\n",
      "Epoch 8/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 33.3884\n",
      "Epoch 8: val_loss did not improve from 13.12876\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 32.5673 - val_loss: 13.5646\n",
      "Epoch 9/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 31.4245\n",
      "Epoch 9: val_loss improved from 13.12876 to 11.99655, saving model to ./model_save\\7_fold_009-11.9965.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 31.0437 - val_loss: 11.9965\n",
      "Epoch 10/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 31.4928\n",
      "Epoch 10: val_loss did not improve from 11.99655\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 30.7371 - val_loss: 12.0670\n",
      "Epoch 11/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 30.4567\n",
      "Epoch 11: val_loss improved from 11.99655 to 10.53675, saving model to ./model_save\\7_fold_011-10.5367.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 30.1669 - val_loss: 10.5367\n",
      "Epoch 12/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 30.2942\n",
      "Epoch 12: val_loss did not improve from 10.53675\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 29.2978 - val_loss: 10.6977\n",
      "Epoch 13/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 27.0953\n",
      "Epoch 13: val_loss improved from 10.53675 to 9.86720, saving model to ./model_save\\7_fold_013-9.8672.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 27.9186 - val_loss: 9.8672\n",
      "Epoch 14/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 28.2359\n",
      "Epoch 14: val_loss did not improve from 9.86720\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 28.5606 - val_loss: 10.7782\n",
      "Epoch 15/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 25.6869\n",
      "Epoch 15: val_loss improved from 9.86720 to 9.46200, saving model to ./model_save\\7_fold_015-9.4620.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 26.8065 - val_loss: 9.4620\n",
      "Epoch 16/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 26.0574\n",
      "Epoch 16: val_loss did not improve from 9.46200\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 26.4389 - val_loss: 9.5688\n",
      "Epoch 17/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 25.5749\n",
      "Epoch 17: val_loss did not improve from 9.46200\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 25.7809 - val_loss: 10.5972\n",
      "Epoch 18/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 24.0421\n",
      "Epoch 18: val_loss improved from 9.46200 to 8.93266, saving model to ./model_save\\7_fold_018-8.9327.hdf5\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 24.7447 - val_loss: 8.9327\n",
      "Epoch 19/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 25.0142\n",
      "Epoch 19: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 24.6733 - val_loss: 11.7263\n",
      "Epoch 20/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 24.8565\n",
      "Epoch 20: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 24.9526 - val_loss: 11.1932\n",
      "Epoch 21/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 25.0347\n",
      "Epoch 21: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 25.4077 - val_loss: 9.7319\n",
      "Epoch 22/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 23.1234\n",
      "Epoch 22: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 23.2614 - val_loss: 11.5656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 22.2351\n",
      "Epoch 23: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 22.9274 - val_loss: 11.3294\n",
      "Epoch 24/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 21.5351\n",
      "Epoch 24: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 21.7730 - val_loss: 9.3305\n",
      "Epoch 25/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 22.9121\n",
      "Epoch 25: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 23.2706 - val_loss: 9.4449\n",
      "Epoch 26/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 22.6871\n",
      "Epoch 26: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 22.3899 - val_loss: 9.7960\n",
      "Epoch 27/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 20.8777\n",
      "Epoch 27: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 21.0642 - val_loss: 10.4142\n",
      "Epoch 28/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 21.6060\n",
      "Epoch 28: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 21.1476 - val_loss: 9.3383\n",
      "Epoch 29/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 21.4263\n",
      "Epoch 29: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 21.3461 - val_loss: 10.5992\n",
      "Epoch 30/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 20.1438\n",
      "Epoch 30: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 20.3209 - val_loss: 11.8100\n",
      "Epoch 31/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 20.3538\n",
      "Epoch 31: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 20.1256 - val_loss: 10.7297\n",
      "Epoch 32/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 19.8807\n",
      "Epoch 32: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.9617 - val_loss: 11.2218\n",
      "Epoch 33/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 20.3170\n",
      "Epoch 33: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.8563 - val_loss: 10.9122\n",
      "Epoch 34/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 19.1003\n",
      "Epoch 34: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 19.2042 - val_loss: 11.7202\n",
      "Epoch 35/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 19.1589\n",
      "Epoch 35: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 19.1993 - val_loss: 11.6499\n",
      "Epoch 36/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 19.5447\n",
      "Epoch 36: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 19.8537 - val_loss: 9.2267\n",
      "Epoch 37/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 18.5107\n",
      "Epoch 37: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.5850 - val_loss: 10.3555\n",
      "Epoch 38/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 18.8427\n",
      "Epoch 38: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.9906 - val_loss: 10.0678\n",
      "Epoch 39/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 18.3743\n",
      "Epoch 39: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.7620 - val_loss: 10.7669\n",
      "Epoch 40/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 17.6465\n",
      "Epoch 40: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.0719 - val_loss: 9.2131\n",
      "Epoch 41/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 18.6600\n",
      "Epoch 41: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 18.6642 - val_loss: 11.1146\n",
      "Epoch 42/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 17.7492\n",
      "Epoch 42: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.5987 - val_loss: 9.6470\n",
      "Epoch 43/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 16.7326\n",
      "Epoch 43: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.6574 - val_loss: 12.5286\n",
      "Epoch 44/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 17.2221\n",
      "Epoch 44: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.9993 - val_loss: 11.4582\n",
      "Epoch 45/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 17.0448\n",
      "Epoch 45: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 17.4549 - val_loss: 12.2886\n",
      "Epoch 46/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 18.1790\n",
      "Epoch 46: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 18.4235 - val_loss: 10.2447\n",
      "Epoch 47/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 16.7390\n",
      "Epoch 47: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 16.7559 - val_loss: 9.9069\n",
      "Epoch 48/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 15.2175\n",
      "Epoch 48: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.7127 - val_loss: 10.1934\n",
      "Epoch 49/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 15.9307\n",
      "Epoch 49: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.8696 - val_loss: 11.5998\n",
      "Epoch 50/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 14.9567\n",
      "Epoch 50: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.6238 - val_loss: 10.8613\n",
      "Epoch 51/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 15.1289\n",
      "Epoch 51: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 15.6217 - val_loss: 10.4633\n",
      "Epoch 52/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 15.6490\n",
      "Epoch 52: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.5877 - val_loss: 11.8786\n",
      "Epoch 53/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 15.6124\n",
      "Epoch 53: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 15.5041 - val_loss: 11.9259\n",
      "Epoch 54/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 15.0113\n",
      "Epoch 54: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.9532 - val_loss: 11.2439\n",
      "Epoch 55/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 14.8980\n",
      "Epoch 55: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.5408 - val_loss: 10.6065\n",
      "Epoch 56/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 14.1806\n",
      "Epoch 56: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.2010 - val_loss: 10.2051\n",
      "Epoch 57/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 13.9946\n",
      "Epoch 57: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 14.4325 - val_loss: 11.5293\n",
      "Epoch 58/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 13.2097\n",
      "Epoch 58: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.5427 - val_loss: 11.8075\n",
      "Epoch 59/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 13.2722\n",
      "Epoch 59: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.3849 - val_loss: 9.3972\n",
      "Epoch 60/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 13.4449\n",
      "Epoch 60: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.4654 - val_loss: 12.1775\n",
      "Epoch 61/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/84 [==========================>...] - ETA: 0s - loss: 13.7549\n",
      "Epoch 61: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 13.5822 - val_loss: 12.8180\n",
      "Epoch 62/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 13.2976\n",
      "Epoch 62: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 13.2253 - val_loss: 13.9356\n",
      "Epoch 63/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 13.2553\n",
      "Epoch 63: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.5105 - val_loss: 11.7465\n",
      "Epoch 64/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 13.1288\n",
      "Epoch 64: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.4059 - val_loss: 11.9854\n",
      "Epoch 65/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 13.2398\n",
      "Epoch 65: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.5560 - val_loss: 17.0914\n",
      "Epoch 66/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 13.3450\n",
      "Epoch 66: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 13.3968 - val_loss: 11.0718\n",
      "Epoch 67/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 12.5253\n",
      "Epoch 67: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 12.5338 - val_loss: 12.9109\n",
      "Epoch 68/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 12.1955\n",
      "Epoch 68: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.1578 - val_loss: 16.3466\n",
      "Epoch 69/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 12.2114\n",
      "Epoch 69: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.0730 - val_loss: 15.4593\n",
      "Epoch 70/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 10.8477\n",
      "Epoch 70: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.1371 - val_loss: 15.0239\n",
      "Epoch 71/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 12.3300\n",
      "Epoch 71: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.3258 - val_loss: 16.3075\n",
      "Epoch 72/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 12.2071\n",
      "Epoch 72: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 12.0171 - val_loss: 12.9146\n",
      "Epoch 73/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 12.2720\n",
      "Epoch 73: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.9735 - val_loss: 12.9599\n",
      "Epoch 74/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 11.4796\n",
      "Epoch 74: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.3959 - val_loss: 16.8639\n",
      "Epoch 75/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 11.3872\n",
      "Epoch 75: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.3599 - val_loss: 18.5303\n",
      "Epoch 76/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 10.8664\n",
      "Epoch 76: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.4129 - val_loss: 13.1003\n",
      "Epoch 77/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 10.4394\n",
      "Epoch 77: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.3791 - val_loss: 14.6334\n",
      "Epoch 78/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 10.8728\n",
      "Epoch 78: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.5963 - val_loss: 15.2863\n",
      "Epoch 79/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 10.4452\n",
      "Epoch 79: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.0467 - val_loss: 18.1557\n",
      "Epoch 80/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 10.1882\n",
      "Epoch 80: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.0928 - val_loss: 13.5710\n",
      "Epoch 81/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 10.2426\n",
      "Epoch 81: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.3293 - val_loss: 13.1053\n",
      "Epoch 82/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 11.6549\n",
      "Epoch 82: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.0475 - val_loss: 14.2820\n",
      "Epoch 83/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 10.9356\n",
      "Epoch 83: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 11.0106 - val_loss: 15.3222\n",
      "Epoch 84/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 9.9295 \n",
      "Epoch 84: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.7117 - val_loss: 13.0943\n",
      "Epoch 85/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 9.8469 \n",
      "Epoch 85: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.1362 - val_loss: 17.2427\n",
      "Epoch 86/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 10.3368\n",
      "Epoch 86: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.6875 - val_loss: 15.7680\n",
      "Epoch 87/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 10.1878\n",
      "Epoch 87: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.1404 - val_loss: 16.4857\n",
      "Epoch 88/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 10.0730\n",
      "Epoch 88: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.2513 - val_loss: 15.2301\n",
      "Epoch 89/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 10.0168\n",
      "Epoch 89: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.6851 - val_loss: 16.8420\n",
      "Epoch 90/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 9.2771\n",
      "Epoch 90: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.3853 - val_loss: 14.7573\n",
      "Epoch 91/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 10.3200\n",
      "Epoch 91: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.8210 - val_loss: 14.2215\n",
      "Epoch 92/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 10.3255\n",
      "Epoch 92: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.3316 - val_loss: 14.3341\n",
      "Epoch 93/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 8.9799\n",
      "Epoch 93: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0665 - val_loss: 15.2720\n",
      "Epoch 94/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 9.8204 \n",
      "Epoch 94: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.8959 - val_loss: 14.2592\n",
      "Epoch 95/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 10.3599\n",
      "Epoch 95: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.2802 - val_loss: 16.0613\n",
      "Epoch 96/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 9.5614\n",
      "Epoch 96: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.5562 - val_loss: 12.8704\n",
      "Epoch 97/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 10.6286\n",
      "Epoch 97: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.9001 - val_loss: 15.0665\n",
      "Epoch 98/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 9.3357\n",
      "Epoch 98: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.3357 - val_loss: 14.8847\n",
      "Epoch 99/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - ETA: 0s - loss: 9.3992\n",
      "Epoch 99: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.3992 - val_loss: 17.4173\n",
      "Epoch 100/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 9.0133\n",
      "Epoch 100: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9212 - val_loss: 15.8573\n",
      "Epoch 101/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 9.4066\n",
      "Epoch 101: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0046 - val_loss: 17.2700\n",
      "Epoch 102/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 9.3728\n",
      "Epoch 102: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.2379 - val_loss: 13.7354\n",
      "Epoch 103/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 10.0440\n",
      "Epoch 103: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 10.1925 - val_loss: 11.8755\n",
      "Epoch 104/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 8.9050\n",
      "Epoch 104: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7446 - val_loss: 12.7965\n",
      "Epoch 105/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 9.6915 \n",
      "Epoch 105: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.7389 - val_loss: 15.3260\n",
      "Epoch 106/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 9.0010\n",
      "Epoch 106: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1845 - val_loss: 15.9749\n",
      "Epoch 107/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 8.6012\n",
      "Epoch 107: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6012 - val_loss: 15.1351\n",
      "Epoch 108/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 9.1803\n",
      "Epoch 108: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1446 - val_loss: 16.0704\n",
      "Epoch 109/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 9.0272\n",
      "Epoch 109: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1732 - val_loss: 11.8769\n",
      "Epoch 110/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 9.7623\n",
      "Epoch 110: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.4727 - val_loss: 16.3932\n",
      "Epoch 111/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 8.6092\n",
      "Epoch 111: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7779 - val_loss: 12.8374\n",
      "Epoch 112/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 8.7471\n",
      "Epoch 112: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7869 - val_loss: 19.1820\n",
      "Epoch 113/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 9.5076\n",
      "Epoch 113: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.1029 - val_loss: 15.8772\n",
      "Epoch 114/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 8.1850\n",
      "Epoch 114: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5372 - val_loss: 15.8330\n",
      "Epoch 115/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.8427\n",
      "Epoch 115: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8378 - val_loss: 15.3788\n",
      "Epoch 116/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 8.3563\n",
      "Epoch 116: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5321 - val_loss: 13.9908\n",
      "Epoch 117/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 8.9956\n",
      "Epoch 117: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9401 - val_loss: 13.4627\n",
      "Epoch 118/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.4559\n",
      "Epoch 118: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7432 - val_loss: 17.8585\n",
      "Epoch 119/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 8.4794\n",
      "Epoch 119: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5105 - val_loss: 13.5702\n",
      "Epoch 120/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 9.0348\n",
      "Epoch 120: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.0816 - val_loss: 11.9827\n",
      "Epoch 121/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 9.1601\n",
      "Epoch 121: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.4687 - val_loss: 15.6980\n",
      "Epoch 122/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 8.1573\n",
      "Epoch 122: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1573 - val_loss: 15.2027\n",
      "Epoch 123/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 8.8269\n",
      "Epoch 123: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.9453 - val_loss: 15.3163\n",
      "Epoch 124/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 8.1290\n",
      "Epoch 124: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0920 - val_loss: 14.0388\n",
      "Epoch 125/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 8.1418\n",
      "Epoch 125: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1973 - val_loss: 16.3378\n",
      "Epoch 126/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.8446\n",
      "Epoch 126: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8950 - val_loss: 17.0245\n",
      "Epoch 127/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 8.4176\n",
      "Epoch 127: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7264 - val_loss: 15.1530\n",
      "Epoch 128/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.4131\n",
      "Epoch 128: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6590 - val_loss: 15.0600\n",
      "Epoch 129/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 8.7432\n",
      "Epoch 129: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.6176 - val_loss: 14.1949\n",
      "Epoch 130/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.6434\n",
      "Epoch 130: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5624 - val_loss: 14.4567\n",
      "Epoch 131/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 8.4369\n",
      "Epoch 131: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3041 - val_loss: 13.8233\n",
      "Epoch 132/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.8917\n",
      "Epoch 132: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8591 - val_loss: 15.3250\n",
      "Epoch 133/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 8.1241\n",
      "Epoch 133: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0832 - val_loss: 16.4333\n",
      "Epoch 134/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.2260\n",
      "Epoch 134: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5245 - val_loss: 16.9550\n",
      "Epoch 135/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 9.1177\n",
      "Epoch 135: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7598 - val_loss: 16.3722\n",
      "Epoch 136/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 8.7684\n",
      "Epoch 136: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.5935 - val_loss: 12.8987\n",
      "Epoch 137/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/84 [========================>.....] - ETA: 0s - loss: 8.4635\n",
      "Epoch 137: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2823 - val_loss: 15.2251\n",
      "Epoch 138/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 8.2281\n",
      "Epoch 138: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9455 - val_loss: 14.9876\n",
      "Epoch 139/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.3011\n",
      "Epoch 139: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.2554 - val_loss: 17.9942\n",
      "Epoch 140/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.5212\n",
      "Epoch 140: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5658 - val_loss: 15.9901\n",
      "Epoch 141/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.8113\n",
      "Epoch 141: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8259 - val_loss: 17.4913\n",
      "Epoch 142/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 8.4250\n",
      "Epoch 142: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3525 - val_loss: 16.9811\n",
      "Epoch 143/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.4783\n",
      "Epoch 143: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2491 - val_loss: 15.9973\n",
      "Epoch 144/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 8.0329\n",
      "Epoch 144: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9639 - val_loss: 16.5984\n",
      "Epoch 145/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 9.1456\n",
      "Epoch 145: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.7804 - val_loss: 15.5307\n",
      "Epoch 146/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.8894\n",
      "Epoch 146: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8894 - val_loss: 15.9597\n",
      "Epoch 147/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.6815\n",
      "Epoch 147: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.6086 - val_loss: 16.7724\n",
      "Epoch 148/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 7.4060\n",
      "Epoch 148: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5347 - val_loss: 16.6900\n",
      "Epoch 149/700\n",
      "60/84 [====================>.........] - ETA: 0s - loss: 7.1095\n",
      "Epoch 149: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4553 - val_loss: 14.0572\n",
      "Epoch 150/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.8625\n",
      "Epoch 150: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8545 - val_loss: 15.7963\n",
      "Epoch 151/700\n",
      "60/84 [====================>.........] - ETA: 0s - loss: 7.7172\n",
      "Epoch 151: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0163 - val_loss: 15.1733\n",
      "Epoch 152/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 7.1511\n",
      "Epoch 152: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4393 - val_loss: 15.8030\n",
      "Epoch 153/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 8.1659\n",
      "Epoch 153: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0720 - val_loss: 17.9420\n",
      "Epoch 154/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 8.4540\n",
      "Epoch 154: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1575 - val_loss: 17.2636\n",
      "Epoch 155/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 8.1904\n",
      "Epoch 155: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0040 - val_loss: 17.5327\n",
      "Epoch 156/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.5375\n",
      "Epoch 156: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4887 - val_loss: 17.5096\n",
      "Epoch 157/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.3368\n",
      "Epoch 157: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3368 - val_loss: 18.6003\n",
      "Epoch 158/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 8.1355\n",
      "Epoch 158: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1071 - val_loss: 10.8302\n",
      "Epoch 159/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 9.7202 \n",
      "Epoch 159: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 9.5384 - val_loss: 16.8191\n",
      "Epoch 160/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.0799\n",
      "Epoch 160: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4590 - val_loss: 12.8371\n",
      "Epoch 161/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 7.1178\n",
      "Epoch 161: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1345 - val_loss: 18.1157\n",
      "Epoch 162/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.2502\n",
      "Epoch 162: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3804 - val_loss: 16.3250\n",
      "Epoch 163/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 7.1413\n",
      "Epoch 163: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4058 - val_loss: 17.8850\n",
      "Epoch 164/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.5572\n",
      "Epoch 164: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7850 - val_loss: 17.2991\n",
      "Epoch 165/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 7.3817\n",
      "Epoch 165: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5333 - val_loss: 17.2134\n",
      "Epoch 166/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 8.2662\n",
      "Epoch 166: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.0316 - val_loss: 15.6701\n",
      "Epoch 167/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 7.8367\n",
      "Epoch 167: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5345 - val_loss: 18.2422\n",
      "Epoch 168/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 7.6131\n",
      "Epoch 168: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4305 - val_loss: 16.2216\n",
      "Epoch 169/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.1183\n",
      "Epoch 169: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0962 - val_loss: 16.1651\n",
      "Epoch 170/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 7.3214\n",
      "Epoch 170: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3491 - val_loss: 16.3016\n",
      "Epoch 171/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.7111\n",
      "Epoch 171: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8223 - val_loss: 16.6290\n",
      "Epoch 172/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.6089\n",
      "Epoch 172: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9726 - val_loss: 18.3643\n",
      "Epoch 173/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.8728\n",
      "Epoch 173: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.8699 - val_loss: 14.6736\n",
      "Epoch 174/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.2855\n",
      "Epoch 174: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2855 - val_loss: 16.5676\n",
      "Epoch 175/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/84 [=======================>......] - ETA: 0s - loss: 7.1988\n",
      "Epoch 175: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3254 - val_loss: 18.4428\n",
      "Epoch 176/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.0088\n",
      "Epoch 176: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3317 - val_loss: 18.6229\n",
      "Epoch 177/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.5571\n",
      "Epoch 177: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5001 - val_loss: 16.7031\n",
      "Epoch 178/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.3940\n",
      "Epoch 178: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3940 - val_loss: 17.0955\n",
      "Epoch 179/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 8.1888\n",
      "Epoch 179: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.1591 - val_loss: 15.7227\n",
      "Epoch 180/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 7.4076\n",
      "Epoch 180: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2878 - val_loss: 18.9513\n",
      "Epoch 181/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 7.0844\n",
      "Epoch 181: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0710 - val_loss: 16.8394\n",
      "Epoch 182/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 7.4804\n",
      "Epoch 182: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1313 - val_loss: 17.2268\n",
      "Epoch 183/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.3157\n",
      "Epoch 183: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1931 - val_loss: 16.6837\n",
      "Epoch 184/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.9806\n",
      "Epoch 184: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9351 - val_loss: 15.5747\n",
      "Epoch 185/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.2667\n",
      "Epoch 185: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2203 - val_loss: 17.3385\n",
      "Epoch 186/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 7.4294\n",
      "Epoch 186: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.5028 - val_loss: 15.6406\n",
      "Epoch 187/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.8096\n",
      "Epoch 187: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2105 - val_loss: 16.2296\n",
      "Epoch 188/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.7684\n",
      "Epoch 188: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7256 - val_loss: 14.0767\n",
      "Epoch 189/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 7.3092\n",
      "Epoch 189: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2886 - val_loss: 15.6089\n",
      "Epoch 190/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.0715\n",
      "Epoch 190: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0360 - val_loss: 19.5115\n",
      "Epoch 191/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.4860\n",
      "Epoch 191: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3533 - val_loss: 17.2820\n",
      "Epoch 192/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.4553\n",
      "Epoch 192: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4553 - val_loss: 16.4465\n",
      "Epoch 193/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 6.6998\n",
      "Epoch 193: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7573 - val_loss: 17.8973\n",
      "Epoch 194/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.9057\n",
      "Epoch 194: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9057 - val_loss: 15.6021\n",
      "Epoch 195/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.9367\n",
      "Epoch 195: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9119 - val_loss: 15.9182\n",
      "Epoch 196/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.6947\n",
      "Epoch 196: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8653 - val_loss: 15.3637\n",
      "Epoch 197/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.2358\n",
      "Epoch 197: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2624 - val_loss: 18.7676\n",
      "Epoch 198/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.1577\n",
      "Epoch 198: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0953 - val_loss: 15.4498\n",
      "Epoch 199/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 7.7252\n",
      "Epoch 199: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.7558 - val_loss: 16.1447\n",
      "Epoch 200/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.1773\n",
      "Epoch 200: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1773 - val_loss: 16.1855\n",
      "Epoch 201/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.9371\n",
      "Epoch 201: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9371 - val_loss: 15.1940\n",
      "Epoch 202/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 7.0964\n",
      "Epoch 202: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1404 - val_loss: 17.1967\n",
      "Epoch 203/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 7.1079\n",
      "Epoch 203: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0588 - val_loss: 16.5617\n",
      "Epoch 204/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 7.1312\n",
      "Epoch 204: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1337 - val_loss: 17.7645\n",
      "Epoch 205/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 7.3649\n",
      "Epoch 205: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2511 - val_loss: 17.9946\n",
      "Epoch 206/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 7.3891\n",
      "Epoch 206: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4953 - val_loss: 17.3430\n",
      "Epoch 207/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 7.7237\n",
      "Epoch 207: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3761 - val_loss: 14.2501\n",
      "Epoch 208/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.5442\n",
      "Epoch 208: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6481 - val_loss: 13.8517\n",
      "Epoch 209/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 6.3320\n",
      "Epoch 209: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6986 - val_loss: 14.4042\n",
      "Epoch 210/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.9202\n",
      "Epoch 210: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8779 - val_loss: 15.0702\n",
      "Epoch 211/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 8.0790\n",
      "Epoch 211: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.9772 - val_loss: 16.8907\n",
      "Epoch 212/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 6.3735\n",
      "Epoch 212: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4158 - val_loss: 16.2090\n",
      "Epoch 213/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/84 [======================>.......] - ETA: 0s - loss: 7.3797\n",
      "Epoch 213: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3334 - val_loss: 17.7058\n",
      "Epoch 214/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.9638\n",
      "Epoch 214: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1984 - val_loss: 16.3638\n",
      "Epoch 215/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 6.9602\n",
      "Epoch 215: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6371 - val_loss: 16.6395\n",
      "Epoch 216/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.9138\n",
      "Epoch 216: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9355 - val_loss: 17.3705\n",
      "Epoch 217/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 7.2937\n",
      "Epoch 217: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.4949 - val_loss: 14.0311\n",
      "Epoch 218/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.5543\n",
      "Epoch 218: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6108 - val_loss: 17.4367\n",
      "Epoch 219/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 7.0587\n",
      "Epoch 219: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0983 - val_loss: 15.7740\n",
      "Epoch 220/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 7.2397\n",
      "Epoch 220: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.2614 - val_loss: 15.4023\n",
      "Epoch 221/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.2012\n",
      "Epoch 221: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5098 - val_loss: 17.6264\n",
      "Epoch 222/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.3036\n",
      "Epoch 222: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5342 - val_loss: 15.0894\n",
      "Epoch 223/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.7085\n",
      "Epoch 223: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7693 - val_loss: 16.1868\n",
      "Epoch 224/700\n",
      "61/84 [====================>.........] - ETA: 0s - loss: 6.5565\n",
      "Epoch 224: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7708 - val_loss: 16.1245\n",
      "Epoch 225/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 7.1267\n",
      "Epoch 225: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9575 - val_loss: 16.4233\n",
      "Epoch 226/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.8888\n",
      "Epoch 226: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7696 - val_loss: 16.7383\n",
      "Epoch 227/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 7.4186\n",
      "Epoch 227: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3379 - val_loss: 15.9009\n",
      "Epoch 228/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.8561\n",
      "Epoch 228: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8250 - val_loss: 14.7030\n",
      "Epoch 229/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.8222\n",
      "Epoch 229: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8038 - val_loss: 17.1853\n",
      "Epoch 230/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.1174\n",
      "Epoch 230: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0130 - val_loss: 13.8619\n",
      "Epoch 231/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.5524\n",
      "Epoch 231: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 6.4214 - val_loss: 15.4388\n",
      "Epoch 232/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.7901\n",
      "Epoch 232: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7676 - val_loss: 17.8971\n",
      "Epoch 233/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 7.4928\n",
      "Epoch 233: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.3040 - val_loss: 16.4469\n",
      "Epoch 234/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 7.1535\n",
      "Epoch 234: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9122 - val_loss: 16.4272\n",
      "Epoch 235/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.3009\n",
      "Epoch 235: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 6.5374 - val_loss: 16.5929\n",
      "Epoch 236/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 7.1748\n",
      "Epoch 236: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1748 - val_loss: 13.7637\n",
      "Epoch 237/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.5503\n",
      "Epoch 237: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4857 - val_loss: 16.8079\n",
      "Epoch 238/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.4532\n",
      "Epoch 238: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5809 - val_loss: 16.8783\n",
      "Epoch 239/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.5637\n",
      "Epoch 239: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5598 - val_loss: 17.0207\n",
      "Epoch 240/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.0586\n",
      "Epoch 240: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1474 - val_loss: 15.0078\n",
      "Epoch 241/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.6942\n",
      "Epoch 241: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7673 - val_loss: 19.6331\n",
      "Epoch 242/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.3267\n",
      "Epoch 242: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4210 - val_loss: 18.4105\n",
      "Epoch 243/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.7276\n",
      "Epoch 243: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5555 - val_loss: 16.9269\n",
      "Epoch 244/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.2847\n",
      "Epoch 244: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4556 - val_loss: 15.8597\n",
      "Epoch 245/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 6.1612\n",
      "Epoch 245: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3442 - val_loss: 14.3387\n",
      "Epoch 246/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.6227\n",
      "Epoch 246: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5158 - val_loss: 17.3647\n",
      "Epoch 247/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.9831\n",
      "Epoch 247: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8186 - val_loss: 18.2779\n",
      "Epoch 248/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.2653\n",
      "Epoch 248: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5192 - val_loss: 15.2639\n",
      "Epoch 249/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.3596\n",
      "Epoch 249: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3151 - val_loss: 16.3363\n",
      "Epoch 250/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.6902\n",
      "Epoch 250: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0117 - val_loss: 17.7327\n",
      "Epoch 251/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/84 [=========================>....] - ETA: 0s - loss: 6.4740\n",
      "Epoch 251: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4957 - val_loss: 17.7124\n",
      "Epoch 252/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.2690\n",
      "Epoch 252: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3697 - val_loss: 13.9541\n",
      "Epoch 253/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 8.7374\n",
      "Epoch 253: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 8.3549 - val_loss: 16.7599\n",
      "Epoch 254/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.6761\n",
      "Epoch 254: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7688 - val_loss: 17.7219\n",
      "Epoch 255/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.6195\n",
      "Epoch 255: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8002 - val_loss: 15.1068\n",
      "Epoch 256/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.6812\n",
      "Epoch 256: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6849 - val_loss: 16.7591\n",
      "Epoch 257/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.0431\n",
      "Epoch 257: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1367 - val_loss: 15.6826\n",
      "Epoch 258/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.5446\n",
      "Epoch 258: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3620 - val_loss: 15.7045\n",
      "Epoch 259/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 6.3933\n",
      "Epoch 259: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5464 - val_loss: 18.0802\n",
      "Epoch 260/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.2185\n",
      "Epoch 260: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1808 - val_loss: 16.8332\n",
      "Epoch 261/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.4053\n",
      "Epoch 261: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3899 - val_loss: 18.1086\n",
      "Epoch 262/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 6.6227\n",
      "Epoch 262: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7144 - val_loss: 15.3406\n",
      "Epoch 263/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 7.0658\n",
      "Epoch 263: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.0038 - val_loss: 14.7685\n",
      "Epoch 264/700\n",
      "61/84 [====================>.........] - ETA: 0s - loss: 6.3364\n",
      "Epoch 264: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3299 - val_loss: 15.8920\n",
      "Epoch 265/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.5940\n",
      "Epoch 265: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4178 - val_loss: 16.9963\n",
      "Epoch 266/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.7749\n",
      "Epoch 266: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7030 - val_loss: 15.0780\n",
      "Epoch 267/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.3938\n",
      "Epoch 267: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4570 - val_loss: 16.3392\n",
      "Epoch 268/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.2119\n",
      "Epoch 268: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1760 - val_loss: 13.0133\n",
      "Epoch 269/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.7368\n",
      "Epoch 269: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7445 - val_loss: 14.3734\n",
      "Epoch 270/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.9901\n",
      "Epoch 270: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9854 - val_loss: 16.0778\n",
      "Epoch 271/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.8224\n",
      "Epoch 271: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0048 - val_loss: 16.6691\n",
      "Epoch 272/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 7.1777\n",
      "Epoch 272: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8826 - val_loss: 15.7514\n",
      "Epoch 273/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.8924\n",
      "Epoch 273: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8924 - val_loss: 19.0542\n",
      "Epoch 274/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.8116\n",
      "Epoch 274: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8318 - val_loss: 17.0631\n",
      "Epoch 275/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.6490\n",
      "Epoch 275: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.7178 - val_loss: 14.1543\n",
      "Epoch 276/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.6433\n",
      "Epoch 276: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6044 - val_loss: 15.4788\n",
      "Epoch 277/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.7825\n",
      "Epoch 277: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9122 - val_loss: 15.5442\n",
      "Epoch 278/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.5112\n",
      "Epoch 278: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.5479 - val_loss: 12.3047\n",
      "Epoch 279/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 7.1951\n",
      "Epoch 279: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 7.1016 - val_loss: 16.3222\n",
      "Epoch 280/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.5386\n",
      "Epoch 280: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4313 - val_loss: 17.8953\n",
      "Epoch 281/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.0243\n",
      "Epoch 281: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.0254 - val_loss: 16.0111\n",
      "Epoch 282/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.2639\n",
      "Epoch 282: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4027 - val_loss: 17.3672\n",
      "Epoch 283/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.6280\n",
      "Epoch 283: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4492 - val_loss: 17.7944\n",
      "Epoch 284/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.7890\n",
      "Epoch 284: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0827 - val_loss: 16.9795\n",
      "Epoch 285/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 6.5452\n",
      "Epoch 285: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.8899 - val_loss: 14.4084\n",
      "Epoch 286/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.1345\n",
      "Epoch 286: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.0946 - val_loss: 15.7529\n",
      "Epoch 287/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.9595\n",
      "Epoch 287: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0136 - val_loss: 15.8596\n",
      "Epoch 288/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.4959\n",
      "Epoch 288: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5069 - val_loss: 17.5818\n",
      "Epoch 289/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/84 [=========================>....] - ETA: 0s - loss: 6.1849\n",
      "Epoch 289: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2272 - val_loss: 16.1416\n",
      "Epoch 290/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.2882\n",
      "Epoch 290: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3060 - val_loss: 13.7532\n",
      "Epoch 291/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.3462\n",
      "Epoch 291: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3049 - val_loss: 15.4493\n",
      "Epoch 292/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.8989\n",
      "Epoch 292: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8680 - val_loss: 16.5450\n",
      "Epoch 293/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.0874\n",
      "Epoch 293: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0054 - val_loss: 16.4006\n",
      "Epoch 294/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.9036\n",
      "Epoch 294: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9100 - val_loss: 16.7265\n",
      "Epoch 295/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.4791\n",
      "Epoch 295: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4204 - val_loss: 13.7936\n",
      "Epoch 296/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.7432\n",
      "Epoch 296: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6859 - val_loss: 16.9943\n",
      "Epoch 297/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.5680\n",
      "Epoch 297: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9500 - val_loss: 21.3858\n",
      "Epoch 298/700\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 6.6438\n",
      "Epoch 298: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6175 - val_loss: 15.7448\n",
      "Epoch 299/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.7920\n",
      "Epoch 299: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9601 - val_loss: 14.7036\n",
      "Epoch 300/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.2123\n",
      "Epoch 300: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3205 - val_loss: 17.0625\n",
      "Epoch 301/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.3992\n",
      "Epoch 301: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2362 - val_loss: 17.8446\n",
      "Epoch 302/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.0097\n",
      "Epoch 302: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9605 - val_loss: 16.3413\n",
      "Epoch 303/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.9585\n",
      "Epoch 303: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9984 - val_loss: 17.9480\n",
      "Epoch 304/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 6.3803\n",
      "Epoch 304: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3502 - val_loss: 16.8401\n",
      "Epoch 305/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.6965\n",
      "Epoch 305: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8269 - val_loss: 16.3122\n",
      "Epoch 306/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.4160\n",
      "Epoch 306: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2954 - val_loss: 16.8904\n",
      "Epoch 307/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.1730\n",
      "Epoch 307: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1535 - val_loss: 15.6563\n",
      "Epoch 308/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.2552\n",
      "Epoch 308: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0927 - val_loss: 15.6170\n",
      "Epoch 309/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.8573\n",
      "Epoch 309: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5991 - val_loss: 16.7731\n",
      "Epoch 310/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.0063\n",
      "Epoch 310: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9267 - val_loss: 16.0153\n",
      "Epoch 311/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.1712\n",
      "Epoch 311: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1410 - val_loss: 18.3207\n",
      "Epoch 312/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.5101\n",
      "Epoch 312: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3827 - val_loss: 17.6043\n",
      "Epoch 313/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.4481\n",
      "Epoch 313: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4165 - val_loss: 16.5016\n",
      "Epoch 314/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.6454\n",
      "Epoch 314: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7825 - val_loss: 15.4830\n",
      "Epoch 315/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 6.2399\n",
      "Epoch 315: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2528 - val_loss: 16.8499\n",
      "Epoch 316/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.2257\n",
      "Epoch 316: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3042 - val_loss: 17.5343\n",
      "Epoch 317/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.6301\n",
      "Epoch 317: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8309 - val_loss: 16.6135\n",
      "Epoch 318/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.7030\n",
      "Epoch 318: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6372 - val_loss: 17.3770\n",
      "Epoch 319/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.8971\n",
      "Epoch 319: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1775 - val_loss: 15.5393\n",
      "Epoch 320/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.5088\n",
      "Epoch 320: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4389 - val_loss: 15.9507\n",
      "Epoch 321/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.1230\n",
      "Epoch 321: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2067 - val_loss: 17.4123\n",
      "Epoch 322/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.7454\n",
      "Epoch 322: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5104 - val_loss: 17.2055\n",
      "Epoch 323/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.7565\n",
      "Epoch 323: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6207 - val_loss: 16.0412\n",
      "Epoch 324/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.8661\n",
      "Epoch 324: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9097 - val_loss: 15.0978\n",
      "Epoch 325/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.3552\n",
      "Epoch 325: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3999 - val_loss: 13.7624\n",
      "Epoch 326/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.8350\n",
      "Epoch 326: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5688 - val_loss: 17.5066\n",
      "Epoch 327/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/84 [=========================>....] - ETA: 0s - loss: 6.6001\n",
      "Epoch 327: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.5392 - val_loss: 14.6732\n",
      "Epoch 328/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.9197\n",
      "Epoch 328: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9390 - val_loss: 17.0275\n",
      "Epoch 329/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.7982\n",
      "Epoch 329: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9571 - val_loss: 15.5468\n",
      "Epoch 330/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.1259\n",
      "Epoch 330: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0724 - val_loss: 17.0658\n",
      "Epoch 331/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.6263\n",
      "Epoch 331: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6036 - val_loss: 16.1725\n",
      "Epoch 332/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 6.1530\n",
      "Epoch 332: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0643 - val_loss: 16.6256\n",
      "Epoch 333/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.5763\n",
      "Epoch 333: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4915 - val_loss: 18.1108\n",
      "Epoch 334/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 6.2234\n",
      "Epoch 334: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1233 - val_loss: 15.6473\n",
      "Epoch 335/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 6.4779\n",
      "Epoch 335: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1686 - val_loss: 15.9703\n",
      "Epoch 336/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.4212\n",
      "Epoch 336: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4326 - val_loss: 14.9124\n",
      "Epoch 337/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.9013\n",
      "Epoch 337: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9745 - val_loss: 17.2155\n",
      "Epoch 338/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 6.2225\n",
      "Epoch 338: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1495 - val_loss: 12.5189\n",
      "Epoch 339/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.4676\n",
      "Epoch 339: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2677 - val_loss: 13.7282\n",
      "Epoch 340/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.5205\n",
      "Epoch 340: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5596 - val_loss: 15.7387\n",
      "Epoch 341/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.9001\n",
      "Epoch 341: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9627 - val_loss: 16.3665\n",
      "Epoch 342/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.8108\n",
      "Epoch 342: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7817 - val_loss: 17.3134\n",
      "Epoch 343/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.0394\n",
      "Epoch 343: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9736 - val_loss: 15.3883\n",
      "Epoch 344/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.6907\n",
      "Epoch 344: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7602 - val_loss: 17.4302\n",
      "Epoch 345/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.0611\n",
      "Epoch 345: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0829 - val_loss: 16.0650\n",
      "Epoch 346/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.1722\n",
      "Epoch 346: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0665 - val_loss: 16.2907\n",
      "Epoch 347/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.5021\n",
      "Epoch 347: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5062 - val_loss: 14.4240\n",
      "Epoch 348/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.8507\n",
      "Epoch 348: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7332 - val_loss: 16.7694\n",
      "Epoch 349/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.8523\n",
      "Epoch 349: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8273 - val_loss: 16.4298\n",
      "Epoch 350/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 6.1727\n",
      "Epoch 350: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4054 - val_loss: 15.5575\n",
      "Epoch 351/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.2182\n",
      "Epoch 351: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0237 - val_loss: 16.6473\n",
      "Epoch 352/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.7385\n",
      "Epoch 352: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7873 - val_loss: 15.0055\n",
      "Epoch 353/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.4550\n",
      "Epoch 353: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4923 - val_loss: 15.8785\n",
      "Epoch 354/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 6.1602\n",
      "Epoch 354: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1695 - val_loss: 16.2209\n",
      "Epoch 355/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.6452\n",
      "Epoch 355: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9508 - val_loss: 18.9119\n",
      "Epoch 356/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 6.1534\n",
      "Epoch 356: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0392 - val_loss: 13.8275\n",
      "Epoch 357/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.5658\n",
      "Epoch 357: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4863 - val_loss: 15.5161\n",
      "Epoch 358/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.8688\n",
      "Epoch 358: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8411 - val_loss: 15.6312\n",
      "Epoch 359/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.6062\n",
      "Epoch 359: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6393 - val_loss: 17.6609\n",
      "Epoch 360/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.7358\n",
      "Epoch 360: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7802 - val_loss: 15.3097\n",
      "Epoch 361/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.8834\n",
      "Epoch 361: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8073 - val_loss: 15.4463\n",
      "Epoch 362/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.6428\n",
      "Epoch 362: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6183 - val_loss: 16.0594\n",
      "Epoch 363/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.7621\n",
      "Epoch 363: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8571 - val_loss: 15.7504\n",
      "Epoch 364/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.0612\n",
      "Epoch 364: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9075 - val_loss: 14.4737\n",
      "Epoch 365/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/84 [========================>.....] - ETA: 0s - loss: 6.0779\n",
      "Epoch 365: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8853 - val_loss: 14.9822\n",
      "Epoch 366/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.9131\n",
      "Epoch 366: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8234 - val_loss: 17.2864\n",
      "Epoch 367/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.7961\n",
      "Epoch 367: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6831 - val_loss: 18.3011\n",
      "Epoch 368/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.4963\n",
      "Epoch 368: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3326 - val_loss: 14.1241\n",
      "Epoch 369/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.7510\n",
      "Epoch 369: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1007 - val_loss: 14.6086\n",
      "Epoch 370/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.3915\n",
      "Epoch 370: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4933 - val_loss: 14.5706\n",
      "Epoch 371/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 6.0241\n",
      "Epoch 371: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8275 - val_loss: 15.5970\n",
      "Epoch 372/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.3086\n",
      "Epoch 372: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4011 - val_loss: 16.5142\n",
      "Epoch 373/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.4174\n",
      "Epoch 373: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4549 - val_loss: 16.6468\n",
      "Epoch 374/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 6.0498\n",
      "Epoch 374: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1052 - val_loss: 17.0540\n",
      "Epoch 375/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.7087\n",
      "Epoch 375: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7373 - val_loss: 16.0474\n",
      "Epoch 376/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.4622\n",
      "Epoch 376: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3485 - val_loss: 13.9289\n",
      "Epoch 377/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.5993\n",
      "Epoch 377: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7478 - val_loss: 14.5814\n",
      "Epoch 378/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.7271\n",
      "Epoch 378: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8558 - val_loss: 15.8227\n",
      "Epoch 379/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.2441\n",
      "Epoch 379: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3558 - val_loss: 13.2637\n",
      "Epoch 380/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.3042\n",
      "Epoch 380: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3279 - val_loss: 16.1510\n",
      "Epoch 381/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.5523\n",
      "Epoch 381: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6555 - val_loss: 15.8648\n",
      "Epoch 382/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.6531\n",
      "Epoch 382: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8066 - val_loss: 16.4041\n",
      "Epoch 383/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 6.6324\n",
      "Epoch 383: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4816 - val_loss: 17.8954\n",
      "Epoch 384/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.4620\n",
      "Epoch 384: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5486 - val_loss: 15.9145\n",
      "Epoch 385/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.4543\n",
      "Epoch 385: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3895 - val_loss: 16.7104\n",
      "Epoch 386/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 6.0429\n",
      "Epoch 386: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9336 - val_loss: 17.5225\n",
      "Epoch 387/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.6175\n",
      "Epoch 387: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6124 - val_loss: 16.1417\n",
      "Epoch 388/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 5.3789\n",
      "Epoch 388: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3021 - val_loss: 16.7648\n",
      "Epoch 389/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.9845\n",
      "Epoch 389: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.3139 - val_loss: 16.6843\n",
      "Epoch 390/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 6.2631\n",
      "Epoch 390: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1206 - val_loss: 17.1401\n",
      "Epoch 391/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.7438\n",
      "Epoch 391: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8772 - val_loss: 14.5779\n",
      "Epoch 392/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.5414\n",
      "Epoch 392: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6186 - val_loss: 15.2462\n",
      "Epoch 393/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.5205\n",
      "Epoch 393: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6323 - val_loss: 16.0098\n",
      "Epoch 394/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.6449\n",
      "Epoch 394: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6413 - val_loss: 15.5564\n",
      "Epoch 395/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 4.9349\n",
      "Epoch 395: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0074 - val_loss: 17.6328\n",
      "Epoch 396/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.2960\n",
      "Epoch 396: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3544 - val_loss: 16.3462\n",
      "Epoch 397/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.2920\n",
      "Epoch 397: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 5.2749 - val_loss: 13.4806\n",
      "Epoch 398/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.3722\n",
      "Epoch 398: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 5.3801 - val_loss: 14.4885\n",
      "Epoch 399/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.1987\n",
      "Epoch 399: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5082 - val_loss: 14.7448\n",
      "Epoch 400/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.6783\n",
      "Epoch 400: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8667 - val_loss: 15.8205\n",
      "Epoch 401/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.9999\n",
      "Epoch 401: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8761 - val_loss: 18.7327\n",
      "Epoch 402/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 6.1228\n",
      "Epoch 402: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.1487 - val_loss: 12.5759\n",
      "Epoch 403/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/84 [========================>.....] - ETA: 0s - loss: 5.6436\n",
      "Epoch 403: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6401 - val_loss: 15.1379\n",
      "Epoch 404/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.5901\n",
      "Epoch 404: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7932 - val_loss: 14.7348\n",
      "Epoch 405/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.8618\n",
      "Epoch 405: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7513 - val_loss: 13.9457\n",
      "Epoch 406/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.9442\n",
      "Epoch 406: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8613 - val_loss: 13.8637\n",
      "Epoch 407/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.7707\n",
      "Epoch 407: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6622 - val_loss: 14.6432\n",
      "Epoch 408/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.6093\n",
      "Epoch 408: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6619 - val_loss: 15.0283\n",
      "Epoch 409/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 6.0363\n",
      "Epoch 409: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 6.0188 - val_loss: 15.1834\n",
      "Epoch 410/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.3490\n",
      "Epoch 410: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4227 - val_loss: 16.2163\n",
      "Epoch 411/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.4605\n",
      "Epoch 411: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5502 - val_loss: 17.0641\n",
      "Epoch 412/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.6536\n",
      "Epoch 412: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 5.7033 - val_loss: 18.1029\n",
      "Epoch 413/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.7209\n",
      "Epoch 413: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 5.7924 - val_loss: 15.5926\n",
      "Epoch 414/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.6143\n",
      "Epoch 414: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5264 - val_loss: 16.3238\n",
      "Epoch 415/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.6405\n",
      "Epoch 415: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6910 - val_loss: 14.8511\n",
      "Epoch 416/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.5176\n",
      "Epoch 416: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5231 - val_loss: 14.2791\n",
      "Epoch 417/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.4599\n",
      "Epoch 417: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5190 - val_loss: 16.8281\n",
      "Epoch 418/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.5119\n",
      "Epoch 418: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5529 - val_loss: 16.4441\n",
      "Epoch 419/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 6.1444\n",
      "Epoch 419: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.2664 - val_loss: 17.1402\n",
      "Epoch 420/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.9963\n",
      "Epoch 420: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8530 - val_loss: 18.1141\n",
      "Epoch 421/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.6793\n",
      "Epoch 421: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7273 - val_loss: 14.5272\n",
      "Epoch 422/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.9409\n",
      "Epoch 422: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9190 - val_loss: 15.5565\n",
      "Epoch 423/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.7029\n",
      "Epoch 423: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5187 - val_loss: 15.7739\n",
      "Epoch 424/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.5576\n",
      "Epoch 424: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6437 - val_loss: 14.5839\n",
      "Epoch 425/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.4189\n",
      "Epoch 425: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3254 - val_loss: 13.5931\n",
      "Epoch 426/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.5685\n",
      "Epoch 426: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5774 - val_loss: 13.9356\n",
      "Epoch 427/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.9608\n",
      "Epoch 427: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8440 - val_loss: 16.8471\n",
      "Epoch 428/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.7434\n",
      "Epoch 428: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7298 - val_loss: 14.9442\n",
      "Epoch 429/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 6.0469\n",
      "Epoch 429: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0327 - val_loss: 16.3745\n",
      "Epoch 430/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.3013\n",
      "Epoch 430: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2436 - val_loss: 14.8867\n",
      "Epoch 431/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 5.3364\n",
      "Epoch 431: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3364 - val_loss: 13.7364\n",
      "Epoch 432/700\n",
      "66/84 [======================>.......] - ETA: 0s - loss: 5.7480\n",
      "Epoch 432: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6221 - val_loss: 16.4713\n",
      "Epoch 433/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.9038\n",
      "Epoch 433: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8021 - val_loss: 17.7761\n",
      "Epoch 434/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.1693\n",
      "Epoch 434: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1259 - val_loss: 14.0096\n",
      "Epoch 435/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 5.8237\n",
      "Epoch 435: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6045 - val_loss: 15.0330\n",
      "Epoch 436/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.3279\n",
      "Epoch 436: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3517 - val_loss: 14.1284\n",
      "Epoch 437/700\n",
      "63/84 [=====================>........] - ETA: 0s - loss: 5.4549\n",
      "Epoch 437: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3099 - val_loss: 12.2424\n",
      "Epoch 438/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.3367\n",
      "Epoch 438: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5311 - val_loss: 14.9818\n",
      "Epoch 439/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.5719\n",
      "Epoch 439: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6104 - val_loss: 15.9655\n",
      "Epoch 440/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.1191\n",
      "Epoch 440: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2391 - val_loss: 14.7855\n",
      "Epoch 441/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/84 [=======================>......] - ETA: 0s - loss: 6.0821\n",
      "Epoch 441: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9539 - val_loss: 16.0648\n",
      "Epoch 442/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.2111\n",
      "Epoch 442: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3193 - val_loss: 12.8581\n",
      "Epoch 443/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.0571\n",
      "Epoch 443: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0800 - val_loss: 13.0711\n",
      "Epoch 444/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.8184\n",
      "Epoch 444: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7346 - val_loss: 14.8655\n",
      "Epoch 445/700\n",
      "64/84 [=====================>........] - ETA: 0s - loss: 5.3961\n",
      "Epoch 445: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4910 - val_loss: 15.5046\n",
      "Epoch 446/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.3805\n",
      "Epoch 446: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4818 - val_loss: 15.5359\n",
      "Epoch 447/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.2726\n",
      "Epoch 447: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 5.2170 - val_loss: 14.3762\n",
      "Epoch 448/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.4107\n",
      "Epoch 448: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3217 - val_loss: 16.1848\n",
      "Epoch 449/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.6235\n",
      "Epoch 449: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5785 - val_loss: 14.4270\n",
      "Epoch 450/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.3711\n",
      "Epoch 450: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4479 - val_loss: 15.4710\n",
      "Epoch 451/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 7.0329\n",
      "Epoch 451: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.6681 - val_loss: 15.8319\n",
      "Epoch 452/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.4122\n",
      "Epoch 452: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3236 - val_loss: 16.9416\n",
      "Epoch 453/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.7544\n",
      "Epoch 453: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6304 - val_loss: 14.0177\n",
      "Epoch 454/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.8604\n",
      "Epoch 454: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9475 - val_loss: 14.2408\n",
      "Epoch 455/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.5410\n",
      "Epoch 455: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5124 - val_loss: 15.2716\n",
      "Epoch 456/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.8303\n",
      "Epoch 456: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7767 - val_loss: 14.1954\n",
      "Epoch 457/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.6548\n",
      "Epoch 457: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6821 - val_loss: 16.1842\n",
      "Epoch 458/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.4302\n",
      "Epoch 458: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6709 - val_loss: 16.5846\n",
      "Epoch 459/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.4053\n",
      "Epoch 459: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3838 - val_loss: 15.7754\n",
      "Epoch 460/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.4325\n",
      "Epoch 460: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2136 - val_loss: 17.2389\n",
      "Epoch 461/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.5086\n",
      "Epoch 461: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5823 - val_loss: 18.7407\n",
      "Epoch 462/700\n",
      "83/84 [============================>.] - ETA: 0s - loss: 5.7489\n",
      "Epoch 462: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.7724 - val_loss: 15.6183\n",
      "Epoch 463/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.7583\n",
      "Epoch 463: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8702 - val_loss: 17.3970\n",
      "Epoch 464/700\n",
      "65/84 [======================>.......] - ETA: 0s - loss: 5.9836\n",
      "Epoch 464: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6698 - val_loss: 16.0908\n",
      "Epoch 465/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 4.9433\n",
      "Epoch 465: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9278 - val_loss: 15.0601\n",
      "Epoch 466/700\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 5.1123\n",
      "Epoch 466: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1622 - val_loss: 16.8707\n",
      "Epoch 467/700\n",
      "84/84 [==============================] - ETA: 0s - loss: 6.4060\n",
      "Epoch 467: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.4060 - val_loss: 16.5565\n",
      "Epoch 468/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 7.1668\n",
      "Epoch 468: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.9200 - val_loss: 15.6759\n",
      "Epoch 469/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.6698\n",
      "Epoch 469: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6243 - val_loss: 16.6455\n",
      "Epoch 470/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.0932\n",
      "Epoch 470: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2652 - val_loss: 17.5995\n",
      "Epoch 471/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.3414\n",
      "Epoch 471: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2925 - val_loss: 16.1829\n",
      "Epoch 472/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.2853\n",
      "Epoch 472: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2291 - val_loss: 15.9976\n",
      "Epoch 473/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 4.9628\n",
      "Epoch 473: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0334 - val_loss: 13.6833\n",
      "Epoch 474/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.5149\n",
      "Epoch 474: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4247 - val_loss: 16.7697\n",
      "Epoch 475/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.6071\n",
      "Epoch 475: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6690 - val_loss: 17.2179\n",
      "Epoch 476/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.8052\n",
      "Epoch 476: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9376 - val_loss: 14.0830\n",
      "Epoch 477/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.5279\n",
      "Epoch 477: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5133 - val_loss: 15.6997\n",
      "Epoch 478/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.3455\n",
      "Epoch 478: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4688 - val_loss: 13.1497\n",
      "Epoch 479/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/84 [===========================>..] - ETA: 0s - loss: 5.3165\n",
      "Epoch 479: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3137 - val_loss: 14.2035\n",
      "Epoch 480/700\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 5.4665\n",
      "Epoch 480: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3678 - val_loss: 14.5605\n",
      "Epoch 481/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.0871\n",
      "Epoch 481: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1804 - val_loss: 17.6776\n",
      "Epoch 482/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.4232\n",
      "Epoch 482: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4823 - val_loss: 17.2735\n",
      "Epoch 483/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.4987\n",
      "Epoch 483: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4195 - val_loss: 15.9692\n",
      "Epoch 484/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.5946\n",
      "Epoch 484: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4964 - val_loss: 15.9685\n",
      "Epoch 485/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.4875\n",
      "Epoch 485: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3927 - val_loss: 14.2826\n",
      "Epoch 486/700\n",
      "82/84 [============================>.] - ETA: 0s - loss: 5.8816\n",
      "Epoch 486: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.9038 - val_loss: 15.2792\n",
      "Epoch 487/700\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 5.4422\n",
      "Epoch 487: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4376 - val_loss: 13.8326\n",
      "Epoch 488/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.3128\n",
      "Epoch 488: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4572 - val_loss: 15.4798\n",
      "Epoch 489/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.5336\n",
      "Epoch 489: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5553 - val_loss: 14.6331\n",
      "Epoch 490/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.4429\n",
      "Epoch 490: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4098 - val_loss: 14.0199\n",
      "Epoch 491/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.2151\n",
      "Epoch 491: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3576 - val_loss: 14.4818\n",
      "Epoch 492/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.4698\n",
      "Epoch 492: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5273 - val_loss: 14.4843\n",
      "Epoch 493/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.4997\n",
      "Epoch 493: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6680 - val_loss: 14.3048\n",
      "Epoch 494/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.6465\n",
      "Epoch 494: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6341 - val_loss: 14.0086\n",
      "Epoch 495/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.6119\n",
      "Epoch 495: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4797 - val_loss: 14.9532\n",
      "Epoch 496/700\n",
      "62/84 [=====================>........] - ETA: 0s - loss: 5.5424\n",
      "Epoch 496: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3075 - val_loss: 14.4410\n",
      "Epoch 497/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.3406\n",
      "Epoch 497: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2536 - val_loss: 13.1503\n",
      "Epoch 498/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 4.7705\n",
      "Epoch 498: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.7884 - val_loss: 12.1025\n",
      "Epoch 499/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.2370\n",
      "Epoch 499: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2806 - val_loss: 14.4966\n",
      "Epoch 500/700\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 5.2756\n",
      "Epoch 500: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2795 - val_loss: 14.9293\n",
      "Epoch 501/700\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 5.9888\n",
      "Epoch 501: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 6.0175 - val_loss: 14.9713\n",
      "Epoch 502/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.3624\n",
      "Epoch 502: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3088 - val_loss: 15.6862\n",
      "Epoch 503/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.3161\n",
      "Epoch 503: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3077 - val_loss: 16.8905\n",
      "Epoch 504/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.1672\n",
      "Epoch 504: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1440 - val_loss: 14.5252\n",
      "Epoch 505/700\n",
      "70/84 [========================>.....] - ETA: 0s - loss: 5.3348\n",
      "Epoch 505: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.6023 - val_loss: 15.0678\n",
      "Epoch 506/700\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 5.5951\n",
      "Epoch 506: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5272 - val_loss: 12.9763\n",
      "Epoch 507/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.9101\n",
      "Epoch 507: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8115 - val_loss: 15.0077\n",
      "Epoch 508/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.5557\n",
      "Epoch 508: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.5835 - val_loss: 12.4257\n",
      "Epoch 509/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.3420\n",
      "Epoch 509: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2005 - val_loss: 14.0500\n",
      "Epoch 510/700\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 5.1049\n",
      "Epoch 510: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.1084 - val_loss: 13.4636\n",
      "Epoch 511/700\n",
      "73/84 [=========================>....] - ETA: 0s - loss: 5.0605\n",
      "Epoch 511: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2353 - val_loss: 13.8217\n",
      "Epoch 512/700\n",
      "69/84 [=======================>......] - ETA: 0s - loss: 5.8080\n",
      "Epoch 512: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.8384 - val_loss: 15.0371\n",
      "Epoch 513/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 5.3554\n",
      "Epoch 513: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3019 - val_loss: 13.3337\n",
      "Epoch 514/700\n",
      "76/84 [==========================>...] - ETA: 0s - loss: 4.8805\n",
      "Epoch 514: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0477 - val_loss: 13.2690\n",
      "Epoch 515/700\n",
      "68/84 [=======================>......] - ETA: 0s - loss: 5.3982\n",
      "Epoch 515: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.3499 - val_loss: 14.7650\n",
      "Epoch 516/700\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 5.2197\n",
      "Epoch 516: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.2496 - val_loss: 14.5285\n",
      "Epoch 517/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/84 [==========================>...] - ETA: 0s - loss: 5.0465\n",
      "Epoch 517: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.0769 - val_loss: 11.9062\n",
      "Epoch 518/700\n",
      "75/84 [=========================>....] - ETA: 0s - loss: 5.4223\n",
      "Epoch 518: val_loss did not improve from 8.93266\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4447 - val_loss: 11.5982\n"
     ]
    }
   ],
   "source": [
    "# 2차원의 CNN + LSTM 모델 정의\n",
    "# 기본적으로 시계열 데이터이므로 LSTM 모델이 가장 적합하다고 판단.\n",
    "# 어느 시간대에 어느 피처값이 중요하게 작용하는지 그 특징을 찾아내기 위해 CNN을 활용함. (특징 추출)\n",
    "\n",
    "hidden_units = 360 # (24*10)의 1.5배로 설정\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 700\n",
    "NORM = regularizers.l2(0.01)\n",
    "\n",
    "# leaky_relu = LeakyReLU(0.2)\n",
    "\n",
    "model = kFoldModelFit(input_data, targets, BATCH_SIZE, EPOCHS, hidden_units, NORM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습 결과 시각화\n",
    "* 각 fold중 validation loss값이 가장 작은 모델을 불러와 시각화 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- < ./model_save/1_fold_204-10.9574.hdf5 > -----\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "----- < ./model_save/2_fold_049-12.2967.hdf5 > -----\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "----- < ./model_save/3_fold_079-12.4715.hdf5 > -----\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "----- < ./model_save/4_fold_300-25.4943.hdf5 > -----\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "----- < ./model_save/5_fold_127-7.9495.hdf5 > -----\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "----- < ./model_save/6_fold_007-14.0299.hdf5 > -----\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "----- < ./model_save/7_fold_018-8.9327.hdf5 > -----\n",
      "4/4 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7번의 교차 검증으로 학습한 결과중 가장 우수하게 학습된 top3의 모델 선별\n",
    "# 각 모델들이 어떻게 validation을 진행하였는지 graph 그려보기\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "hdf5_path = './model_save/'\n",
    "\n",
    "files = os.listdir(hdf5_path)\n",
    "\n",
    "models_list = []\n",
    "\n",
    "for file in files:\n",
    "    if 'hdf5' in file:\n",
    "        models_list.append(hdf5_path+file)\n",
    "\n",
    "\n",
    "for i, model in enumerate(models_list):\n",
    "    print('-'*5, '<', model, '>', '-'*5)\n",
    "    loaded_model = load_model(model, custom_objects={'rmse': rmse})\n",
    "    \n",
    "    pred = loaded_model.predict(X_val_list[i])\n",
    "\n",
    "    yval_df = pd.DataFrame(y_val_list[i])\n",
    "    pred_df = pd.DataFrame(pred)\n",
    "\n",
    "    val_pred_df = pd.DataFrame(pd.concat([yval_df, pred_df], axis=1).values, columns=['yval', 'pred'])\n",
    "    \n",
    "    plt.figure(figsize=(16,9))\n",
    "    plt.rcParams['font.family'] = 'HYGothic-Extra'\n",
    "    title_font = {'fontsize': 16,\n",
    "                  'fontweight': 'bold'}\n",
    "    plt.title(model, fontdict=title_font, pad=20)\n",
    "    sns.lineplot(data=val_pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST\n",
    "* 총 7개의 fold, 그 중에서도 가장 학습이 잘 되어 보이는 모델로 test data 예측 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data 불러오기\n",
    "test_path = './test_input/'\n",
    "\n",
    "files = os.listdir(test_path)\n",
    "\n",
    "test_df_list = []\n",
    "\n",
    "for file in files:\n",
    "    if 'csv' in file:\n",
    "        df = pd.read_csv(test_path+file)\n",
    "        test_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data 전처리 진행(절댓값, 정규화)\n",
    "test_df = pd.concat(test_df_list).reset_index(drop=True)\n",
    "\n",
    "test_df1 = prepro(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAT</th>\n",
       "      <th>내부온도관측치</th>\n",
       "      <th>내부습도관측치</th>\n",
       "      <th>co2관측치</th>\n",
       "      <th>ec관측치</th>\n",
       "      <th>시간당분무량</th>\n",
       "      <th>시간당백색광량</th>\n",
       "      <th>시간당적색광량</th>\n",
       "      <th>시간당청색광량</th>\n",
       "      <th>시간당총광량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261725</td>\n",
       "      <td>0.578485</td>\n",
       "      <td>0.197276</td>\n",
       "      <td>0.730669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.273344</td>\n",
       "      <td>0.575470</td>\n",
       "      <td>0.198170</td>\n",
       "      <td>0.731802</td>\n",
       "      <td>0.371075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244656</td>\n",
       "      <td>0.572234</td>\n",
       "      <td>0.198677</td>\n",
       "      <td>0.734435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243811</td>\n",
       "      <td>0.577090</td>\n",
       "      <td>0.204206</td>\n",
       "      <td>0.734663</td>\n",
       "      <td>0.371075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266185</td>\n",
       "      <td>0.579299</td>\n",
       "      <td>0.192857</td>\n",
       "      <td>0.735246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3355</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.179533</td>\n",
       "      <td>0.562669</td>\n",
       "      <td>0.154537</td>\n",
       "      <td>0.650580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3356</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.186837</td>\n",
       "      <td>0.547551</td>\n",
       "      <td>0.150698</td>\n",
       "      <td>0.651106</td>\n",
       "      <td>0.039081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3357</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162233</td>\n",
       "      <td>0.537753</td>\n",
       "      <td>0.143140</td>\n",
       "      <td>0.651001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152314</td>\n",
       "      <td>0.528798</td>\n",
       "      <td>0.133168</td>\n",
       "      <td>0.651873</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3359</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.150085</td>\n",
       "      <td>0.534235</td>\n",
       "      <td>0.125199</td>\n",
       "      <td>0.651884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3360 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DAT   내부온도관측치   내부습도관측치    co2관측치     ec관측치    시간당분무량   시간당백색광량  \\\n",
       "0     0.0  0.261725  0.578485  0.197276  0.730669  0.000000  0.000000   \n",
       "1     0.0  0.273344  0.575470  0.198170  0.731802  0.371075  0.000000   \n",
       "2     0.0  0.244656  0.572234  0.198677  0.734435  0.000000  0.000000   \n",
       "3     0.0  0.243811  0.577090  0.204206  0.734663  0.371075  0.000000   \n",
       "4     0.0  0.266185  0.579299  0.192857  0.735246  0.000000  0.000000   \n",
       "...   ...       ...       ...       ...       ...       ...       ...   \n",
       "3355  1.0  0.179533  0.562669  0.154537  0.650580  0.000000  0.000333   \n",
       "3356  1.0  0.186837  0.547551  0.150698  0.651106  0.039081  0.000000   \n",
       "3357  1.0  0.162233  0.537753  0.143140  0.651001  0.000000  0.000000   \n",
       "3358  1.0  0.152314  0.528798  0.133168  0.651873  0.060800  0.000000   \n",
       "3359  1.0  0.150085  0.534235  0.125199  0.651884  0.000000  0.000000   \n",
       "\n",
       "      시간당적색광량  시간당청색광량    시간당총광량  \n",
       "0         0.0      0.0  0.000000  \n",
       "1         0.0      0.0  0.000000  \n",
       "2         0.0      0.0  0.000000  \n",
       "3         0.0      0.0  0.000000  \n",
       "4         0.0      0.0  0.000000  \n",
       "...       ...      ...       ...  \n",
       "3355      0.0      0.0  0.000163  \n",
       "3356      0.0      0.0  0.000000  \n",
       "3357      0.0      0.0  0.000000  \n",
       "3358      0.0      0.0  0.000000  \n",
       "3359      0.0      0.0  0.000000  \n",
       "\n",
       "[3360 rows x 10 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 일간누적\n",
    "# test_df2 = mm_test_df.iloc[:,[0,2,3,4,5,7,9,11,13,15]]\n",
    "\n",
    "## 시간당\n",
    "test_df2 = test_df1.iloc[:,[0,2,3,4,5,6,8,10,12,14]]\n",
    "\n",
    "## 모두 사용\n",
    "# test_df2 = mm_test_df.drop(['obs_time'], axis=1)\n",
    "\n",
    "test_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test feature data를 24시간 간격으로 자르기\n",
    "sliced_list = slice_24(test_df2)\n",
    "\n",
    "test_input = np.array(sliced_list)\n",
    "test_input = test_input.reshape(140,24,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model_save/1_fold_204-10.9574.hdf5\n",
      "5/5 [==============================] - 0s 10ms/step\n",
      "./model_save/3_fold_079-12.4715.hdf5\n",
      "5/5 [==============================] - 0s 9ms/step\n",
      "./model_save/5_fold_127-7.9495.hdf5\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "./model_save/7_fold_018-8.9327.hdf5\n",
      "5/5 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "# validation loss 값이 가장 작았던 모델로 예측 진행..\n",
    "testPreds = []\n",
    "\n",
    "for model in models_list[0::2]:\n",
    "    selected_model = load_model(model, custom_objects={'rmse':rmse})\n",
    "    print(model)\n",
    "\n",
    "    testPred = selected_model.predict(test_input)\n",
    "    testPredDf = pd.DataFrame(testPred, columns=['predicted_weight_g'])\n",
    "    testPreds.append(testPredDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_weight_g</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAT</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.324325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.852734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.876583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.205376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.176702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>62.978054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>98.251160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>95.945656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>107.343079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>114.888397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     predicted_weight_g\n",
       "DAT                    \n",
       "0             10.324325\n",
       "1             14.852734\n",
       "2             11.876583\n",
       "3             16.205376\n",
       "4             20.176702\n",
       "..                  ...\n",
       "135           62.978054\n",
       "136           98.251160\n",
       "137           95.945656\n",
       "138          107.343079\n",
       "139          114.888397\n",
       "\n",
       "[140 rows x 1 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_df = pd.concat(testPreds, axis=1)\n",
    "mean_df = pd.DataFrame(vote_df.iloc[:,:-1].mean(axis='columns'), columns=['predicted_weight_g'])\n",
    "mean_df.index.name='DAT'\n",
    "mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='DAT', ylabel='predicted_weight_g'>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7IAAAIUCAYAAAAnshCzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAADUNUlEQVR4nOzdd5gk910n/ve3QndPntkJmxQ2SVply1rZWJJt2RayMeEAYwMHmAMbA2fC7+7AwHHHYY477mxyxmBjcxiTg8GAc1LAyrKyNkubJvdMx+qqru/vj6rq7pnpUN1d1V3V/X49j5/dnZmdKa+qu+pTnySklCAiIiIiIiKKC6XfB0BERERERETUDgayREREREREFCsMZImIiIiIiChWGMgSERERERFRrDCQJSIiIiIiolhhIEtERERERESxovX7ADo1NzcnDxw40O/DICIiIiIiohA88sgjK1LK+Xqfi20ge+DAATz88MP9PgwiIiIiIiIKgRDibKPPsbSYiIiIiIiIYoWBLBEREREREcUKA1kiIiIiIiKKFQayREREREREFCsMZImIiIiIiChWGMgSERERERFRrDCQJSIiIiIiolhhIEtERERERESxwkCWiIiIiIiIYoWBLBEREREREcUKA1kiIiIiIiKKFQayREREREREFCsMZImIiIiIiChWGMgSERERERFRrDCQJSIiIiIiolhhIEtERERERESxwkCWiIiIiIiIYoWBLBEREREREcUKA1kiIiIiIiKKFQayREREREQAVrIG3vhrX8LplVy/D4WIWmAgS0REREQE4MRSFs8vZvDsxc1+HwoRtcBAloiIiIgIQLZoAQCKZrnPR0JErTCQJSIiIiICkDFMAEDRtPt8JETUCgNZoi48d2kTP/j/HuaTWyIiogHAjCxRfDCQJerCr336BXzy6UWcTxf6fShERETUpU0vkLUYyBJFHQNZog6dXc3hU88sAgAMliARERHFXtbwMrK8rhNFHQNZog798X1nIKXz+1KZFzwiIqK4yxSdHlmDpcVEkcdAlqgDGwUTf/nwS9g/PQKAFzwiIqJBwB5ZovhgIEvUgT9/8EXkS2X84GsPAQAMixlZIiKiuMsUWVpMFBcMZInaZJZtfPj+M3jVoVnccvkMAKDEQJaIiCj2MgaHPRHFBQNZojb9y1OXcHGjiHfceRBJ3XkJMSNLREQUfxmWFhPFBgNZojZIKfHBL5/CwbkxvP7oApKaF8jygkdERBR33rAnlhYTRR8DWaI2PHJ2HU+c28D333kQiiKQcANZlhYTERHFX3X9Dh9QE0UdA1miNvzRl09jakTHW16+HwCQ1FQALC0mIiKKOylltbSY13WiyGMgS+TTi6t5fPKZS/iuV16B0YQGACwtJiIiGhBF00bZdhbEc60eUfQxkCXy6Y/vPw1NEfje2w9UPsbSYiIiosHg9ccCLC0migMGskQ+ZIom/vKhl/CNN+3D7slU5eOaIqAIlhYTERHFnbd6J6EpHPZEFAMMZIl8eGExg1ypjG+4ee+WjwshkNRUBrJEREQx5/XHzo8nuUeWKAYYyBL54F3cpkcTOz6X0BSWFhMREcVc1r3Wz00kWVpMFAMMZIl88ALZiaS243NJTeGwJyIiopjzemTnx5MomjaklH0+IiJqhoEskQ/eXrmJlL7jc0ldgcFeGiIioljzemTnJ5zqK7YNEUUbA1kiH7xyo/HUzoxsQlVglHmxIyIiirPaHlkAfEhNFHEMZIl8yBRNCAGM6uqOzyU1lRc7IiKimKvtkQXAgU9EEcdAlsiHjGFhPKlBUcSOzyV19sgSERHFXaZoYjShYjThVF9x4BNRtDGQJfIhU7TqDnoCnNJiTi0mIiKKt6z70HrErb7iLlmiaGMgS+RDtmjV7Y8FgKTOPbJERERxlylamEhpSOnO7TEzskTRxkCWyIesYdWdWAx463cYyBIREcXZZtHEeEpHqpKRZSBLFGUMZIl8yBRNjDcqLdYUlNgjS0REFGtZw8JkbUaWD6mJIo2BLJEPGaNJaTEzskRERLGXKTo9skmNGVmiOGAgS+RDtug8pa0nqbFHloiIKO6ylR5ZBrJEccBAlsgH7yltPUmNU4uJiIjizmkj0iulxdwRTxRtDGSJWrDKNgpmucWwJz61JSIiiquyLZErlbdmZHltJ4o0BrJELWQNCwCaZmQNy4aUspeHRURERAHxrvUsLSaKDwayRC1kim4g26BHNqEpkBKwbAayREREcbQlkNW8PbIsLSaKMgayRC14F7dmw54AcOATERFRTGWKJgBgPKlDUxVoimBGlijiGMgStVDJyCYb9MhWhkLwgkdERBRH2WI1IwsAKV1lRpYo4hjIErWQNdyntI1Ki1XnZVQq84JHREQUR5kdgazCYU9EEcdAlqiF7Re37ZIc009ERBRrGWPrtT6pqSwtJoo4BrJELVQC2YZTi9kjS0REFGdej6y3ai+lK6E8oH70xXWcWs4G/n2JhhEDWaIWKut3WpUWM5AlIiKKpeo8jNoe2eAzsj/xl0/gNz97PPDvSzSMQgtkhRBTQog3CyGKQojvdT92gxDiq0KIrBDin4UQe9yPzwkh/kUIsSmEuE8IcSis4yJqV7ZoQVUERty9cttVSovZS0NERBRL2aIFRQCjCedan9LVUHpkV7IGK7iIAhJmRvZxAJ8AkKz52B8C2ADwHwG8CsD73Y+/D8AtAH4UwAKAPwrxuIjakimaGE9qEELU/TxLi4mIiOJt+7U+pSuBTy0u2xKbRYt754kCEmYg+1b3fwAA4bwzjAJ4v5TyTwB8AcDL3U/fDeDvpZQfAfAnAF4jhKi/64SoxzKG1XDQEwAkNJYWExERxZlzra/eeqZCGPa0WXD6cMsMZIkC0fjuvEtSyoeFEMs1f5YAbgYAIcReAHcAuNf99B4AK+7vFwGoAOYBXKj9nkKIdwF4FwBcccUVYR060RaZolXpmaknqbG0mIiIKM4yxa0PrcPokU0zkCUKVM+HPQkhbgTwAAAJ4L/W+ZKGr24p5QeklMeklMfm5+fDOkSiLbLF5hnZaiDLjCwREVEcbb/WJ0MoLV7PlwAwkCUKSk8DWSHELQC+CCf7epuU8jn3UxcBzLm/3w3AArC88zsQ9V52W7nRdgkGskRERLGWMcwt1VcpXQ280moj72RkLZv3C0RB6HVG9iPur+8DcKMQ4vXunz8D4JuFEG8H8L0AviilNHt8bER1eQMgGmln2FPRLCPnrvMhIiKiaHAystt7ZIMNONMFJyPLOJYoGKH1yG4nhFgAcKP7x79wfz0D4CCA9wDYC+C3ATwJ4Ad6dVxErWQNq+EOWaC9YU8///Gn8dJ6Hh9959cEdnxERETUnZ09skrwPbLMyBIFKtRAVkp5FkDtzpK6+0uklKsA3hzmsRB1avvFbbt2hj2dTxdwcaMY2LERERFR9zLbHlqndBWWLWGVbWhqMAWMXiDLHlmiYPR82BNRnJQsG4ZlY8LP1GIfJUhFs+zr64iIiKg3DKuMkmVjsra0WHeu7cUA519sFLyMLANZoiAwkCVqIuv2szbrkRVCIKEqKJVbX+wKZplreoiIiCIkW9x5rU/pzvyLIMuLObWYKFgMZIma8C5uzaYWA05W1k+mtVBiRpaIiChKMpVrfU0gqwUfyLK0mChYDGSJmtgsOhedZsOeAGffnJ9Ma9G0uaaHiIgoQjJ1MrJJr7Q4wIfP6QIDWaIgMZAlasIrLW7WIwvAKS32uX6nVLZh8yJGREQUCRnDCTC3rN8JobR4wystlrwHIAoCA1miJjJ+S4t11VemteBeEP300xIREVH46pYW696O+ABLi71hT2UGskRBYCBL1ETW8FlarLUuLZZSVgJZ9skSERFFQ7Zuj2ywpcVlW1amFrO0mCgYDGSJmqh3casnobUuLTYsG141EScXExERRUPGm4cR4tTiTNGs3AOwtJgoGAxkiZrYrDMAoh4nI9s8kK29GHLgExERUTRUVu3VKS0OKiPrTSweT2rMyBIFhIEsURNZw4KuCiS15i+VpNa6R7ZQE8gGOTyCiIiIOpcpWkhoCpLuyh0ASFWmFgdzvfb6Y2fHE7A4J4MiQA5AZQADWaImskULEykdQoimX+entLhQYkaWiIgoajKGhcltLUSVjGxArUBpd2Lx7FiCGVmKhC++sIxXv+9zOL6Y6fehdIyBLFETmaLZsqwY8DfsqbCltJgZWSIioijIuA+ta6W0cEqLZ8eT7JGlSHj4zDoupIvYNz3S70PpGANZoiayhtVGINuqR7b6eU4tJiIiioZsnYfWyaBLi92M7Nw4M7IUDQ+dWcP1+yYx5uM+N6oYyBI14Tylbf0C91NazGFPRERE0VPvWp/UFAgBGAH3yM6MJmAxkKU+K1k2Hn8pjdsO7Or3oXSFgSxRE34DWV/DnkosLSYiIoqaetVXQjiDHosBPXhO501MpDQkNAVSAjaDWeqjJ89vwLBs3HZgpt+H0hUGskRNtFVa3OKpbYEZWSIiosip1yMLOAOfgiot3iiYmBlNQFOc4ZHsk6V+evjMGgDg1iuZkSUaWJmiWffitl1CU1BqMU5/SyDLHlkiIqJI2CyadauvUlpwgex6voTpUR2KF8gyI0t99NCZdRycG8P8RLLfh9IVBrJEDUgpnYysz9JisyybXphqL4ZBjfMnIiKiznnX+rqBrK4EOrV4akSvZGTZJ0v9YtsSj5xdw7Er411WDDCQJWrIsGyYZemvR9adbths4NOWHllmZImIiPouVypDStRtIwq6tHh6NAFVce4XmJGlfjm1ksV63sRtB+NdVgwwkCVqKFO0AAATPnpkE2rrQHbL+h1mZImIiHriez74Ffz6Z16o+7msd62v00aU1NUAhz2VMF2TkWUgS/3y0Jl1AIj9xGKAgSxRQ1nDubj5Ki12M7LNAtSCWUZCdcf5c9gTERFRTzx/KYMvH1+p+7lM0VmLU+9an9KUQDKyti3djGy1R9ayeR9A/fHQ6TXMjSdwYHa034fSNQayRA1UntImWw97SmoqgOYBatEsYyShOhOOGcgSERH1hGVLvHApA1lnUnDG8DKy9UuLg9gjmzEs2BKYrplazDiW+uWhs2s4duUuCCH6fShdYyBL1ECzp7TbJTQvI9u8R3ZEV52dswH13BAREVFzZtlGxrBwcaO443PN2ohSurJl40Cn0vkSAGB6RIfKjCz10aWNIl5aK+BYzPfHehjIEjXgPaX1u0cWaF1azIwsERFRb1llJxP7/KXMjs8165F1hj11f71O550H49OjOlTBHlnqn4fPOvtjB6E/FmAgS9SQd3Gb9LFHNuknI2uWkdJVp1SJgSwREVFPeNnP5xd3BrJe9VWYe2TThWogq6kMZKl/Hj6zjtGEiuv3Tfb7UALBQJaogU5Ki5tPLS4jpStuRpalxURERGGTUsJ0M7Iv1MvINhns6OyRDa60eGokUSktZiBL/fDQmTXccsU0NHUwQsDB+H9BFIJsW6XFrYc9VXpkA1ywTkRERI3VBoz1MrKbbvXVeKLBHtkAKqg23IzsTE1pscVAlnosUzTx7MVNHLtyMMqKAQayRA1lihaSmlLJtjZTKS1u8uS2aNUMe2JGloiIKHReNlZVBI4vZXdkQrNFC+NJrbIWp1ZSV1GybNhdBp3rOSeQnaoZ9sSMLPXaoy+mYcvB6Y8FGMgSNZQxrLo9M/V4gWyp3Dwjm/KGPTEjS0REFDrT7Y+9amEcJcvG2dXcls9nimbDa31Kbz3/wo90oYSJpAZNVdgjS33z8Jk1qIrALVdM9/tQAsNAlqiBbNGqO8WwnkppcZMAtWjabkaWU4uJiIh6wZtYfJ073OaFbeXFWcNq2EKUcq/t3fbJbuRNTI069xOq4tx6s7SYeu2hM2u4ft8kxny0zMUFA1miBjJF01d/LAAkfTy1LZgsLSYiIuoly62UunbPJIQAnr+U3fL5TLFx9VVKdwPZLq/Z6YKJaS+Q5fod6oOSZePxl9ID1R8LMJAlaqjZU9rtEqo3tbjJHtmSu0dWZ0aWiIioF0w3YJxIabhy1+iOjGymaGK8QfWVV1rc7YDGdL6E6ZEEALBHlvri6QsbKJo2bjsw0+9DCRQDWaIGmj2l3a5VRlZK6eyR1RSkNJU9skRERD3gZWQ1VcHVuyd2TC5uNg+jkpHtsrQ4na9mZNkjS/3w0Jk1AMCtDGSJhkOmaPnaIQtUM7KNAlnv46lKRpalxURERGHzphbrqsA1eyZweiW35RqcKVqYaNQjW8nIBldarFTW7/CBNvXOQ2fWcWB2FAsTqX4fSqAYyBI1kDUaX9y201QFqiJQahDIehdBb9gT98gSERGFzwsYNcXJyJZtiZNL1cnF2WY9spVhT51fs21bbikt1lhaTD0mpcTDZ9YGau2Oh4EsUR1SSieQ9Tm1GIA7jbj+U9vClkDWGfYkJS9iREREYfKmFmtuRhaoTi42yzYKZrnhtT4ZwLCnbMmCLVEd9sRAlnrs9EoO63kTxwasrBhgIEtUV8Eso2xL36XFAJBoslanUHIDWXePrC05ep+IKGjPX8rwISFtYbo9sroqcGB2DLoqKn2yOcMCgMbrd7z5F12UFm/kTQDA1AgDWeqPFxadSd3X7Z3q85EEj4EsUR3ZYvOLWz1JTWlYWuxlZFO66mtVDxERtefkchZv/PUv4R8ev9DvQ6EI8R4aa4qChKbg0Nw4XrjkBLIZ91rfethT59fr9XwJADAzurW0mA+zqVdOLjuB7KH5sT4fSfAYyBLVsdni4laPUzLsp0fWuTB284SXiIi2OrPi9D3+01cv9vlIKErMytRiJ4C8ek91crH/QLbz63XazchuLy22WTlAPXJyOYu9UymMtZGciQsGskR1ZI32A9lEsx7ZknMh9UqLAWZkiYiCdGGjCAD48vHlSskokVWZWuxce6/ZPY5z6wVkDQuZohNkNuqRTWndTy1OF7YGspqibDkuorCdXM7h8Px4vw8jFAxkierIVp7StjfsqWVpsaZWnvAykCUiCs6ljQIA5731iy8s9/loKCq8qcWVQHbPJADg+GKm8tC6cY+sN+yp8+v1hltaPOVOLXbjWPbIUk9IKXFqKTuQZcUAA1miuryntO32yDYc9uSVFieUmowsS4uJiIJycaOI3ZNJ7BpL4JNPX+r34VBEeHtkvd7Ua3ZXJxf3srTYG/bkZWTLLC2mHljOGMgYFjOyRMMk0+IpbT0JTYHRYCBEsd6wJ+6SJSIKzMV0EZfNjOLuaxfwuWeXGlbI0HDZXlp82cwIRnQVz1/KVq/1DQJZVRHQVdHVsKd0wcRYQkXCfYitctgT9dAJd9ATA1miiPvC80v4xX96JpDv5ZUWT7ZVWqzCKPsf9tTNE14iItrq0mYRe6dSeNMNe5AxLNx/cqXfh0QRsH3Yk6IIXL17HM8vblaqr5pd61Oa2tX1ej1fwrQ7sRioWb/T4H6BKEinlp0heIcXWFpMFGmffmYRf/qVs4F8L6/caCyp+v47SU1pOIl4+x5ZgD2yRERBkVLi4kYBe6dSuP3wHMYSKsuLCUDNHlmlest79e4JJyNbtKAponJdriepq121Am3kzcqgJ4AZWeqtk8tZjCZU7JlM9ftQQsFAlgZGvlSGYdmQAfSdZA0TI7oKTfX/Ekn4HPZUWb/DQJaIKBDpvImiaWPP1AhSuorXHV3Ap59Z5EAdqu6RdTOyAHDNngmsZA28uJrHREqDEKLRX0dKV7ouLa4NZDWu36Ee8iYWNzvH44yBLA2MnGFByupgh25kilZbq3eA5ntkC2YZSU2BoohqjyyHPRERBeKiu3pn35STdXjTDXuwki3hkbPr/TwsigBrW2kx4GRkAeCRs+sN+2M9Kb270uJ0voTpkZ2lxczIUi+cXMri8IBOLAYYyNIAyZWccuBiAAFixrBaXty2S+qNpxYXS+XK9MNKaTGHPRERBeLSprN6Z48byN51zQISmoJ/fYrlxcPOe7hdW1p8zR4nkL20WcREsvksDCcj20VpccHEVJ3S4jL3yFLICqUyzqcLODSgg54ABrI0QHKGc6EJIkDMFi1MtDGxGAASqtIwy1owyxipBLIsLSYiCtKFtJOR3Ts1AsCZOP/qI3P45NOXAmk3ofjy9sjWZmQXJpKVdTitqq+cYU+dXa+llEjnTczUBrJuiSfX71DYTq0M9sRigIEsDZC8l5ENYBpwpmhioo2JxYCTkW3cI2tjJOEEsCmWFhMRBerSRhGqIjA/kax87I037MH5dAFPX9js45FRv5nb1u8AgBCisk+2ZSCrqx1XemUNC5Ytt5QWK4qAIsD+bQrdyQGfWAwwkKUBUsnIBpDpzBpWWztkgWqPbL2n/0WztrSYGVkioiBd2Chg90SyUrYJAHdfuxuKAKcXDzlvj6ymbB1245UXt3po3c2wp3TeWe9TW1oMOOXF7JGlsJ1azkII4MAsA1miyPN6ZIPIdGaLHfTIur2vpTq74YpmGSNuJtZbis49skREwbi0Uaz0x3p2jSXwyoOz7JMdcl5psbotkL3aDWRbPbRO6mrD1XqtbBScQHZ6ZGcgy4wshe3kcg6Xz4xWEimDiIEsDYy8m5HtZky+p7OpxW4gWyfTWiiVK6XFqiKgq4IZWSKigFzaKGLv9MiOj7/x+t04vpTFyeVsH46KosAsS+iq2LF+xHdpsdb51GIvIzs9mtjycU1RGMhS6AZ9YjHAQJYGRMmyK5nQbjOyti2RLbU/7KkyjbheIFsz7Mn5WpVTi4mIAiClxIWNAvZOpnZ87p7r9wBgefEws8o2NGXn7e41uyegKQJz48k6f6sqpSsodvjgeT1fAoAte2QBsEeWQmfbEqdWsgM96AlgIEsDolCqBq/dZjrzZhlStu6b2S7RLCNrlpHcEsg2nnBMRET+bRRMFE17R2kxAOybHsHNl0/jk08v9uHIKAosW26ZWOyZGtXx8R+5E9/xisub/v1u9simvdLibYGspiqVkmeiMFzYKKBo2gO9egdgIEsDIuv2xwLouJfFkyk6F572e2QbD3EqlrZnZBvvnCUiIv8ubjird/bVKS0GnPLiJ15KYylT7OVhUUSYZXvLxOJa1+2bxGii1dRiZ49sJ2ucNtyM7FTdHtm2vx2Rb5WJxSwtJoq+vFETyHYZIGaLzvdqf2px47U6O0qLdZWBLBFRAC5uFACgbkYWqE7sXMuVenZMFB2W2yPbqZSmwpbVNT7tSOdNjCbUyoNuj6YIlJmRpRCdcucCHF5gRrYjQogpIcSbhRBFIcT3uh87JoR4QgiRFkJ8VAgx6n58TgjxL0KITSHEfUKIQ2EdFw2mXE1pcbfTgDfdQLbdYU/NSouLNXtkATcjy6nFRERd8zKyexsEst60WquDQITiz7Tr98j65U187WSXbLpg7phYDACK4PodCtfJ5SymRnTMjiVaf3GMhZmRfRzAJwDUdtH/BYBNAD8F4C0AfsL9+PsA3ALgRwEsAPijEI+LBlCgGVmjs0C2UWmxlBKFmj2yADOyRERBubRRhKoILEzUD2S9bBwDh+HUdUZW73xlXjpfwtTozkBCUwVsno8UopNLORyeH9sxrXvQhBnIvtX9HwDAzbIeAvA7Uso/AHAfgDe4n74bwN9LKT8C4E8AvEYI0d6kHRpq2dpAtstpwNXS4vZOwaR7sdv+872AdWePLDOyRETdupAuYmEiuWNPqEd1s3EWmxKHkmXb0Br0yPrhDWrs5N4ina+fkVUVZmQpXCeXB39iMRBiICulfBjAQzUf2uP+uuL+ughgb83naj+uApjf/j2FEO8SQjwshHh4eXk5+IOm2MoHWFrsDXtqu7TYvVCWylt/vjdReUSvvtySmhLIvttaL67m8X1//CByNUE9EdGgu7RZaNgfCwC6wozsMCtZElqDhxx+VEqLO8nIFkzMjNUJZIXg+h0KzWbRxFLGGPj+WKC3w562v4s0egU3fGVLKT8gpTwmpTw2P78jzqUhlisFX1rc9tTiBhnZgnvx29ojG3xp8QOnVvD555dxdjUf6PclIoqyixtF7JuqP7EYYI/ssLPsxlOL/UhpXmlxZxnZqZGdpcXMyFKYTrkTiw/NDfbEYqC3gewF99c599fdAC66v7+47eMWAKZcybe84QSLQgSRkXUC2bEWI/m3a9Qj6wWyW3tkgy8tXs4YAMDddEQ0NKSUuJguNs3IemWlfG8cTla5/h5Zvzod9iSlxEahtGOHLMAeWQrXyaXhmFgMAO3dqXdBSnlaCHESwLuFEJMA7gTwi+6nPwPgm4UQ9wP4XgBflFKavTo2ij8vizqZ0rvOdGaKFsaTWsN+q0YaTS32SotT23tkAy4tXsk6qyX4lJeIhsVmwULBLDecWAygUlbKjOxwMss29CCmFrf5kDxXKsMsywY9sgqv1RSaUytZaIrAFbtG+30ooev1Htm3AZiEM6X4rwH8ivvx9wB4FMBvA1gC8AM9Pi6KuXzJwoiuYjShdp3pzBpm2ztkgcZ7ZL2L39ZhT8GXFlcysrxZI6IhcXHT2SG7t0lpscapxUPNsrvNyHZWWpzOOw+X62VkVQH2yFJXSpbdMKt/cimHK2dHuyqpj4tQM7JSyrOo6Y2VUj4K4OY6X7cK4M1hHgsNtlypjLGkGsgQpaxhtT3oCagNZLf+fO94antkU2GWFnMyJxENiYtpZ4ds02FPLC0ealbZxlgHD6c9Ix1mZNN5p7Bwut76HUVhIEtd+Y4PPICZ0QT+8O3HoGyrIByWicVA7zOyRKHIGxbGkpqb6ey+R7bdQU9AtbS4UY9s2BnZlawTyJq8OBLRkLi44QSyzUqLvTYRBg7DySzLyuTqTnRaWrxRcAPZBut3eD5SN86u5vHZ55bwW587seXjVtnGmdXcUPTHAgxkaUBkjTJGE5qb6QymR7Zd3vodX8OeNAUly4aUwV3ImJElomFzaaMARQALE8mGX+P1R5psuxhKzh7ZzgNZbyNBsc17i2YZWWdqMa/V1LlcyUJCU/Drn30BX3yhOh/3pfUCzLJkRpYoTvIlC2MJFUlNDWSP7GRq5xPUVoQQzhCn7T2ypTrrd/T6QW+nimYZGXfgFW/WiGhYXNgoYmEiVZlMXI+qehlZBg7DyJla3P2wJ6Pd0uJCkx5ZZmSpC1bZRtG08f13HMTVCxP4//78MZxPO/MCvInFh+YHf/UOwECWBoTTI6u5a22675HtJCMLOOXFO6YWexlZrfpyq6zqCWhysZeNBVg+R0TD49JG89U7ACplpXzIN5xM2+6utFjrrkd2qk5psaYIlAOsyKLhknMTJHPjCfzed78cZlni3R99FCXLxslld/XOHDOyRLGRMyx32JPa/bCnDntkgfq9r5Ue2cTW0mJg54TjTi1nq4Esy5WIaFhc3Chg33TzQJY9ssOt24ysrgooorOpxSld2dJW5FEUwQ0D1LGcW4E3ntRwaH4c7/u2m/D4S2n8r088g1PLOcyNJzFVpxJgEPVsjyxRmPKGhdGEBiHKXQWHZVsiVyp3NLUYqL8ftrJHVqsXyAYTdK7UZGSZdSCiYSClxMWNIl579ULTr/OCGJPzA4aSWZbQu+iRFUIgpbfftpTOm5ip0x8LuBlZPlihDnmBrDeN+8037sU77jyID957GpMpDdfunezn4fUUM7I0EHKlMsYSKlKa2lW5brbmKVcnkpqC0rabpaJVRlJTtoxHT3o9N2FkZHmzRkRDYLNoIV8qt8zIaszIDjXLtrvep5nSVRTbvF5f3Chi11j9QFZlaTF1od696k9/3VEcu3IGm0VraCYWAwxkaUDkS1ZNj2znwaH35tBpRjahKTsGQhRL5S1lxUA1I9ttGbSntkeW63eIaBhc2mi9QxZAZWKtxffGoWSVJTSly0C2zR31hlXGw2fXcNuBXXU/z4wsdSNnOPeZtfuRdVXBb//7l+PIwjjuPDLXr0PrOZYWU+wZVhlmWWIsqaFo2l1lZDNFZzjDRAdTiwG3tLhOj+zIth6ZyhTEoEqLs0ZlCiIzskQ0DC5sOFM6m+2QBVAJYtiTOJzMst1VaTGAtkuLHzm7jqJp444GAQV7ZKkbXtJldFuSZM9UCp/5z6/txyH1DTOyFHt598nUaEJFUlfaLv+plS12W1qs1plabO8IZAMf9pQxsNvdo8invEQ0DLyM7N6pkaZfpyoCQnAQ3rCybNnVHlnAaQdqJyN734kVqIrA1xxqnJG1WVpMHcqXurtXHSQMZCn2cu4LeiyhIakpMMuy42AuU+yutLheaXOhVK70xFa+LuBhT8sZo1Jex2FPRDQMLqYLUAQw7z7Ea0ZTBEuLh5BtO/cDXZcWt9m2dO/xFdxy+XTD6i5VUXg+Use2D3saZgxkKfbypWqvgFeyuz0r6lem2x5ZdWdpcdEsY0Tf+lKr7pENJiO7ki1h77STlWBpMRENg4sbRcxPJH0N8tEUhe+NQ8h0s/BdlxZr/kuLN/Imvnp+o2FZMQCoCqunqHNZtxKRGVkGsjQAKr0CSbVmiFJnAWK1tLjDHlldqVNaXGfYkx58RnbvpJuR5cWRiIbApc1iy7JiDzOyw8nrQ+1mjyzgZGT9lhbff3IFUgKvvqpxIMsHK9SNnGFBEc55Oez4L0Cx5/XIOqXF3Q1Rqg576rxHdsewp9LOYU+V0uIAphbnDAsFs4z5iSRURfDiSERD4UK60HLQk0dTOVxnGFUCWaV3w56+fGIF40kNN18+3fBrVEWAz1WoU1nD2dQhRHfn9SBgIEux5/XIjibUytOpjjOyhgUhdk6C88spLd62fscqV0qePdWAu/vSYm/1ztx4kiP9iWgoSClxcaPYcvWOhz2Jw6laWty7PbL3nVjB1xza1fRnqorg8DHqWM6wWFbsYiBLsVc7va37jKzz5tDpU656pcXFehnZAEuLl7NOIOv1inHYExENuoxhIV8qY5/P0mJdZbXKMKqWFnebkfVXWvzSWh5nV/NN+2MBVNblEXUiV7I46MnFQJZiz2t6H01WM7KdZjozRQuTHe6QBZrskd2W4U11GXDXWslUA1lN5VNeIhp8F9PO6h3/GVkGDsPIdB9e6F1OLU76HPZ074kVAM37YwGweoq6kjXKGOuwcnDQMJCl2Msbtet3nBd2O/veamUNs6tyjUSjQHZbRlZXnb2GQUwt9jKyTmkxM7JENPgubhQAwHePrK4qHIQ3hLxy8u4zsqqvmRb3Hl/BnskUDs+PN/06r0fW5jlJHcgbzMh6GMhS7OXc9TsjulpTstt5j+x4h4OeAOepbdmWlRI225YomvaOPbJCiLrZ206sZAwoAtg1lmD5HBENhUsbTkbWWzvWipOR5XvjsPGuh0FMLS6V7aZZVNuWuO/kCu44MteyPUl1P1+WDGSpfVkGshUMZCn28oaFsYQKRRHVkt0OM7KZotXxxGKgOo245F48vUB1e0bW+Vr/UxCbWc4amB13JharXDFBREPgwkYRQgALE0lfX68pgtUqQ8j7b64HMLUYaP6Q/OkLm0jnzZZlxQCguhlilhdTJ3IlDnvyMJCl2MuVLIy6L2gvI+t3uuB22WJ3bw6JbWt1CqaXLd75UgsqI7ucMTA37tzM6SoncxLR4Lu0UcD8eNL3NFpNZU/iMPJmRnSdka3sqG98zfb6Y28/Mtvy+3nrgHhOUidyRhljSfbIAgxkaQDkapreu83IbhYtTHQ17Mn5+V5G1su4bh/2BDhBdzBTi0uYd7MSGvfIEtEQuLhR9F1WDMCdH8D3xmFjBja12Ju/0fgh+b0nlnF0zwQWJlr3bStuaTEfPFMnWFpcxUCWYi9fsjCaCCgja5iBlBZvz8hu3yPrfK0ayB7ZlYyBufEEAOepM8vniGjQXdwoYu+kv0FPAKfEDivvwW4igD2yQONAtmiW8dCZddzZYu2OhxlZ6pRZtlGybIwnGMgCDGRpAOSMcqUceHsg2Q6zbKNo2sGUFrsBaqFmENV2SU3pOHPskVJiOWNUMrI61+9QRPz4nz+G3/rs8X4fBg0gKSUubRR9r94BnIycxYd8Q6cytbjrHtnmpcUPnVlDybJxh4/+WABQ3cCagSy1K+dt6mBGFgDAfwWKvVzJwq4xJyNZHcjQfjCXLTpvDoFkZK3WpcUpXe26tHizaKFUtjE/XltazAsj9d8XX1iuPMghCtK/PHUJWcPCDfunfP8dTVGQt6wQj4qiyAxoarG3eaBRtde9x1egqwKvPLjL1/djRpY6la0EsuyRBZiRpQGQMyyMuSUWXvlQJ9OAvTeHbjKyyW2BdPPSYqXr0uLljLNDttojyz4w6r+cYSGdN9n/RYHLGRZ+4R+fwXV7J/HNL9vn++9pKie6DyPvwa7ebY+s1ry0+N4TK3j5FTOVNqdW1EqPLK/X1J68+4CYGVkHA1mKvXypOr1NUQQSamdDlDIBZGS9QNp3aXGXGdmVrBvIehlZTuakCLi4UQAAPlShwP3m547j0mYR//Obb2gry8ZqleFUycgq3e+RBeq3La1mDTx9YdPX2h2P6mZkGcdSu7IsLd6CgSzFXs6wtjwFTepKRxnZTNEEgO6mFrsXu5KvjKzadY+sl5Gd8zKyqgKTgSz12fl0EQAYOFCgji9m8MEvn8bbjl2GW6+caevvaorC7NcQ8q6HXWdkmwx7uv/kKgDgDp+DnoDqFGWek9SuXADVg4OEgSzFmpQSudLWfVrONOAOemSDKC1uo0c2qSsdT1f2VEqLvT2yXL9DEXAx7WRkeZNGQZFS4uf+4WmMJTX81JuOtv33VQ57GkpWQD2yqSY9svedWMFESsNNl037/n7e+h1WUFG7KsOeOLUYAANZijnDslG25ZaMbErvrPe0EsgGOuzJ+TWsqcUrWQO6KjA14mSROZmTouBC2ist5rlIwfj4ExfwwKlV/OQbr8Gs++CuHbrCHtlh5F0Pw5xafN/JFbzq0GylXNgP73h4TlK7soZzf8uMrIOBLMWa1/Re+4LuNEDcDGRqsROwbi8trh/Idr9HdjljYHYsCcW9KDqlxcyCUX9VSot5LlIAMkUT/+sTz+Kmy6bwna+4oqPvoSoKq1WGkHc91LvNyLrX9u2T2F9ay+OltQJuPzzb1vdTObWYOpTj1OItGM5TrHkv6NHE9tLiDjKyXiCb7KJHtsEeWe/j27+222FPy9nqDlmAA00oGrxhTzwXKQi//pnjWM4a+MO3H2sr61VL59TioVTJyAbVI7vt3uL+kysA2uuPBRjIUuc47GkrZmQp1nKlnS9op7S4k6nFJjRFVEqIOpHQtk42LJplpHSlkjGtlezwOGut7AhkFV4Yqe+qpcXMgFF3nru0iQ/ffwbfcdsVuPny6Y6/j8rS4qHkvQfpXU4t9h5Gby8tvu/EKuYnkjiyMN7W91NZWkwdyhkWVEXUTZAMI/4rUKzl3F6B7RnZTvfIjqc0CNH5k9tKaXG5Wlpcb2Ix4JQqlW3ZVbnbcsbA3Hii8mddFQweqK9sW+LChldazJs06s7//ufnMJnS8J43XtPV99FVlhYPI+89qNuMrKIIJDQFRs29hZQS959cxe2HZ9u+b/DWAdmS75HUnpxhYSyhdnWvOkgYyFKs5Us7Jw13mpHNFq2um+e3Z2QLpXLd/liguqqn06ysbUusZktbM7Isn6M+W82VKj3iZpcVB0RPn9/Am27Yg5mxROsvboIZ2eFUnVrc/U1/Stu62u/4UhYrWQN3HG6vrBioyciy/YLalCuVOeipBgNZirVqRrZ22FNnGdnNotXVDlnAuThpiqj2yJpNAlk3e9tpIJsumLBsibnxraXFzMhSP3n9sbNjCe40ph3+8YkL+N4PPejra21bYj1fwuxY+1OKt+NDvuHkTU7vtrQYcPpka0uL7zvh9MfefqS9QU8Ae2SpcznDYn9sDQayFGv1prd12nuaNUxMBPDmkNSUSkaq2KS0uNpz09nk4soOWQ57ogjx+mOvmB1lKSft8OiL6/jiC8u+3vfSBRO2BGbHu8vGAt57I8/HYWPZNhSBunMq2pXS1S3Dnu47sYordo3ispnRtr9XtUeW5yS1J8tAdgsGshRrXmnxlj2ymtrR+h2vR7ZbSV3dskd2JBFOafFK1g1kazOyKoc9UX95q3cOzI7xoQrt4GW01nKlll+7lnPe43Z1WVYMONUqtnSyvDQ8rLLsevWOJ6VXS4utso2vnFrFHR1kY4HqHln2yFK7ckb3bXCDhIEsRZo3ZryRXL09srqyY0S+H5mi1dUOWU9CVdosLe4uIztXk5HVVcE9stRXF9MFpHQF8xNJnou0gxcIrGZbB7Le1wRSWswpsUPJDDSQrZYWP3VhExnDwu0d9McC7JGlzuWMMnfI1mAgS5H1wmIGN/38J/H0hY2GX5M3LAiBLStzUnqHGdkAhj0BTiDtlRYXSq1Lizs5VqBRabECKdl3Q/1zYaOAfdMjLHOnurzd2qtutrUZL2sbSEbWDWb43jhcLNsOZNAT4FR7eQ9ivP7YVx3uLCPLHlnqVNawMJZgRtbDQJYi68RSFrYEji9mG35N1ihjLLF1ZU5SczKyss2SnUxQpcWaUlNaXG64l7bbYU8rWQNJTdnS1+tdsDnwifrlfLqI/dMj0FQFli3bfh3SYCu0k5F1A9mgemQBsEpgyJhlWVl10y2n2ss5fx44uYqjeya2DFtsh3c+lvn+SG3KldgjW4uBLEWWl3FcyhQbfk2+ZG3ZIQs4gaSU1WmFfhhWGSXLxmSXU4sBZwWPF5w2Ky1OVXpkOy8tnhtPbgnidZXlc9RfF9IF7J1KQWcpJ9VRKS1uIyM7MxpERtYNHFglMFSssl25LnbLqfYqo2iW8dCZtY7LioHq8ClmZKldnFq8FQNZiiwvgF3abHzDU2+fllfK206AmC3u3EfbqaSmVkuLzXLjYU9eRrbT0uKssaWsGABU98kzp3NSPxhWGcsZwyktVr1zkTdqVFUNZP0MeyphIqVV9nN3gxnZ4WSWAywt1p3S4kdfXIdh2bi9w7JioKZnm++P1IaSZcMsS4yzR7aCgSxFVjUj2ziQzRsWRpM7M7IAtux7ayUTaCBbM+yp1GTYU5dTi72MbC1mZKmfFjec1+q+6ZHKucjAgWq1W1o8G0B/LMAe2WFl2jKQHbIAkNIUFE0bD5xchaoIvPLQro6/l8rSYupAdeUkM7IeBrIUWV4gu9wkkM0a1pbVO0Bn04C96ciBTC1298jatoRh2a2HPXVYWrxSJyOrKcyCUf+cd3fI7neHPQE8F2kr7wHjarZ1afFq1ghk0BPADNiwsoLOyFpl3HdiBTddNoWJLlqRvGs1H6xQO7IMZHdgIEuRtZz10yO7s7TYy3R2lJENcNiTl2ltVVrcznF6yrbEWq60M5DlsCfqo4sbTiC7dypVU1rMc5GqvIysvz2yJewKYPUOUH1vZLXKcLECHPaU0hVkixaeOLeBO7rojwUA75B4PlI7cqXgqgcHBQNZiiyvN7ZZaXGu7rCn9jOymaIJAAENe1JhWHblhq3xHtnOM7KrOQO2BOa3TfNkaTH10wU3I7u1tJjnIlUV3fU7Kz5Li+cCmFgM1Far8MHKMDFtGeiwJ8uWKNuyq/5YoCYjy/OR2sDS4p0YyFIklW2J1VwJCVVBpmhVBoRsl3fX79RKddB76pVrBNUjW6oJZBuu3+miR7beDlmAN2vUX+fTRcyOJZDSVZ6LVFfB59RiKSXWc6XgS4v5YGWoOKXFQWVknYfSSU3By6+c6ep7VXtkuz4sGiJZw3n/HGtQ6TeMGMhSJK3nSyjbElfvGQfQeHJxru6wJ69kt/0e2eBKi8solLxAtv4bTsK9uHYytdjLZmwf9lSZzMmrI/XBhXQBe6dTAGrL3HkuksMs27BsifGkhqJpI++WydWzWbBg2TK4QJZTtIeSU1ocTEbWq6I6dmCm4XXdr0ogy2F41AZmZHdiIEuR5GUcr987BaB+n6yUErmS1bBHtp1Mp9cjG9SwJ8O0K4F0o9JiTVWgKaKj0uKGGVlO5qQ+urhRwL6pEQCA7p6L7Ncmj/eeuH/aOUeaTS72MrazgZUWexlZno/DxLTtyntRt7zgtZv9sR5WCFAngqweHBQMZCmSvEDtun2TW/5cy7Bs2BI7phanOtjPmilaSKhKJZvbjaSmwijX9Mg2KQFJ6WpHpcUr7iCsHRlZrjyhPpFS4vx6AfvcIIVTYmk77z1x/4xzjqw0mVzsDYPisCfqhlWWgU0t9h5033Gk+0DWy8jaPB+pDXlmZHdgIEuR5A14ut4NZOsNfKqWWGwrLdbbH6KUNcxAyoqBao9svtQ8I+t9bacZ2dGEuuPNTOf6HeqTzaKFXKmMfW5pse6W4fGhCnmKJedcuGzGT0bW+VxQe2RVPlgZSmbZDmxq8T3X7cEfvf0Ybr5squvvpQo+WKH25dz7yu33vcOMIT1FkpeBvWbPBFRF1C0tzrlN7zsysnpnGdkgyooBp7QYADYL5pbjqSfpliG3azmzc4csUJN1YDkn9Zi3esfLyPKhCm1XdB/aeYFssxU81YxsMIGsV17K0uLhYgU4tXgkoeLu63YH8r0URUAItgFRe7KGBV0VgVQPDgpmZCmSljMGxhIqJlI65sYTdYc9VfdpbR/25O6RbScjW9zZa9sp7+dvuIFss9LipK6i2GFp8fx4nUBW4coT6o/a1TsAH6rQTt4AvP3TowCAlSaTi4MOZFX2JA4lqxxcj2zQNEXwfKS25AyLZcXbRPPVTUNvOVvNOC5MpOqWFnsTL7dnZCv7WdvMyAYWyLoZ2Eog2zIj21lp8fb+WKB22BODB+qt82mnasIb5MM9srSd1yM7M6pjNKE2Ly3OljCWULueDuthhcBwMgPskQ2aqgj2yFJbsoa1Y+XksGMgS5G0nClWAtn5iWTdYU9eafH2XoFKaXEbGdmMYWEipXd6uFsk3WAynS9tOZ66X6spne2RzTYoLeb6HeqTi+kCNEVUHrBwjyxt500tTiVUzI4nmpYWr+YM7ApoYjHAdSfDyrLtykOMqFEFM7LUHicjy7LiWj1/dQsh/osQYkkIsS6E+C3hOCaEeEIIkRZCfFQIMdrr46JoWcrUZmSTTYc9bc/IaoqAIoBiGxnZrGEG1iPrDZvyl5FV2x72VLJspPNm3Yyszl2J1CcX0gXsmUpVAgbukaXtKoGspmLXWLLl1OKgJhYDNRUCPB+HSpBTi4OmKoI9stSWnFFmafE2PQ1khRBHAPwygL8C8H8A/AiANwL4CwCbAH4KwFsA/EQvj4uiZzljYGHCmX66MJHEas7YkdnxprdtLwkWQrhrbdrIyAY47MkrbU7nzS1/rvu1evsZWW+/YtNhT8w6UI9dSBcr/bEAh+vQTrUryebGEi1Li+cC6o8FajOyDByGiRnlHllV4flIbckawbXBDYpev7q9yOIBAA+6v98EcAjA70gp/wDAfQDe0OPjoggpmmVkila1tHgyBSmr6xg81R7ZnRnPpKb4zshKKQMd9pSoGfaU0hUoSuOnwUlNbXtqsTdUZ89UnYysW0LFrAP12vl0AfumUpU/c48sbVdw1++M6K1Li52MbHCBrBfMmCx1HypmWVbei6JGYWkxtSlfYo/sdr7+NYQQpwBsf7W9BOA/Sykf9fvDpJSnhRAfB/D/3A99FYDXmLji/roI4Jjf70mDx+uH9abyLrgB7dKmgd2T1Rvlao/sztO4nZJdw7Jh2TLAPbLVYU/NyooBLyPbXmnxyeUcAODQ3PiOz6mcFEt9ULYlFjfrZ2QZOJDHKy12Almn0kZKCSG2BhpSSieQDaVHloHDMLFsuzIEMWo0RbBnm9rC0uKd/L66HwGwB8DjAEYA5AHMAfiddn6YEOLrAHwTgP8G4N0AbgJw17Yva3iVEUK8SwjxsBDi4eXl5XZ+NMXIcnZr6az363J26y7ZnGFBEfVLd1NtlOxuFp0S4MCGPdVkZFsGsh0Mezq1nIOuisouxlo6V0xQHyxnDFi23BLIVsvceS6SwystTuoKZscSMMsSm0Vrx9dlDQulso3ZADOyGqdoDx0pJcxycHtkg+b0yPb7KChOnNJiDnuq5TeQPQrgv0gp3wLgdQCOAPg5ADe3+fNudH/9FSnl7wLIAPga92Nz7q+7AVys95ellB+QUh6TUh6bn59v80dTXHg7Y2uHPdV+3JMrOfu0tj/NB5ysaNHnWpuseyM1EXBpcTpvItVkhyzgZY7bu5KdXM7iwOxY3afMmspJsdR7591y9/21gSynFtM2RbMM4T58nHWzrfXKi6s7ZIMb9uSdj2Wej0PDy75rEZ1arKnMyJJ/Ukruka3D77/GfgBH3WnCdwBIwAlKG48crO9J99dfEEJsApgA8OcArgLwbiHEJIA7Afxim9+XBoiXkV3YlpHdPrk4b5Qb9gq0M0Qp4wayge2RdUuLC2YZKa11RtZvwO05tZzFkYWdZcUAs2DUHxc3nEB273S19J9TYmm7olnGiK5CCIFZN0hdzRo4ODe25eu8eQhhZGT53jg8vP/WkZ1azB5ZaoPXBsdAdiu/j6n+EMCPwcmg/iGAzwMYBfB37fwwKeW/APh5AN/jfr9fBvCnAN4GYBLA+wD8NYBfaef70mBZzhgQApVBH0lNxfSojqXMttLikoXRBiUWqXYysu4an6CnFgPOdM6mX9vm1GKrbOPFtTwOzdcPZDnsifrBG0C2tbSYU4tpq4JZruzV9t7fV+pMLl7LlrZ8TRA0tl0MHa8/P9qlxTwfyR9v5eRYi/vKYePrzl1K+VNCiM/CKSU+DSeAPQBn4FNbpJTvBfDebR9+FO2XKdOAWs4YmB1LbCmdXZhI7iwtNhpPb0vqSiVAbaWSkQ0okE3UBrIte2RVlCy77sCTel5aL8AsSxzalsHwaBz2RH1wIV3ERFLDZE2fuRc48KEKeQolu/Ke6O3B9taJ1aqWFgcZyLLUfdh4E9OjWlrMQJba0WzA6TDz/a8hpfwUgE95fxZCLAJ4Vgjx1nYmFxO1spwxKjc5nvmJZKXk2JMrlTHWICOb1NSmOwprZbxhT8lghz0BqGQfWn2tYdktvxZwyooBNMzIVoIHXhyph86nC1vKigFOLaadimYZKd05L7wgda3O+/SKG9zOBji1mBnZ4WPazMjS4PCSM9wju1U3j6kUAAcBBDeNgQjAcqZY6Yv1LEykdmRkm+3TSuoKij7X2gReWlwTkLYqLfaCV7/lxSfdQPbwfP2MrBDCvTgyeKDeubhR2FJWDDg3aYrgHlmqKprlyntiQlMwkdJ27AcHnOA2pSsYDXBfosLzcehUMrIRXr/DByvkV67klhYzkN0imq9uGmrLGQMLE1uzOwsTSSxnnJ2DnpxRxmiDF3RSU2CY/oK5bNClxWptaXHzl1g1I+sv6D61nMPsWALTo40zFZoieLNGPXUhXdwRyALODaTJhyrk2j4Ab248iZVs/dLi2QAnFns0RWHgMESqpcXRzcjakucj+VPpkWUgu0W3gSxfgRQoKSWWs8aOjOz8RBKlso2Ngln5WK7JPq2U7n+tTcawkNKVSilkt3RVwGt39bNHFoDvoPvUcg6HGmRjqz9fYV8i9UyhVMZaroR9U6kdn9P5UIVqFGoysoAzlbje+p3VXCnQsmKPpgr2yA6RamlxNHM2Kt8fqQ1ejyxLi7fq9tUdzcdcFFsbBRNmWe4sLZ50bpJrV/DkS+WGpWdORtZfljNTtDAeUH8s4JT3egFqyx7ZNkuLT61kcWiufn+sR1MFJ8VSz3irdxplZBk4kKdobp0FsGssUXeWwVquFOigJ4/KUs6h4gWJUQ5k2SNLflUzspxaXMvXq1sIcbkQIlnz5ySAKTiTix8J59BoGHmB6o6MrDv8yeuTlVIiV7IajiFvJyObNazA+mM9Xnmx32FPflYFbeRNrGRLLTOymiKYkaWeuZB21mLVC2R1VXDwGFUUa9bvAMDseLLh1OIwAlldVfiQb4h4g+aiukfWKXXn+Uj+ZCvrd5iRrdX0X0MIcTmcYPULAH5aCPFv7qdeD+C/Syn5r0mBWnYD2YUdGVnnz8tZ56a5YJYhJZr2yJbKNsq2hNqiPyZTNAMPZJO6ChSt1ntka6YWt3JyxRv01CIjqzALRr3j7ZDdXy8jy3ORahRK5S1zA+bGndJi25ZQat6nV3POCragsZRzuHjZ90hPLebpSD6xR7a+Vv8a3wfg5+H0wv6fmo8LACdCOiYaYssNMrJeYOtlZFvt00q6A0VKlt0ymMwWrcB7DrwA1c8eWcDfsKdTyzkAaJ2RVVmuRL1zPl2AEMDuyZ09sk5PIs9FchTM8pb3xF1jCdgSSBfMSgY2X7JQNG3sCmHYk87S4qHiPUSL9h5ZPugjf7IlCwlVQUKL5vncL63u3j8M4IsAPg/gZwA8UPO5Z0M6JhpijQLZ8aSGEV2tlB7nvTHkDUuLq9OAWwWymaKFK2dHuzru7RJ+A1ndf0b21HIWmiJw+a7mx6qrCss5qWcubhQwP56se3HluUi1imYZqcTW0mIAWM0alUDW65kNJSPLYU9Dxays34luRpYP+sivnGGxP7aOpoGslPJFAC+Ca3qoR5azBpKagoltGVIhBBYmk5VA1svINh725LzYiz6mATs9ssENe6r9+Sm/pcU+jvPUcg5XzI62HFzhrN/hzRr1xsWNIvbWmVgM8FykKtuWMCx76/odL3jNlXCV+zFvinEoPbJcvzNUvB7ZqA570rh+h9qQM8osK67D77Cn7xFCLAohyjX/s8I+OBo+S5tFzE8kIcTOJ6jz40ksbTo9stXF0K0zsq2E0iPrMyOb0tsoLV7JtuyPBdzdnXzKSz3iBLI7+2MBnotUVXTf42orZHaNb83CAjWBbAjrd5gBGy7eIKWo7pFVWOpObXBWTjKQ3c7vv8ivATgD4PcA8PE6hWY5a+wY9ORZmEziuUsZAK2b3v1mZKWUyIbw5uC7tNjnsKeyLXFmJY/XHV1o+bM1het3qDeklLiYLuDVV83V/bzOVVDkKpTcQLZ2arHbB1s7uXgla7ifC2OPLDOyw8SM+Podjet3qA25ksWMbB1+/0U2AfyKlPJjYR4M0XLGwMG5+sOMFiZS+PILKwCcHbJA4zHk1QCxeaYzXyrDlggtI5vSm19Aq8Oemt/sn1vPo1S2cbjFDlmAw56odzKGhVyp3KK0mOciAUX3Pa72PXFmVIcQwEqdjKzXPxskPuQbLlYMemR5rSa/skYZUyPBtsENglbrd/67+9tnAfySEOJ6AN6jUyml/MUwD46Gz3LGwCsO7qr7ufmJJDKGhUKpXMnIjjbZIwu0DhC9vVzjgQey6pbjaPh1Xgl0iz2yficWA04fmMm+ROqBSxtOqf+epqXFPBepmpGtfU/UVAXTIzrWajKya7kSEprScJBfN/iQb7hUS4uZkaX4yxkW9jV4aDzMWt29v3fbn/9rze8lAAayFJiSZWM9b2J+vP4LtbKCJ1NsXVrsBojFFgFipmgCQAjDntzS4oD2yJ5cdnbIHvLVIytQ8jEFmahb3g7ZRhdXXRWVAIaGm/devL3dYnY8uaVHdjVXwuxYou6chG5piuCDlSFSLS2ObkaWpe7klzO1mKXF27WaWhzNx1g0kLzeqIXJ+iVl85VA1kDOKy1uMOzJ7zTgTNEJiLdPSe6W32FPCdVnRnYlh5lR3dckT01VKv8+RGGqZmQbBbIKMjbnAlJNILvt4d7sWGLHsKcwJhYDTmaOpcXDo7JHNqI9siwtpnaEMc9lEPj6FxFCfE+dD78opfxiwMdDQ6yyQ7ZBb9TCRKrydfmSBU0RlUBwu76XFuv+AlkhBJKa0vI4Ty1nfWVjAUDnyhPqkYsbRQhRfW1upymcWkyOgrmztBgA5saTeO7SZuXPq2EGsqpAweT5OCy8HdZ6RKcWa4rCQJZ8kVJyj2wDfu/ePwKnlFi4vwIAhBC/LKX8qTAOjIZPJZBtMrUYcFb05IwyRhNqw/IzLyPaurTYzcgGHMh6AXar0mIAvgLZk8s53HX1vK+fzRUT1CuXNoqYG09WpnRvp6t8qEKOelOLAWdf7GquNiNr4ODsaCjHwJ7E4RL1jKwieD6SP0XThi0bt9MNM7+v7vcD+FcANwP4JQCPAfhZAG8P6bhoCC1nmweyu0YT0BThlBa36BXwnZF1A9mgyzWS7s9PNrjBr5XS1abTlTNFE8sZw39GVmX5HPXGhY1C0+ETXHdCnkYZ2dnxBNJ5s9K7upYtYddY8BOLAUDlILyhEvWpxRrXk5FPuVI496qDwO+/yA8D+EEp5ZNCiDUAPwPgAwDqj5cl6oCXkZ1rUFqsKAJz40ksZQwUSuWmgazfjOymN+wpGeywp7uunkehVPY1sCSpK017eduZWAx4F0cGDxS+SxvFpuelzuE65PLe43b0yLrv9+v5EiZTOnKlMmbHwykt1jm1eKiYbpDYqAWp31RFgHEs+VEZcNpg5eQw8/svcgLO+p1bANwNoADgGgAnwzowGj5LmSJmRvWGZYqAk61dyhhQBJquZ/C7nzWsHtnbj8zh9iNzvr42qalNj/PUijOx+LDPjKymKCwtpp64tFHEHU3Oc01lmTs5KhnZbe/vs24/7Gq2VDlXwuqR5ZTY4VLJyEa0R1YVzMiSP9kWmzqGmd/HVG8HcBHAuwEkALwNwAsAfiyk46IhtJwxGpYVexYmks6wJ6OM0SZPpqprbZpnZLNFC6MJFWofL3ROj2zj4zy1nIOqCFyxy1/fmK4yC0bhyxRNZAwLe1uWFvNcpGogW29qMeAEst704rACWbZdDBevR7af1/dmVEXAloDNhyvUQs5ovqljmPkK7aWUTwF4VcjHQkPOVyA7mcQT59IQSGHfdOMbaMWdaFz0sX6n3z0HSa35cZ5czuKKXaNNM9W1mHWgXmi1egfwSot5LlK1zSOl1S8tXs0ZlSBzNsyMLM/HoWHaEroqQtlJHAQvU1yWEgqieYwUDTlmZBtq+i8ihHg1gCcB3Fjv81LKL4dxUDSclrMGbr1ipunXzE+ksJorIaWruCrZvNQ2qTfPdAJOuUbQE4vb5ZQWN8/IHprz1x8LOFkHZmQpbBfdQHbv1EjDr9FUhVOLCYCTkU1oCpRt2bHajKzXvzrbYE5Ct3TOD4iEv37kHO66Zr7hPIygWGUbmhLN/lgAUN0hVGVbosWmPhpylTY4BrI7tHqFfxFOJvaLAL5Q51eiQEgpsbRpYGGycXYHcEqLpQQupAtNS4sBJ0BsmZE1LIyngh301C4n4K5/nLYtcXol53vQE8AVE9QblyqBbLPSYlHZ5UjDrVgq192rPTWiQ1UEVnMG1nLhlhY78wP4YKWfzq3n8RN/9QT+8YkLof8ssywjO7EYcHpkAfB6TS0xI9tYq3+Ru+BkZO8K/UhoqGUMC4ZlY77FE1qv9NiWzYc9Aa17TwGnz28iAqXFjaYWn08XYFi270FPgJcF44WRwnVhowAA2N3k4ZPOwIFcBbN+IKsowtklmy3Blk7WdDKkKhm2XfTfSXcKf77U/NocBMu2oUd0YjFQ7d3lOUmtVDKynFq8Q9N/ESnll9zffgkAhBDjAAwppRn2gdFw8Vbv+Bn25Gn1ZCrVJNPpyRYt7GmRBQ5bsz2yp1a81Tv+A1ldFZW1A0RhubRRxNx4smnvtqZWh5lsLyml4VI07R2DnjyzYwms5kqQEpgZTYTW06hzinbfnV52pvAbLVbjBcG0ZGQnFgPVHlkOe6JWvAc/HPa0k69HVUKIlwkhngSQBnBMCPGUu4qHKBC+A9maoLPVCzqpqS0vllkjGsOeGgXcJ5eci357pcUKpGS5EoXr4kaxaVkxgEo2hA9WqGCWK9Pkt5sdT2A1a2A1VwqtrBgAVEXh+2KfnXYfzhZ6EcgyI0sDImdYSGoKtAifz/3i91/kQwDOA5WxaksA/jiUI6Kh5DeQrS09btUj6ycjmylamOh3j2yTPbKnVrKYTGltTfH0eoI48InCdGmj2HRiMVDNODALRkWz3CQjm8RqroS1nIHZ8fACWVar9J9XZdRqfkUQrKj3yLqDqPhwhVrJGhb7YxvwG8geBfDXNX/+MIBDgR8NDa0lN5BdaBHIJjQFM6NO4OknI1ts8tTXtqWTke371GKlYeb41HIOh+bH2yq1q4z058WRQnRho4B9rQJZLyPLhypDr9igRxZwhjutZUtYy5Wwayy8SbaqIiC5t7OvTi17gWxvemTjUFpcljwfqbmcYbGsuAG/gezDAH7c/f27APwSgHtDOSIaSssZA7oqMDXSOjvqZW3HWk0tbpGRzZac5vm+D3tqcpynlnNtDXoCqsEDs2AUlqxhIVO0sKfJ6h0ASFSqA3guDruCWUaqQSA7N55AxrBwabMY2g5ZgKXu/VY0y5UhcT0pLS7LWJQWl/n+SC1kjXLLe95h5fcV/t0ATgPIA3gznCD2nWEdFA2f5YyB+fGkr8zjwoSTBWo57ElTG04DBpxBTwAisUfWsuWO6a5LmSIubRZx9e72AlndCx54s0Yh8bN6B6h5qMJzcegVGqzfAap7Y4umHXKPLKtV+unMag5e8rE3pcV2xEuLvR5Zvj9Sc7kIzHOJKr//Kmkp5TeFeiQ01JazRsv+WI9Xfjzaav2OrqDYZP1OZZx53wNZ52bfsOwtjfxffH4ZAPDqq+bb+n7eAnhmZCksvgNZ9siSq2jaDTOytcFrmIGsdz6yQqA/vLLikSaT+oNk2bJyPYwiPlghv3IlCzOj4b03xpnfV/iaEOLfhBC/KIS4SwjBf00K1HLGfyA7P+mWFrd4OtVsPyvg7JAF0PenXLWBbK0vPL+M3ZNJXLt3oq3vx2FPFDavPHBvi9JinT2y5HKGPdW/5ZirGfA0F+KwJ84P6C9vYvE1eyZQ6MEeWbNsVyqUoog9suRXFDZsRJXfQPZHAXwVwJsA/AuAtBDiU6EdFQ2d5UwR8xP+9rn6Li1u8dQ3Uykt7vPUYjdLUXusVtnGl48v466rF9reqahxpD+FzMvILkw2f/jkPVThuUgFs4yU1nhqsSfMYU/V+QF8sNIPJ5ez2DOZwuxYomm1VFCscrQzsgorVsgnDntqzG94/3cATgI4AeA2AN8A4FVhHRQNl5xhYTVX8p2R/aab98G2ZcuJqUlNadqH45UW97tHNqW7GdmaY33spTQ2ixbuuqa9smKgerNWZt8NheTihjOUp1GpqMe7iWRGdrhJKVFotn5nvLelxXyw0h+nV3I4ODeGlK72pEfWtCVGk9ENZFkhQH7ljTLX7zTg9xV+AcBfATgCJ6h9OYCpsA6KhkM6X8JvfOY47vy/n4OUwM2X+Tul5ieS+IHXHGqZqfQysrJB2Y6Xke13uUZS8zKy1Qv7559bgqYI3HHVXNvfT2cfGIXs0kYBe6dbV1B4ZX3MOAw3w7IhJRo++BhPaki4D+DCnFrMie79I6V018mNIakrPSkttsp25XoYRSpLi8kHKSVyJYtTixvw+6/yGwBuAPCNAF4L4FH3f+8P6bhogF3aKOKD957Cn33lReRKZbzh6AJ++K7DOHZgV6A/J6kpsKUT0CW0nRez6Ewt9npkqxf2Lzy/jJdfOYPJDsqeebNGYbu4UcRlM6Mtv45TiwmoVps0CmSFEJgdT2ApY/hawdYpjVNi+2Y9b2KjYOLg3BhOr+R6M+ypLGMxtZgZWWqmYJZhy9btdMPK17+KlPI/CSGOADgG4OsAvAXA28BAltr02587jt/87AmUpcQ33rQXP3TXYRzdMxnKz6pmOstIaDuLDzJFE0K03kcbtu0Z2aXNIp65uImfetPRjr6fxvU7FLKLG0Xc5uPBE6sDCKjuDG20fgdwyovNsl3pGwwDe7b759RyFgBweH4cFzeKPSot3roJIGpU9siSD5UNG+yRrcvXHbwQYgPAOAALwEMAfhXA50I8LhpQv/uFk3j5ldN4/7fdjMt3tc7odKPSe2rZqDf3N2NYGE9ood44+ZF0j7Po3ux94QVn7U4n/bEAoHP9DoUoX7KwUTB9lRazOoCAmkC2wdRiwBniF/Z5wnVQ/XPKnVh8cG4MD59dq1zvwmSVZaRLi70ZAszIUjM5w3mtMCNbn99/lT+AE7h+WUqZ8z4ohLgcwCUppRnGwdFgMawy8qUy7jwyF3oQC1QznY0umNmi1fcdskBNabH7hPoLzy9hz2QKR/e0t3bHU33Ky4wsBe+izx2yAKsDyFH0kZH9ma87inzIfZOVHds8H3vu1HIOuipw2cwIUpoKy5buepzwMqZWOR4ZWfbIUjM5NyPLQLY+v6XF79n+MSHEJIAzAO4E8ECwh0WDKJ13nndM92ipc1Kvv5/VkylGYy9XbWmxs3ZnBV9/49621+54dJbPUYi81Tt7JpvvkAVYHUAOLyObbBLIXrW7swd37VD53tg3p1eyuGLXKDRVqUyvLprlUANZ05aR3iNb7ZHlgxVqrFpa3P/71Sjq9h0kuu8QFDnVQLY3e1tbZmQNq++DnoCtw54efTGNTIdrdzwcsENh6iQjy+qA4VYstc7I9gIfrPSPs3pnHED1gUbYfbJm2Y70HlmWupMfzMg2F91XOA2c9XwJADATlYysYWG8g6nAQfMmeRqWjc8/767dOdL+2h2PxgE7FKJLGwUAwB4fgayXDSkxkB1qfoY99YLKqcV9UbYlzqzmcXh+DACQ0rbOhQhLXKYW2ywtJgDLGQNfObW64+M590Eghz3Vx0CWeibtBrK9ysimvJLdBk99M0UTExF4wlXtkS3jC88v49YrZzDRRYCtc8AOhejCRhG7xhINV6nU0pgBI1Qzb37OmTBxr3F/XEgXULJsHJxzAtna0uIwhd2D263qgxWejwT80ZdP4ds/8G/4m0fObfm4l5Ed5R7Zurp5hdtwemSNYA6FBt26W1rc64xsscG+uvVcCVM9Cqqb8Y7z7Foez17cxOuOLnT1/Zh1oDBd2ihiz2TrbCwA6BrL3Cl6GVlOie2tk+7qnUPzTmlxSutNabFly0qFUhTxfKRay1knnHrP33wVn312sfJxlhY31/RfRQjx6mafl1IeCvZwaJD1uke2WUY2a1hYz5u4bKb1wJqwJdwnxp962nnj6qY/FqhmHVhaTGG4uFHEPh9lxQD3yA6aTz+ziNsOzLQ9sM8LZFNN1u/0gpedM1nq3lOna1bvANXMfCHEjKyUEmVbRnpqscZAlmps5E0cmhvDWFLDf/zoo/jTd74Stx3YVRn2NJZgaXE9rV7hXwTwhSb/I/ItnS8hoSk9eypf7ZHdebE8t54HAFw+E/4aoFY0VYGmCJxPF7BnMoVrupze6V24OQmRwnBpo+BrhyxQu0eW52LcredK+IE/eRh/8sDZtv+uwYzsUDu1nMNESsPcuPMAxNsnHGZpsffwLMp7ZBXB0mKqSrv72T/8fbdh//QI3vHhh/DcpU3kDAspXYn0Q5l+avWvcheA1wH4MJzA9dUA7gDwJQC/G+Jx0QBaz5cwM6p3vFamXdv3s9Y6t+YMrIlCRhaoHuvrjs53/e/DLBiFpVAqYz1vYu+Uv9eNxnUnA+PSpjOt+vhStu2/W3CHlUSlR9bk+dhTp1dyODQ3Vrm2tdooEASvnSHKN//e+yMfrBDgJHumRxKYHU/iT97xCowkVLz9gw/ihcUsV+800fQVLqX8kpTySwC+GcAfSSnvl1L+G4A/BPDWHhwfDZD1vNmz/ligdhrwzovlS15Gdlf/M7JAdR3Ba6/urj8WYBaMwuMFM757ZBWvlJM3anG36P63P9lJIGuWoSmi74N3VIXvjf1wajlb6Y8FelNaXMnIxmBqMR/0EQBsFMzK3JbLZkbx/97xShiWjS++sMz+2Cb8XlWWALxXCPGjQoifBvBeAIst/g7RFht5E1MjvRuulKyM+N950/LSWgEjuorZsd4F1s0kNcVduzPb9fdiFozCctFdveO/tJh7ZAfF0qYziOTUShZ2m+8tBbPc97JioGZvJ98be6ZQKuPCRrHSHwsAKb1xtVRQvPecKA978qa6t/t6osEjpUQ6b2K65h756t0T+NB/OIaUrmAixUC2Eb//Mm8H8BEAv+H++QkA/yGMA6LBtZ4v4XDNU9mweeVLjXpkL5sZ6VmZcytjSQ0HZse6Wrvj4R5ZCsvFtJOV811arLCUc1B4GdmiaeN8utBWNUvRtCtVJ/2kcf1Oz3mDng7NVwNZ76FGo40CQfAeVniT06NIZY8suXKlMixb7hiGeuuVu/AX73oVB9Q14SuQlVI+BOA6IcSU80e5Ge5h0SBaz5uYGetdRlZXBRQBGFadjOx6ezdiYXvft9205UlcN7ynvBz2REFrt7RYCAFNEczIDoDFTLHy+xPL2TYD2XJlwE8/8b2x97ZPLAZqSotLYZYWO/+NvfaGKFIrPbI8H4ddOl8CAEyP7KwSvPny6R4fTbz4eoULIaaEEL8J4DMAjgghfk8IMRPuodEgccomSm2vbeiGEAJJTa07UMLLyEbFy6+Y2dJD1A2u3yE/ljMG7nr/5/HcJf/PJS9uFDA9qmOkjTUAmiqYcRgAi5sGdk8mAbTfJ1soRau0mO+NvXPK3SFbL5ANc4+sl3XXItwjW12/0+cDob7z1lNO9rD9blD4fVT1UQBfB+DlAJIA3gTgT8M6KBo8lbKJHr9IU7qyIyO7kTeRKVqRWL0TBiEEVEVUpjYS1XN8MYMzq3k8cHLV99+5tFH0XVbs0RWFZVEDYHGziGv2TGLXWAInl9sLZItWRAJZTontudMrOeydSmE0US0AVBWBhKqEXFoc/anF3vodZmRpo+AEsttLi6k1v6/wuwC8v+bPPwfgtYEfDQ2s9ZxTNtHLqcUA6mZkvYnFUcrIBs0p5+TNGjW2nHWG93ilf35cSBexd8pfWbFHU3kuDoLFzSJ2TyRxZH4cJzrIyEaiR9abos3AoWdOruS2ZGM9SV0Z+j2yHD5GHi8jy0C2fX4D2QsA3uz+/jYA7wRwPJQjooHUrxdpsk5G9lzEVu+EQVcVls9RU6tZ5+HSqWX/geylzSL2tB3IKqwOiLmyLbGcMbB7MoXDC2M42cY5A7g9slEIZL2MLN8be0JKidPL2S2DnjwpvX7bT1CqpcURzsgqAkKwQoCAdKFxjyw15/cV/sMAbgcgAPw6gEMAfqSTHyiEuFMI8ZQQIi+E+LgQYkwIcUwI8YQQIi2E+KgQYnAjjCG17jayz/R43U1KU3eM+D+37qwQGdTSYgAsLaaWVnPuOhWfZaJFs4y1XAn72gxkdUXwoUrMrWYN2BLYPZnE4flxrOVKWHOrbPyI2vodTtHujbVcCZtFCwfnds5/GNHVUHtkzUppcXQzsoBzTjKQJZYWd85XICul/CyAy+BkY68HcEhKeV+7P0wIoQH4CwCrAH4KwDcA+AH3Y5vux94C4Cfa/d4UbWnvRdrjHtmkvrMP56W1PCaSGiZHBncvl84BO9SCl5G9sFFEvmS1/Hpv/cqeNntkNZU9snG36O6QXZhM4fCCE5S00ydbNO22BoSFxZsfwJ7E3jhVZ/WOJxV2abEV/anFgNMny0CWNvImkppSGYRG/vmdWvzfAVwupXxESvksgCvdj7XrGIB9AH4GwO8AuALAl+BkeH9HSvkHAO4D8IYOvjdFWGW0eI97ZOtlZF9aL+CyXaOR2SEbBk1RuPKEmlpxe2QBf32yFyo7ZNvMyLJHNva8hxi7J1M44k5Xb6dPtmCWkdKjEVConB/QM6fdEvRDdXpkU7qKQpilxXb0pxYD7jwLBrJDL503mY3tUNMrixDiG4UQHwTw8wB+TwjxQffPHwLwsx38vMvdX/8PAAPAXwHwHu+vuL8uAtjbwfemCFvP9a9HdntGNmqrd8LAATvUykq2hLlxZ52Knz7ZS5tOSX67PbI6M7Kx5+2Q3T2ZxP7pEaR0pa1AtlgqRybToDNw6JmTK1noqsBlddp4Ug1W4wWlskc24oGsytJigtMjy/7YzrR6RHoQwOvg9Mbe5P7+dXDKjD/Yxc97DMD3ArgRwC9u+5qGr2ghxLuEEA8LIR5eXl7u4MdTv6znS5hIatB7PHghqSlbMrJSSry0Vhjo/ljADR54caQmVnMGjl3prAP3E8h2mpHlHtn4W9w0IAQwN56Eoggcmhtvq7Q4Kj2ygJeR5YOVXji9nMOVs2NQ60wOTiXC7ZGtDHuKeGkxA1kCnIzsFDOyHWn6CpdS/qaU8hCADwP4WinloZr/vbuDn3fJ/fX3pZR/BuBpAN7VcM79dTeAiw2O5wNSymNSymPz8/Md/Hjql41Cf16kSV2FUZORXcuVUDDLuHzXYGdkebNGraxmS7hsZgT7p0dwaqV1UHJiKYvdk8kt+yD90LhHNvaWNouYG09WHkQeXvC/gscs27BsGZ2MrKrwwUqPnFrJ1S0rBoCUFm6PrBWTYU+qwvORnHvkXs+QGRR+H1X9AIBXCCF2CyGOCiHe0uHP+zcAaQD/QwjxLgC3AHgAwEkA73Y/dieAT3f4/Smi1vOlnu+QBZyMbO1T35fcicX1Sp0GicZJsdREvmQhXypjdjyJQ/NjvjKyT1/YwPX7ptr+WeyRjb/FzSJ2TyYrfz4yP47z6QIKpdaBiBesRCsjy/MxbLYt8eJaHlfO1r/Whr1+p7JHNsLrdwDnWm0zkB167JHtnN9X+O8D+ACASTiDmf5KCPHedn+YlNIA8N0AXgHgV+D0yP46gLe53/t9AP7a/RwNkPU+vUhTurplj2x1h+xgZ2R1VeFkTmrIm1g8O57AobkxnF7JQcrGN1OFUhknlrK4Yd9k2z9LU7hHNu4WNw3snqiWlB9eGIOU8JXJ9wb6pCIwtRhgRrZXVnIGSpbd8KFx2Ot3KhnZOmXNUaKyZ5vg9sj2IdkzCPwGst8O4EellMellP8MZ03Ouzr5gVLKT7ilyRNSyu+SUuallI9KKW+WUk5LKb9bSlno5HtTdKX7mJGtLS1+aW1IMrLsS6QmvInFc+MJHJofR9awsJwxGn79c5c2YUvgug4ysprK6oC4W8oUsTBZDWSPVFbwtM7kezMKIpWR5YOV0J13q5/2T9d/aJzSlVCnFsclI8t1UFQ0yyiaNqZYWtwRv81OqwBeJoTYBWfa8GEA/reh09DrV9lEctv6nXPrecyM6hhPDu4OWcDZnce+RGrEy8jW9j2eXM5tCVZqPX1hEwBww/72M7JOBoznYlyZZRsr2dKW0uIDs2NQhL8VPJWMbETW7/AhX2+cT7uBbIMNAWGXFlsxCWS5foc2Cv3Z6jEo/L7C/y+AdwBYBrAJp2f2N8I6KBosZVtis2j2pWwipSsole1KD8pL64WBz8YCXL9DzXkZWadH1smuNSsTffrCBqZG9IbZlWY09iTGmpep313zkCOlq7h816ivycVeH21UMrIaB+H1xLn11oGsYdmh9YfGZ9iTgN2krYMGXzrvBrJcv9MRX2kpKeXvCyHuBXAXgBSAB6SU94V5YDQ4NgompARm+pSRBQDDsjGSUHFuLY+jeyd6fhy9piqC63eoodWc2yM7lkBCVZDSlaYDn56+sInr901CiPZvCrlHNt4WN6s7ZGsdmR/HyTYystEJZBWuO+mB8+sFTKY0TKbqX/e9KdbetTloldLiGKzf4YO+4ZbOO9djZmQ74/sVLqV8Skr521LKX2YQS+1Yd1+k/eqRBQDDKsO2Jc6lB3+HLMBhT9TcStbAeFJDSlehKAIH58ZxqkF2zSzbeO5SBjfsb78/FmApZ9wtbjoZ2YWJrWXnhxfGcWol1zIo9MpHk1EJZNmz3RPn0wXsb3Kt9UrNwyov9rLuccjI8sHKcEu7pcXske1M04ysEOKzAH4GwC/V+bSUUt4dylHRQPGeNvVjj2ztU9/lrDdFcbAnFgMs56TmVrMlzI1XHywdmhvDUxc26n7tiaUsSpaN6zuYWAy4U4t5LsbWUsbLyG4NZI/Mj6Nk2Ti3nseVs/V3hQLRW7+jMXDoifPrBVy+q3Eg650PRSukQNb9bxz1QFZTBMosLR5qG3kGst1olZEV7v+Umt/XfoyoJa/+v58Z2aJZrqzeuazJxXVQsJyTmlnJGpgdr5aKHpofw0tr+S0Tvj3eoKdOA1ldFTwXY2xxswhVEZgd2/r+fXjBCV5bDXyqlBZHZP2OxvfG0EkpcW493/ShsfeQOawVPN5/46iXFit8sDL00gWWFnejaUZWSvl697ev68Gx0IBarwSy/c3Ieqt3Lh+GjCzLOamJ1WwJV85WH+gcmh+DLYEXV/O4avfWHvKnL2xgRFdxcG68o5/FczHeFjcNLEwkoWzbx3l43lvBk8Ubrt3d8O8XI7Z+R1MEShYD2TBtFEzkSuUWgawTYHrDwIJmlSUUgR3nbdSweorSeROqIgZ+m0ZYWpUWv7rZ56WUXw72cGgQVRvZI5KRHYIeWZZzUjOrOQMvv3Km8udDc97k4tzOQPb8Jq7dOwG1wxtCTVFgMnCIrcXNYt21TNOjCcyNJ1pnZEtRW7+jIBdS8ESOcy12yALVnumwSotN24YW8dU7AHtkyemRnR7ROxqmSK2nFn8RQO0rzPtX9j4WjUesFGnr+RIUAUz04WlTUveGPTkZ2bnxZCVLO8g0heWcVF/ZlljLlTBf2yM775SJbp9cbNsSz1zcxLfcsr/jn5fQFJgcPBZbi5tFHGjQA3t4fhwnm0y7Bmr3yEbjfdfpkeX5GKZWO2SBmh7ZkIY9mZaEHvFsLOBuGOC1eqht5M2+zJAZFK0eV90Fp6z4wwC+AOBOALcD+BKA3w3xuGiApPPODtl+lPhUSotNGy+t53H5rsEvKwacck4+5aV61vMl2BJbemQnUjrmJ5I7Jhe/uJZH1rBww/7O+mMBls7F3eKmsWPQk+fwwjhOLGUhmwyrKZplCFGtjuk3no/h8zKyzaqfUiEHslZsMrIKWy+G3IabkaXONH2VSym/JKX8EoBvBvBHUsr7pZT/BuAPAby1B8dHA8AJZPvzIt1aWjwcq3cADnuixlaz7g7Z8a2l/ofmxnBqZWt2zZtkfP2+zlbvAE4pp2XLpsEORVPRLGOjYO7YIes5Mj+OjYJZ2Uvc6HukNDUyZXPs2Q7f+fUCRnS16VyM6vqdsIY9SegRn1gMsEKAnGFP/Wi9GxR+H1ctAXivEOJHhRA/DeC9ABbDOywaJOv5Ul8mFgPVp755s4wL6cJQrN4B3KwDb9aojtWssxd0dmxrcHJofucu2acvbEJTBK7a3dmgJwCV8j6ej/Gz5O6QbZaRBZpPLi6Y5chMLAa8+QEMHMJ0Pp3H/pmRpg8vwi4ttso2tIhPLAa8Htl+HwX1UzrPjGw3/L7K3w7AAvAbAP43gKz7MaKW1vv4IvUysmdXcrBs2XSv3SDRVA57ovpW3OzZ/MS2dSrzY1jPm1ivya49fWETV++eQFLrPBDxyvt4PsbPYoMdsp4jC9XJxY0USnZkJhYDfMjXC+d9PDT2HjIXQistlpHfIQsAqmBGdtixR7Y7vgJZKeVDUsrrAMwAmJZS3iKlfCLcQ6NBsZHvX9mEdwN+wr3RGqaMLAfsUD0rmUYZWXfg04rzWpFS4unzGx3vj/V45X08H+NncbN5ILt3MoURXW2akS1a5chMLAbc0mI+VAnVufVC04nFAJDSwt8jq8ehR5al7kPNLNvIGBamR1ha3Clfr3IhxJQQ4jcBfAbAESHE7wkhZlr9PSLAycj2Y4csUO3D8TIGw9Ijq6kCUoIDn2iH1ZwBVRGY2lYl4e2J9abQLm4aWM2Vug5kNa+0mMFD7CxWSovr98gqisDhhbGmk4uLpXJkJhYDHK4TtpxhIZ03m04sBoBUojq/IgxWWVbee6JMUwRsno9Da7NgAkDf5sgMAr+Pqz4K4OsAvBxAEsCbAPxpWAdFg6NollEwy5gZ629G9uRSDkIA+1o8JR4U3pNoi1kw2mY1W8KusZ1TxC+fGYGuCpx2Bz497Q56umF/54OegNrSYp6LcbO0WURCU3Y89Kh1eH4cJ1v1yEYokNVVwffFEFVW77S41iZUBUJwarEqmJEdZmkGsl3z+yq/C8D7a/78cwBeG/jR0MBJ550XabMboTB5PbIFs4w9kykkIrICImzMglEjK9kS5sZ3Ztg0VcEVu0YrA5+eOr8JIYBr9wZVWsxzMW4WN4vYPZlsOrTnyPw4zqcLyBlW3c9HbdiTqgiU+b4YmvM+Vu8AgBACKU0Nb49sWSIRhx5Zhavyhlm/75EHgd+7+gsA3uz+/jYA7wRwPJQjooGSLjiDY/o1tVhRBBLuU9lhKSsGOGCHGlvJGpgbr/96dCYXVzOyB2fHMJbUuvp53uRQZmTjZ3HTwO6J+v2xHm/g0+mV+uXFRdPualhY0HRVYb92iM6t5wH4m0eR0pXQemTjkpHlOqjhtuHeI3P9Tuf8vsp/GMDtAASAXwdwCMC7QzomGiDrOedpU796ZIFqVnZYBj0BHLBDja3mDMw2KPU/ND+Gs6t5lG2Jpy9s4vouy4oBVCaHmnyoEjuLmWLDQU+eQ/PNJxcXo5iRZeAQmnPpAhKqgvk6VR/bjejhZmTj0COrskd2qHkZWa7f6ZzfqcWfBXAZnGzs9QAOSSnvD/PAaDCk8/1/2pR0+7MuG5LVO4BzcQSYkaWdVrMlzDa4yTw8N45S2cZT5zdwPl3oetATwH7tOFvaNLDQYNCT58pZ5331zEq+7ucLpTJGIjS1WFcEzLKElHxvDMP59QL2Tqd29ODXk9LV8NbvxGVqMXtkh1olkGWPbMf8Ti3+FIBbpZSPSCmflVKaIR8XDYj1CLxIhzIjqzB4oJ3yJQv5UrlujyxQXcHzT1+9AACBBLLs146nrGEha1gtM7IpXcW+qRTOrNYvLY7asCfVfW9k7BAOPztkPUldDbG0OCZ7ZBWFFQJDLF0wIQQwkWIg2ym/j6sWAXy/EIJF3NSWfvfIAkBSH8YeWQYPtNNq1nk9zjbpkQWAf/rqRQDA9fu6Ly32siIme2RjZamyQ7Z1ieiBubEmPbLRWr9TLXXn+RgGPztkPSO6AsMKs7Q4+hlZTWWp+zDbyJcwmdIrVXTUPr+v8m8E8A4ABSFE2f1f/RGFRDXSeRNJTelrj5S3eP3yXcOTkdVYzkl1rGSdvaCNhj3tGktgelTHxY0i9k2lsCuAtVnVQJY3a3FS2SHbYtgT4ASy9TKyti1hWHa0Aln3hpHBQ/CKZhnLGQP7p/09NE7pKgqlMEuLox8cKIKB7DBLF0xOLO6S33GUvxrqUdDAWs+V+pqNBZyMrKoI7GlRIjdIdIUDdminSkZ2rHGW7eDcGB57MY3rAsjGArXVAXyoEidLGScju+DjffPg7BjSeRPpfGnLPISim22L0rAnTnQPz8UN55zZ77O0OKWr2CyG06nmlBbHICOrcK/xMEvnTfbHdslvIPsQgD8BsMv98yUA3xXKEdFAWY/AizSlqdg3nYrFRS0ovFmjelZzbkZ2onEge2huHI+9mMYN+7vvjwW4RzauFtssLQacFTy3XFETyLr9j6kI7e/2MrKc6B686g5Zv6XF4fXIliy78kA3ylRFwJaAlLLpvmYaTMzIds/v1eX3AJwC8BYA3wsnkP3DsA6KBsdGodT3QPY1V8/jG2/a19dj6DXerFE9K5WMbOMqCW/gUxD9sQD3yMbV4qaB0YSKcR97hA/OuZOLt5UXexNpo5WRZWlxWLwdsn57ZJO6El5psW3HZNgTz8dhtrGtioXa5zcjOwLg16WUfw8AQggbwK+FdVA0ONbzJq5aGO/rMfzwXYf7+vP7gTdrVM9K1sB4Umvas3jHkTn89SPncOuVM4H8TO6RjafFzSL2TKZ8ZYkumxmFEDtX8HhBShR7ZDnsKXjn0wUoAtgz5a+NJ6WroQ17ssrxKC2urMqzJbTovEyoR9IFkztku+Q3kP04gPcIIbyv/0kAnxJCfLeU8k/DOTQaBNt7pqg3vCwYb9aolrNDtvnr8WWXT+PzP3FXYD+Te2TjaXGz2HKHrMdZwTOyIyNb9DKykQpknfORD/mCd369gD2TKd/7W8MsLTbL8Sgt5vCx4WXbEpuF/rffxZ3fQPYd7q8fqfnYDQD+PQAGslSXlJKN7H2ic/0O1bGaMxrukA0L98jG0+KmgVuumPb99QfnxnBmpX4gG6mMLCsEQnMuXcBlbay5S+lKpfw8aHEZ9lQpLZY8H4dNxrBgS7BHtkt+A9kDYR4EDaasYcGyJWYYyPYc1+9QPSuZEq6c7e0+Ze6RjR8pJRY3i9jdxqT3A3Oj+PjjF7YMrYlkjywzsqE5v17AKw7uav2FrpSmomxLJ3sacNDplBZHPyNbCWT5YGXobOSdid2sWuyOr0BWSvli2AdCgyfNF2nfaFy/Q3Ws5gy8PKDeV78q63cYOMTGZsGCYdlYaDLdersDs2PYLFpYz5uV/cNej2yUSotV9siGwirbuLRZ9D3oCahm6otmOfBA1rRt6Er0M7KawvfHYZUuOMMX2SPbnei/yim21vPOi7Tfe2SHkcbSYtqmbEus5UqYa9EjGzROLY6fxYy3esd/RvZgzQoeT9Fy1+9EKJDVOQgvFJc2iyjb0vcOWQBIuZn6oMuLy7aElIhJRtZ5f7RZWjx0qskeBrLdYCBLoVnni7RvKsEDS4vJlc6XYEv0vEdWZ09i7FR3yLZTWuwEsrV9ssXK1OLo3GpUp8TyvTFI7e6QBar7hY2ABz552fags7xh8A6RGdnhky7wHjkI0X+VU2ylKxlZvkh7jcOeaLvKDtleZ2TZrx07i5sGAGC3z6nFAHD5zCgUsXWXbCGCU4srU7T53hioc24g22lpcZC8oFCPUUaWPbLDZ8O9R54aYdViNxjIUmjYI9s/DB5ou9WsE5zMjvVnajEzsvHhZWQXJvxnZBOagstmRreUFkdx2JPKnsRQnE87gey+NgLZkUogG+x1ymtj0GLVI8tr9bDx7pE5tbg70X+VU2x5PbJsZO89ncHDQHv24iYefXG9rb+zknNej73ukWUGLH6WNouYTGltB6AH5sa2ZGQr63e06ASyOoePheL8egFz48m2+qG9rw26R9a77sUjI+scI3tkh0+6YGIsoSKhMRTrBv/1KDTpvImJpBaLXW6DppJ14ICdgfQzf/sk/uOfPgrZxs2Pl5HtdY+sqggIwSmxcbK4abTVH+s5ODuKMyv5ynlZMMtIaAoUJToBhcrhY6E4ny601R8LVHungy8tdjOyMbj3YIXA8ErnTVYsBiD6r3KKrXS+hOkxZmP7oVpazIvjoMkZFp48v4FLm0U8c3HT999byRpQFdGXMiZdVWCydC42FjPt7ZD1HJgbQ9awKv3YxVI5Uv2xANedhOV8utDWxGIgxB5ZNyOrRegBSiPVh848H4fNRqHEsuIAMJCl0KznTa7e6ROWzw2uR19cr6wO+dyzS77/3mq2hF1jib5kx3RF8EYtRpY2jbZ2yHoqk4vd8uKiaUcvkOUgvMDZtsT59QIua6M/FgiztDg+U4s1lhYPLScjy0C2W9F/lVNspfMllk30CXd3Dq4HT69BVQSu3j2Ozz7nP5BdyZYwO9af16OmKjwXY0JKieWsgfkOAtmDs1tX8BTMcqRW7wBcTRaGlayBUtnuICMbzvod7wFuHPbIKqwQGFrpgsmMbACidYWhgeJkZPki7Qfu7hxcXzm9hhv2TeIbbtqHJ86lseL2vraymussOAmCrgqYvFGLhaxhoWTZHfVSXzYzAk0RlYysE8hGLCPLUs7AnUu3v0MWqCkttsLJyMZpanGZ749DhxnZYET/VU6xtZ4vcWJxnwghoCqCWYcBUzTLePylNF5xcBdef3QBUgJfeH7Z199dyRr9y8gqzMjGRTf7hjVVwWUzIzizkgfgnK9RWr0DVLN0DByCc76yQ3a0rb/nlZ0XSpxazPNxuEgp3R5ZVi12i4EshcIq28gULZYW95HKvsSB89VzGyhZNl5xcBbX75vE7skkPvfcoq+/u5otYbbHE4s9mspzMS4q+4Y7PFcOzI1VdskWzXKkVu8A1Swdh48F55wXyHY87CmkPbIx6JFVBQPZYZQvlWGWJTOyAYj+q5xiaaPgLHpmaXH/6Ipg382AefD0KgDgtgMzEELg9Ud340svrKBkNb8RzJcs5EvljrJsQXCmFvNcjAMvI9vpvuEDs84uWSklCszIDoXz6TymR3WMJ7W2/p6qCOiqCKG02M3IxmBqscbBjEMp7d4js2qxewxkKRTreTeQ7VMpI3HAziD6yuk1HN0zUal0eMPRBWQNCw+dWWv691YrwUmfMrKK4LkYEytd7hs+ODeGfKmM5YyBQoTX73B+QDDKtsQzFzaxv82JxZ6UrgZeWhyvPbLOMZZZITBU0nnnmsyMbPei/yqnWPJepJzI1j8csDNYrLKNR86u4xUHd1U+dseROSQ1BZ9tsYanGpz0b2oxA4d48B567OrwIaS3guf0Sg5F047esCeVgUNQbFviZ/72q3j0xTS+5Zb9HX2PlK7CCDgjW9kjG4Me2eqwpz4fCPWUV7XIHtnuMZClUKS9jCx7ZPuGA3bi49JGEb/xmeOVaZv1PH1hE/lSeUsgO5JQcfvhWXz2uUXIJnsIveBkdqx/U4s5eCweVnMGpkf1jndwVlbwrOacHtnIrd9hRjYIUkr8t394Cn/58Dn82OuP4J2vPtTR90npSuA9spU9sjGYWqxUemT5/jhMNtx7ZGZkuxf9VznF0rqbkWUg2z8csBMfH77/DH7tMy/gX5661PBrHjztlA+/4sCuLR9//bW7cXY1j1PugJ16VnPeAJ9+TS3muRgXq13uG943nYKuCpxeyTs9slHLyHJKbNeklPgfH38af/aVF/HDdx3Gf/raqzv+XiOhlBbHKCPLHtmhVOmRZSDbNQay1JXf/cIJvOZ9n8eXXti6AsTLyE6P8UXaL5rC0uK4+MyzzuThD957umFm9Sun13BwbgwLk6ktH3/90QUAwOealBev9LtHVlWaZpspOpazRlfTrTVVweW7RnFmJRfJYU9qZY8sz8dOSCnxC//0DP7kgbN412sO4T1vvAZCdB4wpnQ1tD2ynVYV9BLX7wynyj0yS4u7Fv1XOUXaPzx2AS+u5fH2Dz2In/uHp5AvWQCcjKyqCEy0OcWQgqOpCsuVmkjnS/izr7yIr55L9/Um4sxKDieWsrh27ySeeCmNR19c3/E1ti3x0Jm1HdlYANg/PYKjeybw2SZreFayBsaTWt/6FZ3SYt6oxcFq1sB8lw88Ds6O4YXFDKRE5HpkhRBOhQDPx7ZJKfFL//Ic/vi+M/i+Ow7gZ77uaFdBLACkNBVFM5we2VjskeX6naGULpSQ0JTItV7EEaMM6thSpojnFzP4/+6+CpsFCx+67zS+fHwFv/q2m5EumJge0bu+yFHnNEWwD6yJjz34Ev7vvz4HAJhIaXjlwVm86vAsXnVoFkf3TEDp0eoGLxv7G9/xMrz19x/AB+89jVuv3BqwvrCUwUbB3NIfW+sN1y7g9794ChsFs+6ANWeHbP+e/Dr92lbffj75t5rr/lw5MDeGzz3vVAhELZAF3LYLBg5t+8j9Z/CBL53C2191JX7uG64L5Pqe1BVkisG+N8RrajFLi4fRRp73yEGJ/qucIuv+E85Oy7uv3Y2f+8br8GfvfCUMs4y3/N79+NTTi6z97zOd63eaOr6YwcJEEr/xHS/D19+4F8eXMvif//QM3vybX8bb/uCBpsOTgvSZZxdxze4JXL17At/5iivwr09dwktr+S1fU+mPbRDIvv7oAsq23FHi71nNGV31PXZLVxWU+FAl8syyjXTe7Hoo2IG5MXgvn6j1yALegxWej+3684dewq1XzuC933R9YDfgI3rwGdk47pFlRna4pPMm75EDwkCWOnbviRVMj+q4bu8kAOD2I3P41//0GnzLLZdhpcs+K+oesw7NHV/K4po9E/h3L9uP//OWm/DFn3wd7v/p1+MHX3sID59dx1fPbYR+DBt5Ew+dWcfd1zl9rt97+5VQhMBH7j+z5eu+cmoN+6ZSuGym/q7Gl10+g5lRHZ9/rn6f7Gq21Lf+WMAtLeZDlchby7nTrbvMyHqTiwFgJBG92wyNU7TbdnY1h+cuZfDmG/cGmkVKhRDIeu81scjIsrR4KKULJfbHBiT6r3KKJCkl7j+xgtsPz24pwZxM6fiVt92Mj77zlfi5b7iuj0dITmkxb9bqsW2JE0tZXLUwseXj+6ZH8B9fewS6KvCJJy/6+l6nV3KVUfrt+sILSyjbEndfuxsAsHdqBG++cS/+4qGXkDWccjspJb5yeg2vOLir4Q2kqgi87poFfP75pbo3RP1+sKSpCh+qxEB133C3GdnRyu9TWhQzsnzI165PP+O0QNxz3e5Av28Y63fiNLWYw56GUzpvYooZ2UAwkKWOnF7J4cJGEXccmav7+TuOzOGG/VM9PiqqxfK5xs6nCyiYZVy1e3zH56ZGddx5ZA6f+OrFluXF+ZKFb/rte/E/Pv5UR8fx6WcWMTeexM2XTVc+9o47DyJjWPjLh14C4LzWVrIGXnFwtun3ev21C1jPm3j8pXWsZA3cf2IFH7r3NH76b76K1VwJc33skdX5UCUWqtOtuztX9k2NIKE5txepiE0tBrhjuxOfenoR1+6dxOW7Rlt/cRtGdBWF0EqLo3+Lq7nHyAcrw2XDnSND3eOwJ+rIfSdWAAB3HK4fyFL/aapAweTFsZ7jSxkAwNV1AlkAePONe/H557+KJ85t4GWXTzf8Pv/0xEVkihY+8+wSDKuMZBvZp5Jl44vPL+PNN+7dUtVw8+XTOHblDP74/tP43tsPtOyP9bz6qnloisC//8OvwLCqN+m7xhJ41aFZvPH6Pb6PLWjcaRwPq1lv33B3GVlFEbhy1yiOL2Uj2SOrMiPblpWsgYfPruFHX39V4N873NLiGGRk3WO0eT4OFfbIBoeBLHXkvhOr2D89gitng306S8HRVYV9YA0cX8wCAI7MT9T9/D3X7cF/VZ/EPz95sWkg+7GHXkRSU5A1LDxwchV3XbPg+xgeOrOGjGHh7jqleu+48yB++KOP4tPPLOLB02uYHUvg8PxYne9SNTWi47/ccw1OLTu9v0f3TOKaPROYG0/0fTKixnMxFlYDysgCzsCn40vZSE4t1vlgpS2fe3YJtgTuuT7YsmIASOoqDMuGbcvAJsV7+9O1GAx78npk+WBleBTNMgpmGdOj7JENQl/qLoQQ00KIFSGEdP98TAjxhBAiLYT4qBCC0VGElW2J+0+u4M4jc32/QabGNIU3a40cX8piYSLZsEdlalTHq6+ab1pe/PylDB57MY0fe8NVGEuo+OTTjfe41vPpZxaR1BTcWac8/57r9+CymRF86N7TLftja/3wXYfx/rfejHe++hDuvGoO8xPJSLxGda6CioWVrIGEpmA8gP3fB9yHnFHNyLIn0b9PPXMJ+6dHKoMdg+SdH7VVJN0yyzY0RUTiva+Vao8sH/QNi82CM1NjkqXFgehXA8F/A1D7KOIvAGwC+CkAbwHwE/04KPLnqfMb2CxauP1I85496i9dVdiX2MDxxUzd/thab75xL86nC3j8pXTdz3/swReRUBV85yuuwF1HF/DpZxZ93xxLKfGZZxdx55E5jNTpIVQVgf9w+wE8eGYN59OFlmXFUadxFVQsrGRLmBsLJoN/1W6n2mFyJHqFX3xv9C9nWPjS8RXcc/3uUALDlO7chgZZXmyV7ViUFQPVrDFPx3jayJt44OQqPvbgi1h3p763knYDWfbIBqPnVxghxCEA3wXgQwB+3P3zIQA/K6X8cyHE2wC8AcAv9PrYyJ/7Tjr9sbezPzbS2AdWn5QSx5eyeNuxy5t+3ddetxu6KvDPT17ELVfMbPlc0Szj7x47j3uu341dYwm88fo9+MRXL+Lxl9Zx65Wtg87nFzM4t17Au193pOHXfPttl+PXP3McWcPCK1sMeoo6TRWVcj+KrtWcgbmJYKZbf8st+3Fgdgx7p+qvjOonZmT9+/LxZZQsG/dcF06PvVd6XrSCC2TNsozFoCcAlXJqZmTj4fGX0vj8c0t45uImnrmwifPpQuVzmaKJd73mcMvvkXa3HLBHNhj9eKW/D8CvAlh3/+y9O664vy4C2FvvLwoh3iWEeFgI8fDy8nK4R0kN3XdiBUf3TGA+oBseCgcH7NR3YaOIfKn+xOJaUyNOefE/P3lpR3nxvzx1ERsFE9/5iisAAHddMw9dFb7Liz/7rLPv9Q1HG/fUTqR0vP1VV2LfVArX7KnfyxsXOqfExsJK1sDsWDB9W7qqRLaSQFMVPljx6VNPL2J6VMdtB2Zaf3EHvNLiQinAjKwdn4wswHVQcfKuP3kYv/W54zi9ksOtV87gp7/uKD7y/a/AWELFxY2ir++RzjuZW+6RDUZPA1khxB0AXgngt2o/vO3LGr6apZQfkFIek1Iem5+fD+MQqYWiWcZDZ9Ybrt2h6NAVDtip5/iiM7F4+w7Zer6+QXnxxx58CVfsGsWrDjmZ0smUjtsPz+GTT+8Meuv59DOLuPnyaSxMppp+3U/ccw0+9xN3Vfqo4kpTBWzJyZxRt5ot9XXfcK9oimAGzAezbOOzzy3h9UcXoKnh3C5WS4uD++9hlWVoxxsGVgjEg21LrGQN/PBdh/GZ//xa/OZ33oIfeu1hvPbqeSxMprCUMXx9H2Zkg9XrV/oxAJcBKAD4efdjv+j+6kVGuwFc7O1hkV8Pn1lHybLrDqihaGFGtr4TS87E4qsWmmdkAeDu63YjoSr4xFerb0knl7N48PQavuMVl2+ZsnnP9btxdjWPF9yJyI0sZYp4/KU07m6SjfUoiojk1Nd26e5NpcngIbKklFjNljA3JIEsh4+19tDpNWwUzNDKigFnajEQRmlxfB7+aQxkY2GzaMKWwK6xne+R8xNJLG/6C2SX3TVnrGoMRq8D2Y8CeJn7v993P/ZOACcBvFsI8S4AdwL4dI+Pi3y67+QKNEVEtmSMqjjQpL4XFjOYG09gxkcJpVNePId/frI6vfgvHnoJmiLwbbdetuVrv/a63RAC+OTTl5p+z8+5ZcX11u4MKm+gCR+sRNdm0UKpbAeyeifqNJWBgx+fcierv+bq8B5cp9zd28WAS4t1LT4ZWYWlxbGw5g5z2jW2M5O6MJHEUsZfafHiZhFTI/pAPKSOgp6+0qWUK1LKJ6SUTwC45H7sJIC3AZiE0z/71wB+pZfHRf7dd2IFt1wxjbEA1jNQuNh3U9/xpSyO+MjGer7+pr24sFHEYy+lUbJs/M0j5/CGaxewMLG1LHhhIoWXXzGDTz3TPJD9zLNL2D89gqMx73tth1fmx0A2ulbdLMHsMASy7NluSUqJTz+ziFdfNY/RRHjXe29qe5AZWassY7FD1sOMbDysu72tM3X2vy5M+C8tXtwsYvcks7FB6dsjKynle6WUwv39o1LKm6WU01LK75ZSFlr9feq9dL6EJ89vsD82JlSWFu8gpcSJxSyu3u0/iKwtL/70M4tYzZXwHe6Qp+3uuW43njq/iXPr+bqfL5TKuPfEspu9jc+NVrd0d/AKS4uja9XNNszWKZsbNHzI19rT7kTWe64Pt3IkjB5Zs2xX2hniQFUUlH3MVqD+Wss5va276lRzLUwmkS+VkTWslt9ncdPA7hbzMci/+LzSqe/+7dQqpAT7Y2OCw552Wtw0kDEsX/2xnsmUjtdcPYd/efIiPvbgi9g/PYLXXFV/2Nw91zu9ZJ+qM71YSon/+YlnUDRtvOmG8HrOoqjSI8ssWGStuNmEoeiR5UO+lj71zCIU0XyyehAqpcVB7pG1ZaymFqsKUOb5GHnentj6GVnnfXNps3V58dJmcUdFF3WOgSz5du+JFYwlVNx8+XS/D4V84KTYnY4vOROLj/iYWFzrzTc65cX3nljBW49d1nCK8MG5MVy9e7xuefHvfuEk/uwrL+KH7zqMrzkU772w7WKPbPStuDdpQ9EjqyisDmjhU09fwrEDu0KfYu2VFhcCDGTNsg0tJntkAbfUndfpyFvLez2y9UuLAbQsL7ZtiaWMwdLiAMXnlU59d9+JVbzy0GysSnaGGSfF7uRNFG61Q3Y7r7xYEcDbjl3e9GvfeP0ePHh6rTIYAgD+5pFzeP8nn8c3v2wffvKea9o/8JhjRjb6vB5ZP0PQ4o7Dnpp7cTWP5y5lcE8PBtJVM7LBrt/RY5WR5TqoOFjPlZDQFIwmdg5pWnAD01aB7Fq+BMuWLC0OECMS8uV8uoDTKzn2x8YIs2A7nVjKYNdYou3yycmUjrfddhneeuvl2Dc90vRr33j9HtgS+MyzTnnxl48v46f+5qu4/fAs3vdtN29Z2TMsvDI/Zh2iayVrYGZUH4oHlarC0uJmvnxiGQBw97XhB7LJSo9ssFOL45SRVRUBno7Rt5YrYddoou58C6+0eLlFILvolh4zIxscjp4lX+47sQIAuOPIcJVExpnKQHaH44vtTSyu9YvffKOvr7t+3yT2T4/gU08v4oZ9U/jhP30URxbG8fvfcysSMVoJESTvppIZ2ehazZZCLyONCs4PaG5x04AQwOW7RkP/WUlNgRDBBrJmWSKlx+eBITOy8bCeLzWsWJka0ZFQlZYreJbcXbMLzMgGhoEs+fLQ6TVMj+q4us3eQuoflhZvJaXE8aUsvuGmvaH+HCEEvva63fjYgy/iyfNpTKQ0/PH33YbJ1M7dc8PCK/PjQ5XoWs2WMDsEZcUAJ7q3spYzMD2iN5wFECQhBFKaGnhGNk6VBRorBGJhLVequ0MWcM7j+Ykkljf9ZmQZyAYlPq906qtHzq7j1itmhrIsMq68ck72gjmWswY2CmZbE4s79cbr98CwbORLZXz4+16BvVPNy5EHXWWPLB+qRNZK1sDcxLBkZLl+p5n1nFl3oE1YUroSeI9snPbIqoqAzfU7kbeeN+tOLPbMTyRb9sguuoHu/JBUv/QCM7LU0mrWwKmVHL7t2GX9PhRqg85yzi2OVwY9hV9VcNuBGbzzzoN40w17cM0eVjHo7k2lyaxDZK1kDcwNS0ZWUWDxfbEhJ/PUy0BWDXRqcSl2e2T5YCUOWr0uFiaSOLOaa/o9FjNFzI4lhrbNKAwMZKmlR86uAwBuO7Crz0dC7dBYzrnF8UVn9U67E4s7oakK/ts3XBf6z4mLSkaW52IklSwbm0VreHpkVQYOzaznS7iiB/2xnhE94NLictz2yHKKdtRZZRsbheYZ2YXJJB48s9b0+yxtFtkfGzA+EqCWHjm7joSq4Mb9U/0+FGoDyzm3Or6UxdSIzpKePvBuKtmvHU2rOafcrd1p3nHFDFhzqz3OyCZ1NeDS4nhNLdYYyEZeumACqL9D1rMwkUI6b8KwGj+UWdzkDtmgxeeVTn3z8Nl13LB/Eil95+4sii6N5ZxbHF/K4qqF8bqj8ylcXpk7M7LRtJp1dh7Pjg9HabGmKijbEpJ9iTtIKbGeazydNQxOj2yAU4vteO2RVQQfrETdursXvtnrws8KnsXNInZPMCMbJAay1FTRLOPJcxs4xrLi2OEe2a1OLGV7UlZMO1XL3JmRjaKVrJeRHZJAVuFe40YyhgXLlj2dYB18abEdq9JiTWVGNurW3EB2V4vSYgANBz5ZZRsrWWZkg8ZAlpp66vwGSmUbt1450+9DoTbpLC2uWMkaWMuVcITro/pCr5QW82Ytila8jOzYcNxgcaJ7Y5XMU5Mb9qCldBXFJuWY7XKmFsfn9lZVFD5Uibj1vJeRbbxGb8HNtC41WMGzmivBltwhG7T4vNKpLx52Bz0xkI2fShaMF8jKxOKrmZHtC61SWsyHKlG06mVkh2T9TrXtgufjdqte5qnHpcWFUpClxXaspsKqArB5nY60tZyfHlmvtLhY9/PeDtmFIXmf7ZX4vNKpLx4+s46Dc2NDMwRkkGhcv1NxYsmdWMyMbF9wgna0reZKSGoKxhLDMQfBe29kRnYnP72AQUsFPuwpbntkmZGNukpGtkmlwux4EopoXFrs7ZDdzYxsoBjIUkNSSjz64jqzsTGlM3ioOL6UxURSY29KnyTcMvcSH6pE0krWwNx4cmgGoVWmaPO9cQevF7CXPbIpXW066bUdUkpYtqxM7Y8DZ2ox3xujbC1XwlhCbTr0VFUEZseTDUuLvYwsA9lgxeeVTj13aiWHtVwJxxjIxpJaGWjCC+TxxSyO7ObE4n6p7pHluRhFK9nS0Ax6ApiRbabaC9jDQFYLLiPrZTb1OGVkOewp8vxO8l6YSGKpQWnx0mYRQgzPUL1eYSBLDT1yxumPPXaAgWwcVYY9MeuA40sZXLXA/th+Yb92tK1mDcwOUfsIe2QbW8uZSKi9LTNP6QoKAU0t9q53ccrIqoKBbNSt5f3tVnYC2calxXPjyVidm3HAf01q6OGza5ge1XFojgFAHDF4cKzlSljJlnD1bvbH9ote6dce7nMxqlazpZ6WkvYbpxY3tpYzMDOm97R6ZURXUbZlIA8WTLcCKU57ZDWFe2Sjbj1X8jXJe2Ei1TiQzRTZ3hQCBrLU0MNn13HrFTNQYlSiQ1Uc9uR47EWnsuAIM7J9wz2y0SWlxGrOGJqJxQDbLppZy5nY1eM1TF7fYRC7ZCsZ2Rjdt6gKM7JR5zsjO5nEatao+99zcdPA7gn2xwaNgSzVtZo1cGo5h2MHdvX7UKhDHPbkrDT41U+/gP3TI/iaQ7P9PpyhVSnl5M1a5GwWLJhlOVQZ2eqObZ6P263nS9jVZFdmGFK6898jiPJi72FZnMo3GchG33rO9JmRTcKW1ZVmtZYzRe6QDUF8XunUU4+cZX9s3DHrAPz94+fx9IVNvOdN1zSdNkjhEkI45XPMyEbOSs7dITtEPbKV98YhfsjXiN8SyiB5781GAAOfvIdlcSotZiAbbYZVRtawfD3gmXczrtvLi82yjZVsiaXFIWAgS3U9cnYdCVXBjfun+n0o1CEv6zCsfYlFs4xf/uTzuHH/FL7xpn39Ppyhp6nsA4uilczwBbI65wc0tJrzV0IZpGBLi92MrBKf21v2yEZbOm8C8DfJe8ENVLdPLl7OcIdsWOLzSqeeevjsOm7YP8ksVox55ZzD+qT3Q/edxoWNIv7rm69ln3cE6Ioy9P3aUbTq7Q0dopUQqsJ1UPVYZRsbBX8llEHy7jOCKC02K6XF8XnPVxUF9pBep+PA2628y2dpMVANXD3VHbLD88CwVxjI0g5Fs4wnz22wPzbmNHV4hz2tZg383udP4u5rF/Cqw+yNjQJNFSzljCCvl2uYAlldYUa2nnTByTz1+lwYqWRkAygtLnulxfG5vVUVnotRtp7zv1t53g1klza3B7LOnxc47Clw8XmlU888dX4DpbKNW69kf2ycDXP53G9+9jjyZhk//XVH+30o5NJUZaj7taNqOVuCEP6yDYOCPbL1VW7Ye56RdW5Fh3dqsTK0lVNxsJZ3M7I+AtmkpmJ6VN/RI+uVGrO0OHgMZGmHh91BTwxk400b0vK5U8tZfPQrL+Lbb7scRxa4OzYqdEUMbb92lK1mDcyMJmI15bVbWmVq8XC9N7bilZn3q0c2kNLiyh7Z+JzPmiJQlnxvjKp2H/DMjyd39MgubhahKmKopsP3Snxe6dQzD59Zx8G5saEa/jGIKitPhix4eN+/Po+kpuD/u/uqfh8K1dBUZegeqsTBarY0dDdXGjOydfUvIxvCHtkY9cgq7tRiyWA2ktZyTsn99Ki/tVQLk8kdGdnFTQMLE0nO6wgBA1naQkqJR19cZzZ2ACiKgCKGK+vw0Jk1/OvTl/CDrz3MXpSI0VTBPbIRtJI1hqo/FqgGOcPYdtGMV0LZ6/PBKy0OYv1OXKcWA8M7mDHq1vMlTKY031n+hYlUnR5Z7pANS3xe6dQTp1ZyWMuVcIyB7EBw+hKH4+IopcT//udnsTCRxDtffbDfh0PbJJiRjaTVXGnoqm90lhbX5WVk/WaeglLJyFpBlBY717uEFp/Ml8rhY5G21uZKqoWJJJYzxpYM+9Kmgd0Tw/U+2ysMZGmLv3/sPIQA7jgy1+9DoQDoyvBMin3y/AYeezGNH33DVRhNaP0+HNpGU9kjG0UrWWPoAlmVGbC61nImxpMaklpv1+5VemRLw7lH1jsfbZYWR9J6vuRrYrFnfiKJkrvKyrOYKXLQU0ji80qn0BXNMj76lRfxhqO7cfmu0X4fDgVgmPoSP/X0IlRF4Btu3NvvQ6E6NO6RjZyiWUamaA1dj6yueKvJGDjUWssZmBnrbTYWAFKaN7U4uPU7ceqR1ZiRjbS1XKmtqe5eCbHXJ1s0y0jnTe6QDQkDWar4+OMXsJYr4fvvPNDvQ6GA6EPUl/jpZxZx24GZtp6cUu/o3CMbOWtuKenckJW8qaqXkeWDlVpreRO7xnp/LmiqAl0VgZQWWzGcWlypEOD7YySt59rLyC5s2yW77Aa07JENR3xe6dSxjbwJu0UwI6XEh+47jaN7JvCqQ7M9OjIKm6qIocjInl3N4fnFDL72uj39PhRqQFO4RzZqVrPucJ8he/ijD+lE91bWcyXs6nF/rCelqQGVFsdvj2xl2BNLiyNpLd9+jyxQ3R27uMkdsmFiIDvg1nMlvPaXP48f/4vHm37dA6dW8dylDL7/joMQIj4XAGrOCR4G/+L46WcWAQD3XLe7z0dCjbBHNnpWsk6mYJY9sgQnQ9+vipZUQoURxLCncvwysgrPx8gqlMoomnZbK6m2lxYvuplZlhaHIz6vdOrIB+89jXTexD8+cQH/+tSlhl/3oXvPYNdYAt/0sn09PDoK27CUc37q6UUc3TPB3u4I01VmZKPGC2TnhyyQ1VSvR5bnY612ewGDlNKVQHpkvQe37JGlIHgrqXa10Ts+ntQwmlArpcWVjCxXAoaCgewAS+dL+PD9Z3DPdbtx/b5J/Pd/eAobeXPH151dzeGzzy3iu155RWV6IA0GbQiCh9WsgYfPruGe61lWHGXaEE3QjovVXH/2hvYb93buVCiVUTDL/cvIBlZaHMepxc6xskc2eryVVO1kZAGnvLhSWpwpIqEqPV9rNSzi80qntn3o3tPIGhb+8z1X4/++5Sas5Ur4xU88s+PrPnz/GahC4Lu/5so+HCWFSVMGv5zzs88twZYsK446XeXU4qhZyRhI6QpGE8P1ANPL1jEDVrWe72+/9EhCDWaPrHu902OUkfWqoNkjGz3eQLx2emQBYGEiVSktXto0sDCZZNteSBjIDqiNvIk/vu8M3nT9HhzdM4kb9k/hh157CH/1yDl86YXlytdliib+6uFz+Iab9rIRfQDpQ7B+59PPLGLfVArX75vs96FQE5oqGDhEzGquhLnx4bvB8rJ1rBCo8m7Y+5mRLZrBTS3WYtQjW8nIDnj1VBx5D3jafV3MTyYr04oXN7lDNkzxeaVTWz5032lkDAs/9oarKh/70ddfhcPzY/iZv30SOcMCAPzVw+eQNSx83x0H+3WoFCJVGezgoVAq48vHl/G11+0eupvxuNEUhYFDxJxbz2NuyPpjAed9UQgMfNtFOzrNPAUlqSsoBLlHNoZTiwf5Wh1XlddFJ6XFm9WpxRz0FB4GsgNoo2DiQ/edxj3X7cZ1NVmqlK7ifd92Ey5sFPD+Tz6Psi3xkQfO4NYrZ3Dz5dP9O2AKzaAPe/rS8WUUTZv9sTGgq4KlxRFycaOAh8+u4zVXz/f7UPpCG/CHfO2qZJ76NuxJhRFARjaOU4s5RTu61nMlKAKYHGmvv3VhIoVcqYycYTmlxRz0FBqt3wdAwfvwfWeQKW7NxnpuvXIXvvdVB/CRB84gpas4u5rHT77xmj4cJfXCoO/u/PQzi5hMaXjFwV39PhRqgaXF0fL3j12AlMC33rK/34fSF06FwOC+N7bLyzz1rUdWD6i0uCwhRDU4jANVMJCNqrV8CdOjibbPJ2+X7JnVHDKGxdLiEMXnkRX5slk08cF7T+Hua3fjhv1Tdb/mJ994DfZPj+D3v3gS+6ZSeBOzWQNrkHd3WmUbn312Ea8/uhCrp+/DSlM47CkqpJT420fP4dYrZ3Bgbqzfh9MXzMhu1WnmKSgpXUEhiIysbUOP0cRiAFA5fCyy1nMmZjqYNrzglhI/fX4TAHfIhiler3Zq6SP3ncFm0cKP18nGesaSGn7pW28EAHzfHQdjNRSB2jPIuzsfObuO9byJr72OD2LiYNDL3OPkqfObOL6Uxbe+fDizsYBbIcDzsaLTzFNQUroazB7ZsozVDlmg2iNrM5CNnLVcqaO+ca+U+MnzGwDAjGyIWFo8QDJFE39072m84egCbrysfjbW8+qr5nHfT78e+6b44hpk6gDv7vzUM4tIqApee81w9vjFDdfvRMffPHoOCVXBN9y4r9+H0jfqgLddtGstV+oo8xSU4EqL7dhV6HilxczIRs96voQrdo22/fe80uJqIMuMbFji9Wqnpv7kgbPYKJj48bsbZ2Nr7Z8e4aTXATeoA3aklPj0M4u4/cgsxpN8HhcHmqrAsiUkdyX2lVm28fEnLuDu6xYw1cfApd9YIbDVWq6E2bH+3WwndRWGZXedlTRtGasdsgCHPUVZpxnZ6VEdCVXBsxed0uIFZmRDw0B2QBTNMj5072ncdc08brpsut+HQxGhKcpAXhyfX8zgxbU87mFZcWzoXDERCV98fhlruRK+9ZbL+n0ofTXoq8natZ4zMTPWvwcbKd25HTWs7h68WmW7sic4LjT2yEaSlBLr+VJHu5WFEJifSMKwbIzoKib4wD008Xq1U0P/8Ph5rOZKeNerD/X7UChCBnXY06efXgQA3H3tQp+PhPzyevGZBeuvv33sHGbHEkNfkq+7FQLkWMt3lnkKyoiuAkDX5cVx7JFVBHtkoyhrWDDLsu0dsp45t7x492SS1Y8hYiA7AKSU+OC9p3Ht3km86vBsvw+HIkQfwD6wsi3xiScv4pYrplmuEyNeuZ85YOdjnGzkTXzmmSV808v2xa6PMGjO/ACei4CbecqV+rZDFnCGPQFA0eoukHVKi+N1bnsZZD5YiZb1nAkAHWVkgWqfLO9TwhWvVzvV9eXjK3hhMYt33HmQT31oi0GbzCmlxH/7+yfx3KUMvuuVV/b7cKgN3mTOQTof4+afnryAUtnGW14+3GXFANfv1NosWrBs2deMrFdaXCh1m5G1K+81cVHtkeWDlShZyzu7lXd1WHK/UMnIMpANEwPZAfDBe09jfiKJb7x5b78PhSJGUwZr2NP7P/k8PvbgS/iR1x3Bt93Km/E4qZYWD875GDd/++h5XL17HNfvm+z3ofSd85CP5yLg7JAF0N9AVvNKi7f+N9nImzizkvP9fcyyjN1KQa8Umqdj95Y2i3j3Rx/FmntOd8N7XXRaqeCt4Nk9wYnFYWL3ccwdX8zgiy8s47987dVIuhcCIo82QH1gf/ilU/jdL5zEv3/lFfgv91zd78OhNlVLiwfjfIybMys5PHJ2HT/9dUdZuQOnnHNQ3hu75WWeOi2hDEIq4dy/PHV+A4+9tI7HXkzjsRfXcXI5ByGA//f9r8SdV821/D6bBTN2U4uVyvodRrLd+tiDL+ETT17EPdfvxr97WXd7ste6fMCzMMmMbC/E67EV7fCh+04jqSn4rq9hmSXtpKmDUT73Vw+/hP/1z8/i62/ci//5727gjXgMVfrAmHboi7999ByEAL65y5u7QaEN8I7tdq1l3Rv2PvbIjro9su/5m6/iZ//uKXz+uSUcnBvDT77xGhyeH8d//svHW2bZ/u6xc3jwzBpefzReQwA1rt8JhJQSf//4eQDAM+7am26sd/mAp9ojy4xsmJiRjbHVrIG/efQ83vLyy/paEkTRpStK7AOHTz19CT/9t0/i1VfN4Ve//eZKPxHFi1c+N4hTtKPOtiX+9rHzuPPIHPZMMTsAOOcjAwdHtRewf/cRt1wxg/e86Rrsnx7BLZfP4PJd1T33d10zj2/5nfvxU3/zVXzge26t+yDzxFIWP/t3T+EVB3bhR153pNeH3xWVq8kC8cS5DZx2y9CfvZjp+vut5UrQFNHx6pwb90/h2r2TePkVM10fCzXGjGyMffQrL6Jk2XjHnQf6fSgUUZoqYMv4jvX/t1Or+JGPPYYb90/h97/7VpbPx5g3SZTlc7330Jk1nFsv4FtfzmysR1MUTtB2RaFHNqEp+I93HcG/e9l+XDE7uiVYvX7fFN7zpmvw6WcW8WcPvrjj7xZKZbz7o48ipav4ze+8JXY9sl4gG9frdFT8/WPnkdAUvPH63Xg2oIzszFii4wqwhckU/uXHX43Ld412fSzUWLxe7VRhWGX8yQNncdc18ziyMNHvw6GI8oKHON6wZYomfvRjj+GKXaP44/9wG8a4UDzWOLW4P1ayBt77j89gPKnhjdfv6ffhRAYzslVr+RISmoLRRHQfFH7/HQfx6qvm8D//6RmcWNqabXvvPz6N5xcz+LVvf1ksKw40ZmS7ZpZt/OMTF3D3tQt4xcFZLGcMLGeMrr7nWq7U13J78oeBbEx9/PELWMkaeOedh/p9KBRhaoyDh1//zHGsZA386ttu7usQEgpG5aFKzEvd4+SltTze+vsP4NRKFr/972/BaIIPgzzORPf4vS+GYd29YY/y7AFFEfiVt96M0YSGH/vY4zDcfbN/99g5/PlDL+HdrzuM11493+ej7IzKHtmu3XtiBau5Er75Zftx7V4nudNtVnY9Z2Kmw9U71Ds9D2SFEN8uhDgvhFgTQvy2EEIRQhwTQjwhhEgLIT4qhGAevgkpJT5472kc3TOBO47M9vtwKMLi+qT3+UsZfPj+M/iO267ATZdN9/twKABej2zczsW4Or6YwVt//wGsZg189J2vxF3XxGsATtg0ReHeTtdarhSLh4ULkym8/9tuwjMXN/HLn3x+S1/sf7o7vpPsGch27+8fO4/pUR13XbOA6/Y668W6DWTX8iXOn4mBnj6eFULMAPhjAH8K4CSA/wPgMQD/FcAFAD8F4DcAPA/gF3p5bHFy/8lVPHcpg/d9202RfoJK/afHcHenlBI/9w9PYSKl4T1vvKbfh0MBYUa2dx57cR3f9+GHkFAV/OUPvQpH93Bv7HaqyqnFnrVcCbtiknl6w7W78T1fcyX+8Mun8c9PXoptX2wtBrLdyRoWPvn0Jbzl5ZchoSlIaAnsnUoFkJEtdbxDlnqn16/8AwDOAvg5KeX/BbAO4NsAHALwO1LKPwBwH4A39Pi4YuWD957G3HgC33Tzvn4fCkVcHLNgH3/iAr5yeg0/+cZrYpElIH90Ti3uiS8fX8Z3/dFXMDWi469/6HYGsQ3oymCsJgvCet7ErrH4rAj52a+/FlctjON8uhDbvthaldVkPB878qmnL6Fo2viWW6rD7K7dO9nV5GLbllhnRjYWehrISikfk1JeK6W8JIS4G8AMgAfcT6+4vy4C2Fvv7wsh3iWEeFgI8fDy8nIPjjh6Tixl8bnnlvA9X3MAKT26gxkoGnQlXlmwrGHhf//zs7hx/xS+47Yr+n04FCDukQ3fAydX8f0ffghX7BrFX/3Qq3DFLLt0GlEHYDVZUJyhNvHIyAJASlfx/97xSvzZO18Z277YWpWpxZKBbCf+/vELuGxmBLdeWV1zc+3eCZxczlZ6qdu1WTRhSzAjGwN9qcUQQnw7gI8D+DcAn9326YavZCnlB6SUx6SUx+bn4//m1Yk/vu80EpqC7/oa3uRTa3Eb9vRbnz2OxU0Dv/Dvrue+2AHDPbLhKtsS7/3Hp7FnKoW/+MFXYWEi3lmqsOkqM7KA85Bzo2DGrvplz1QKtx+Z6/dhBCJu1+koWcoUce/xZXzzy/ZvabW7du8kLFvi+GK2o++7FoGVVORPP4Y9fR+APwPw1wBeD6c3FgC8d6TdAC72+rjiYD1Xwt88eg7fest+zI3HpwyI+qdaWhz9zMOJpQw+eO9pfPuxy3ELF4gPHO6RDdc/PH4ez13K4CffeBRTI/HJrvWLytLi/7+9+w6Ps7r2Pf7dUyRZtoplS7Lcq9wrLoALYNM7hIQQQiCUhAsnEEhOQiA5BDi5Jwk3hBxqQifUECCUUI1tjHHBxt3GTS6SLFvV6n3mvX/MjCzbKiNbmpl39Ps8j5+xRiNpy3sszXrX2msBUFrdAOgFezgFrtmq+VjHvbfhAF4LLp165FG7E234dKjaF8ja7QJPdxTqZk8DgMeBtcA/8AWyufgaP91qjEkE5gD/Hcp12cUrX2VT2+Dl+jnDwr0UsYnDwUNkv2CzLIt7391CfIyTX5yrBk/RSHNku05tg4c/fbKDiQOSuHBiiydz5Chup0qL4fALdgWy4WOMwaULK8flX+v2M3FAEiPTEo64f0ifnvRwO9l6nIFsSZX/Ao9KiyNeqDOys4E4YDrwHvA+8FPgO0Ai8Ed8mdo/hXhdEa++0csLy/cyd1RfMtMT2v8AEewTPHy4+SBf7irmP88ZTR9VG0QldS3uOi+t3Mf+0hruOm8MDpXkB0UZWZ+mEkq9YA8rh8Pg0RnZDtlVUMmm/WVc2qzJU4DTYRjdL+H4M7JVgYysqlsiXUgzspZl/QNfJrYlk0O5Frt5f2MeBRV1PPht/TNJ8OwSPLyxJofBKfF8b9aQcC9FuogdO2jbQVlNA48u3sW8zFRmR8mZwVBw6YwscDiQVQlleLkcBk+EX3CONO+s34/DwEWTW65CGZuRyAebDmBZVodHVZaoUsE27Dt4qxuxLIunv9jDqLRezBulFyoSPDsED5ZlsS6nlFOG91GDpyimrsVd48nPsyiraeCXKsnvEJfD6LmImtpEClUIdIxlWby9bj9zRqW22thuXEYCZTUNHCir7fDnP1RVT6zLQQ9NB4l4CmRtYOXuErYeKOeGOcM6fFVJurdAYBjJGdk9RVWUVjcwbUhyuJciXUhzZDvfgbIanl22h0unDGB8/6RwL8dWXA4HXss3L7I7ayqhVGlxWLkcRuN3OuCbAxXkHqrhwkmt9wQYewINn0qqfDNk9Zo78imQtYFnlu0mpWdMi+cARNrS1OwpgoOHtdmlAOpUHOVc6lrc6R7+dCeWBXeelRnupdhOU/+Abh7IllTXkxDrIsall4PhpIxsxyzPKgJgbhtVimNOIJDNr6jTxR2b0E+uCLenqIrPthXw/ZOHEKcSB+mgwIs1TwT/glybfYiEOBcjU3uFeynShVwOZWQ70878Ct74OodrThnCoJT4cC/HdgIXViL5Z2MoHKqq1/nYCODUGdkOWZFVzPC+PclI6tHqY3rFuhicEs83Byo69LlfXrWPpTsKmTU85USXKSGgQDbCPfflHtwOB9ecrCY40nF2aPa0LruUKYOS1W01ytmhOsBO/vDRdnrGuLj1jJHhXootNV1Y6eYVAsUKZCOCy+FQRjZIjR4vq/aUcMqIPu0+dmxGxzoXv7N+P7/+12bmj0nj7vPHnsgyJUQUyEaw0up63liTyyVT+pOaoJEk0nGR3uypsq6R7QfLVVbcDTgdBmNUWtwZ3t+Yx8Jv8rn59BFq0nOcAj8bu3sW7FB1PSnxGjESbg4HHTojW1JVz/988A31jd3v5+nG/WVU1jUG1aV9bEYie4qrqK5vbPexC7fmc+c/NjBrWAqPXz2t6eKrRDbtUgR7fXUONQ0erp8zLNxLEZsKdIqN1IzsxpxSvBZMG5wc7qVICLgdDpUWn6Al2wu44/X1zBjamxv0u+G4KSPrc6iqgZSeulAebh3NyC7aVsBfl+5m0/6yLlxVZFqRVQzAycPbz8iOy0jEsmDbwbbLi1dkFXPLK2uZ0D+Rp6+doaN8NqJANkJ5vRYvr8pm1rCUps5rIh3V1NAkQoOHtdmHAJg6SBnZ7sDt1MiTE7Fmbwk3v/Q1o9IS9GLrBOmMrI+vO6sysuHmdBg8Hbiokl/uGylTWNHx0TJ2tzyriLEZiUFVowTTuXhDTik3vrCaISnxPP/DmfSKdXXaWqXrKZCNUEt3FpJdUs33dTZWTkBT+VyEvlhbl13KyLReJKm0rVtwOR0RWx0Q6bbmlfPD51fTP6kHL94wk6Qe+j9zIpwRfpEvFGrqPdQ0eHRGNgI4jenQ7+nCijoACvy33UVtg4c1ew9xahDnYwEG9u5BQpyr1UB2R34F1z73FSm9Ynjpxln6v2BDCmQj1Esrs+nbK5ZzxvcL91LExpqaPUVg+ZxlWazLKWXqoORwL0VCxO00NEToRZVItqeoih88u4pesS7+fuMs+vZSKeiJckd4/4BQKKn2zZBN0ZiRsPNlZIN/Lhb4M7EF5d0rkF2XXUpdozfoQNYYw9h+iS12Li6trueGF1bjdjp4+YaTSU+M6+zlSggokA2hukYPf/hoG/tLa9p83P7SGhZty+fKGQM1201OSCSXFu8trqakqp5pQ1RW3F24HA6VFnfQgbIavv/0KrwW/P2GWQxIbn3chAQv0D+gOz8fD1X5A1llocLO5ezYHNlAABsoMe4ulmcV4XQYZg4LfjTO2IwEth0ox9vs39fjtbjttfUcLKvlr9ecxOA+GmFmV4qSQuijzQd5YkkW97y9CauN7nSvfZWNBVw1c3DoFidRyRXB43fW7vOdj52mjsXdhstpIvKiSqSqqfdwzTNfUV7TwIvXz2RkmmYtd5ami3zdOCO7PKsIgH5JykSFW0czsvmBjGw3Ky1enlXMxAFJJMQFf7RibEYiVfUecg5VN9335093sHRHIfddPEGvQWxOgWwIvfpVNk6HYcn2QhZ+U9DiYxo8Xl5bncP80WkM7K0rRHJiIvnF2rqcQyTEuhilF+fdhtvpsG1p8da8cub/aQk5JdXtP7iTvLhiL7sKKnns6mlMGJAUsq/bHbi6+VzjfcVVPPTpDhaMSWOinlth15EzspZldcuMbGVdIxtySpk9Mriy4oCjGz59vOUgjy7exZXTB3HVzEGdvk4JLQWyIbKnqIqVu0v4yfyRjErrxf3vb6G2wXPM4z7Zkk9hRZ2aPEmnaJojG5EZ2VImD0rG4Q+2Jfq5HPbtWvz0st3sLqzi3Q15Ifl65bUNPPF5FqePTmVeZmpIvmZ3cvginz2fjyfC67W4681NuB0OfnfZRIzRz+BwczqCLy0ur22krtGLMYebPnUHq/eW0Oi1OHVE+/NjmxvdLwGH8V2M3FVQyc/+sYHJA5O475Lxeu5HAQWyIfKPNTk4HYarZg7mvkvGk1NSw5OfZx3zuJdW7mNg7x564SKdwh04BxZhWbCquka2HSzX/Nhuxte1OLKei8Eora7n/Y0HAN/V/FB4+os9lFY38POzR4fk63U3rm7c7OnV1dms2F3MPReMVVlxhHA5g8/IFvizsMP69qS4qj4ijw51hRVZxcQ4HZzUwb4acW4nw/r2ZPXeQ/z472uIdTl44vsnaXxZlFAgGwINHi9vrMnljNFppCfGceqIvlw4KYMnlmQdUaa2q6CSFbuLuWrm4KbRACInwuEwOEzklc9tzC3Da8FUNXrqVtxOY8sM2D+/zqW+0cslU/qzMbeMvHYa9p2o4so6nvliNxdMzFBJcRfpruN39pfW8D8fbGP2yD5cOUNllZHC0YHS4sC52EBJeHfJyi7PKmLakOTjCkDHZiSyYncxe4urefR70+ivpnlRQ4FsCCzaVkBRZR3fbfZL454LxuJ0GO5/f2vTfS+v2ofbafTLRTqVy+mIuPE7a7N9jZ40eqd78ZUW2ytwsCyLV1Zlc9KQ3ty2YBQAn3RxVvaJJVnUNHi446zMLv063VlgNJkdL6wcL8uyuPutTXi8Fr+/fJLKKiOIqwPNngKjdwKBbHdo+FRaXc+WvPIOlxUHjO/v+7f61XljOCXI0T1iDwpkQ+D11TmkJcRy+ujD5cIZST34yfxRfLo1n8XbC6ip9/Dm17mcOyFDMwKlU7kjMHhYl32I4ak9Sdb8wm7FV1psr8Bhxe5idhdVcfWswYxI7cXItF58vCW/y77egbIaXly5j29NG6guxV3IGcGN8LrKW2v38/mOQn557mgGpaiZZCRxOhxBPxfz/Y2eAsFZd2j4tHJ3MZZF0PNjj/a9WYN58vvTuGHOsE5emYSbAtkudqCshiXbC/j29IFNXRIDbpgzjOF9e3Lfu1t4c20u5bWNfH+WRu5I53JGWIMdy7JYm12qlvfdkLuDsxIjwcurskmOd3P+xAwAzhmfzld7S5pmcHa2//1sF5ZlcfuZo7rk84tPU/+ACLvI11UKymu5770tTB/Smx+cMjTcy5GjOB0cMee0LQXldfSMcTI8tafv7W6QkV2eVUx8jJNJA5OP6+OTerg5d0KGqhCikALZLvbGmly8Flw5/dgANcbl4LcXj2dvcTX3v7eVzPReHRryLBKMSBt5kl1STUlVvQLZbsjlcETURZX2FFTU8vHmg1wxbWDTuaxzxvfD47X4bFvLI9RaU1nXyEsr93HJo8v43lMr2ZBTesxj9hZV8Y81OVw9a4jGr3Wxw2dk7fN8PF6WZfGbdzZT1+jlj1dMUqf4CORyOIIucy+oqCUtMY4+PWNwGCjsBhnZ5VnFzBiaQoxLYYscSc+ILuT1Wry+OofZI/swuE/LL0rmZaZy7vh+1Hu8XD1riK4WSadzOQ2eCMo6NJ2PVcfibsftNLbqWvzGmlwavRbfa1YpM3FAEhlJcUF3L96SV8bdb29i1u8W8ut/babeY7Ejv5JLHvuSO19fz8Gywy9C/7xwBzFOB7eeMbLTvxc5krubdC1u8Hj5xT838vGWfO48K5PhqSpXj0TODp2RrSM1IRaX00GfXrFNpcbRqqC8ll0FlR2eHyvdgyvcC4hmy3YVsb+0hl+eN6bNx913yXgykuO44qSBIVqZdCcuR2Q1e1q7r5ResS4y0xPCvRQJsY5kHcLN4/U1eZo9ss8RL/6NMZw9Lp3XVudQXd9IfEzLv0a/3neIB97fyvqcUmJdDi6a3J+rZw1myqBkKusaeXxJFs8s28OHmw9y82kjmJfZl3c35HHL6SNITVCfhK7m7AZzZCtqG7jl5bV8sbOI2xaM4kfzhod7SdIKVwfmyBaU1zLRX2KblhDb1PwpWq3YXQxw3I2eJLopkO1Cr6/OITnezTnj09t8XHpiHPdeND5Eq5Luxu3snGZPjy3exeyRfZlygp2G1+UcYvKgJI2Y6obcLodtziQu3VHI/tIa7rlg7DHvO2d8P15YsY+lOwo5d0LGMe8vq2ng/7z0NS6H4b8uHMe3pg0kKd7d9P6EODe/PHcM35s5mN9/uI0/L9zBw5/tICHWxY/mjujS70t8mroW2+T52FH55bVc99xqduRX8MdvTeI7moYQ0RwOE/wZ2Yo60vwXu9IT446o6ohGX+4qIqmHm7EZieFeikQgBbJdpLiyjk+2HuSak4cS69LQZQkfl/PEs2A5JdU8+PF2VmQV89KNs47781TXN/LNgQpuOV0v1rsjt8NQ38qZxKq6RvLLaympqqe4qp7iynpKquqwLPjxaSNCfjbq5VX7SE2I5axxx16InDksheR4Nx9vyW8xkP39h9soqqzjX7fObrM5yaCUeB67ehrX7inh4YU7uGRK/yMCXuk60dy1ePvBCn743FeU1TTw7HUzOC0ztf0PkrAKNiNbWddIdb2nKZBNS4hlY25ZVy8vbLIKK1m0rYCTh6fo4re0SIFsF3lr7X4aPBbfnamroBJeLkfL5xL/+XUue4oq+c9z2i59B1iy3dfY5susIg6W1dIvKe641rIxtwyP19L52G7K1Up1wMGyWk57cDF1jS0HuakJsXx3Zug6uu8vrWHRtgJuOX1kU+auOZfTwYIx6Xy69SANHu8Rj1m5u5hXv8rmR/OGB91hc+awFF656eTOWr4EwRWlZ2SXZxXx479/TQ+3k9d/fAoT/LNGJbIFe0Y2MGonLfFwIFtcVUejx3vMZAy7e2f9fn711ibi3E5uPk0Xv6VlCmS7gGVZvLY6m2mDk3UOUMLOFzwcGSB4vRYPfbKdg+W13DBnOCk9257numhbAb3j3RyqbuBf6/cf9y+VjzYfxBiYOkgdi7uj1qoD1mUfoq7Ry13njWFsRiJ9esbQp1cMveNjuOLJ5Tz1xW6+M31QyLqtvv5VNha0eSHynPHpvLk2l5W7i5k7ypfxqm3w8Ku3NjE4JZ47zswMyVrl+Liaxu9EzxnZnJJqbnh+DQN79+D562cyILlHuJckQXI6DB6r/UC2wN/YKT3BdzE5LTEOy4KiyvrjvsAcaWobPNz//lZeWZXNjKG9eeSqaVHzvUnni67LNxGivLaRAb3juSqEGQSR1rhaGLS+NvsQeWW1eC34dGvb3VdrGzwszyrmkikDmDY4mbfW5mIF8Qv3aFmFlby0ch/fnTGI3u0EzhKd3K1UB2w9UI7TYbju1KGclpnKhAFJZCT1IM7t5Ka5w8kqrGLx9o6NuzleDR4vr63O4YzRaW2OwJmXmUoPt/OI7sWPLNrJnqIq/u9lE+kRoyMlkSyQkQ22U2yksyyLe9/dgjEoiLUhpyO46QKBxk7NM7LN77e7vUVVXP74cl5Zlc3Np43g1ZtOVhArbVIg2wWSerh58fqZfHu6yool/Fpq9vTuhjxiXQ4ykuL4aHPbgeyKrGLqGr3MH5PGZdMGsiO/ki155R1ex3+/v5Uebic/O3t0hz9WooPL2fIc2a155YxI7dk0q7W58ydmMCC5B39bujsUS+SNNbkUVNRxzSlD2nxcnNvJaZmpfLIlH6/XYmteOX/9fDdXnDSQOaPUXTPSufzZfTuNg2rLR5sPsmhbAXeelakg1oaCPSMbyMim+jOy6Ym+W7uP4LEsi3fW7+fCR5aRV1bDs9dN567zxkRdubR0Pj1DRKLc0SNPGj1ePth0gAVj07hgYgZf7iqmvLah1Y9fvL2AHm4nM4elcNGkDNxOw9vr9ndoDYu3FbB4eyG3LRhF314aLdJduZyGhhZerG09UM74/i2f5XM7Hfxw9lBW7SlhQ05pl66vtsHDI4t2MnVwMqcH0SDnnAnpFFTUsTb7EHe9tZHkeDf3nH9sl2OJPIHSYk8UjN+pqG3gt+9tYVxGItedOjTcy5Hj4HQ4gistrqglzu0gMc53MjCQmbVzRja/vJYf/f1rbn9tPaPSe/Hv2+Yyf0zb0z5EAhTIikQ5l/PIcs4Vu4spqqzn4sn9OXdCP+o9XhZva7ls07IsFm0rYPbIvsS5nSTHxzB/TBrvrM8L+mxZfaOXB/69lWF9e3KtXmR1a27HsRnZkqp6DpTVMq6N0QpXzhhEQqyLp77o2qzsK6uyOVBWy3+ePRpj2j+PO390Oi6H4Y5/rGdjbhn3XjReZfM2EU0Z2T99soOCijr+5/KJymDZlNMRXJm7b/ROXNPPp769YjHmcKbWTizL4vXV2Zz50Ocs3VHI3eeP4Y0fn6KKAukQ/cQTiXK+kqXDwcN7G/LoFevi9NFpTBvcm9SE2CPO+TWXVVhJ7qEazhhzODt1+bSBFFXW8cWuoqC+/osr9rK7sIrfXDg25CNUJLK4nAavxRHzEr854CtTH9e/9UA2Ic7N92YN5oNNB8gpqe6StVXXN/L4kl2cOqIPp44MrjQ4Kd7NKSP6kFNSw4IxaVw46dhRPBKZHA6Dw9j/jOyGnFJeWLGXH5w8hMknOONbwsfpcODxWu32nygoPzxDFnwVK316xtguI5tdXM3VT6/il29uYlxGIh//dB4/mjdCF2Kkw/SMEYlyvnOJvl+OdY0ePtx8kLPHpxPnduJwGM4el87ibYXUNniO+dhF/kztGaPTmu47Y3QayfFu3lrbfnlxcWUdf/lsJ6dlph7xOaR7CoypaWh2YWVLnm8GYnvD7q+bPRSHMTz75Z4uWdvzy/dSVFnf4TPcV5w0kLSEWB64dEJQWVyJHC6H44jnot00erz86q1NpCXE8rNz1HvAzgIVAu1dWMmvqG0qJw5ITYizVUb2g00HOOfhpWzMLeN3l03g1ZtOZmjfnuFeltiUAlmRKOd2Hm4isXRHERW1jVw0uX/T+8+bkEFNg4elOwqP+djF2woZ0y+B/s1KfWJcDi6a1J9Pthykoo2ztQB/+nQHNfUefnPhWL3Il6YXa82bj23NKycjKa7dEVAZST24eHJ/Xl+dQ1l128+7jiqraeCvn+9m/pg0ThrSsdFQl0wZwKq7Fxzxf0TsweUMrlNspHp++V62Hijn3ovGkxjnDvdy5AQ4A4FsOxnZwnJfaXFz6Ymx5NskI1taXc/db29iVHovPr1zHlfPGhKysWoSnRTIikQ5V7Nzie9uyKN3vJs5zUonZw1PIamHm4+OKi8ur21g9d4SzhhzbCb1smkDqGv08uGm1jseb8kr49WvsvnBKUMZmaZ5ykJT2dgRgeyB8jbPxzZ349zhVNd7eOWr7E5d1zNf7KaspoE7zzq+2a+6SGNPziA7xUai/aU1PPTpDuaPSeO8Cf3CvRw5Qc4gMrLV9Y1U1DUek5FNS4i1TUb24YU7Ka9p4A/fmkRGki7+yYlTICsS5QLNnqrrG1m4NZ/zJ2Y0lXiCr9zzzLHpLNyaT0OzRjxf7iyi0Wu1WBI8dVAyw/r25K11uS1+TcuyuP+9rfSOj+H2BaM6/5sSW3L7Z3cGyjlrGzxkFVYxvo3zsc2N65/I3FF9ee7LPdQ3dk5JaElVPc8s28P5E/sxYUDLnZMlOrmdR3Z0t4uCilp++to6vJbFfReP14WUKNBUrdJGIBsIVo/OyKYlxFFUWRfx57135Ffw95X7uGrm4HaPkogES4GsSJQLNHv67JsCaho8R5QVB5w7oR/ltY2syCpuum/RtgIS41xMG5x8zOONMVw2dQArd5eQe+jI5ju5h6q55eW1rNpTws/OziQpXiVv4hMYeRLIyO7Ir8Djtdps9HS0m+YOp6Cijnc35HXKmp78PIuaBs9xZ2PFvpyOY2dsR7qFW/M59+Ev2Jhbxh++NYlBKfHhXpJ0Aof/YoS3rUC2whfIph+VkU1PjMVr+XpSRCrLsnjg/a30jHHqZ610KgWyIlEu0Ozp3Q15pCfGMnNoyjGPmTuqL/ExzqbyYq/XYsmOQuZlprbaRfCyqQMAeGe9L6CobfDwl4U7OfOhz1m8vYCfnZXJVTMGd9F3JXbUlJH1Z/635vk7FmcEnwmdO6ovY/ol8PDCHTy2eBcfbT7IroKK48rQFpTX8sLyvVw6ZYDK37sht41Ki2vqPfz6X5u48cU19EuM49+3zeGSKQPCvSzpJC5nEBlZ/znYozOyqf63A4FuJPrsmwK+2FnET8/MpI9myUsncoV7ASLStdwOQ2VdI59vL+SaU1purBDndnLG6DQ+2ZLPA5dMYGteOYUVdcxv4XxswKCUeGYOTeHNtbmMSO3JA+9/w/7SGi6YlMHd54/VLDg5RqCkPfBibUteOQmxLgb2Dv65YozhngvG8st/buTBj7c33e90GIakxDN7ZF9+ce5oEoJofvPIol14vBa3n6ny9+7I6TRBz8MOpy15Zdz+2np2FVRy09xh/Pyc0cS6nOFelnSiYM7IHi4tPjYjC5BfXhuW4xH1jV4WfpPPGaPT6BFz7POyvtHLf/97KyNSe3LNKUNCvj6JbgpkRaKcy+mgzp+turiFsuKAcyb049+bDrA2+xArsooxBk7LTG318QCXTxvAXW9t4uaX1jKmXwKv3nQyp4zo06nrl+jhOjoje6CcsRmJHe5aOXdUKst/tYDKukb2FFaxq7CCrIIqduRX8PKqfXy+o5D/vWoqU1qZq3moqp4H3t/KW+v2c/WswQzpo9EP3ZHb4YjojGx5bQNPf7GHJ5bsond8DC/dMIs5o4KbcSz2EswZ2fyKWmKcDpKPOq6TlhjejOxTX+zmwY+3M7RPPH/41iRmDT/yNcDzy/ewt7ia538444j+HCKdQYGsSJQLBA9D+sQzaWDrV2vnj0kjxungo80H+XrfISYPTG63BOiCSRks/CafuaNSuXrWYA0zlzYFzsg2eLx4vRbfHCjnO9MHHffn6xXrYuLAJCY2e16v2VvC7a+t54onlnPHWZncfNqIpmyHZVl8sOkg9767mdLqBm6bP5Jb5488sW9KbCtSz8hW1TXy/PK9/G2pr5v2hZMyeOCSCfRuZ0SV2FcwZ2QLy+tITYg9prlXqv/3dDg6F/tGl2UxeVAyJVV1XPm3lVx7yhB+ce4Yesa6KKyo45HPdnHG6FRO1yx56QIKZEWinNsfPFw0qX+b3S17xbqYO6ov76zPo7iqjp8uaL8hQ0Kcm6evndFpa5XoFjgj2+ix2FdSTXW9J+jRO8GaPjSFD26fy91vb+LBj7ezbGcRf75yCg4Dv3lnMx9vyWfigCRevH5Wh5pMSfRxOSMrI1vb4OHvK/bx5OdZFFfVM39MGneelalu2t1AcGdk644ZvQO+2e4pPWPCMkv2mWV7KK9t5HeXTmBY3548+PF2Xlixl0XbC/jD5ZN4d0MeNQ0efn3huJCvTboHBbIiUS5QytNSt+KjnTOhH59tKwDgjDFtlxWLdFTTHFmv93Cjpy4IJpN6uHn0qqmcNiqVe9/dwnl/WYrHa1HX6OWu88Zw45xhqh6Qpo7u4VbX6OG1r3J4dPEuCivqmDuqL3eclcm0wb3DvTQJEaf/grOnjedjfnktw1NbPgYRjlmyh6rqeXbZHs6bcHh02W8vHs8FkzL4xT838r2nV2EMXD97GCNSe4V0bdJ9KJAViXKXTu1PSq8YRvdrvyvrmWPTcToMveNjmNBfWQDpXG5H4IysxdYDZbgchlHpXfMCxxjDd2YM4qShvfn5GxuIczn53WUTGK4XVOLncpqwzt5s8Hh5Y00ujy7aSV5ZLTOHpfDoVVOPOWMo0c9pAs2eWn9MQUVdqz0oUhNim7oah8pfl+6mqr6RO44apzNjaAof3DaXPy/cwVd7SrhNs+SlCymQFYlyQ/r05Jogm9mk9Izh6lmDSU+M63ADHpH2NGVkPRZb88oZmdary7uvjkjtxdu3zO7SryH25HKYpsZjXaG0uh6P1yKph/uICoBGj5e31+3nfxftJKekhqmDk/njFZOZPbJPm8c/JHo5m5o9tfx8rG3wUFbTcEzH4oD0xDh25ld22fqOVlhRxwvL93Lx5P5kph97kbxHjJO7zx8bsvVI96VAVkSOcP8lE8K9BIlSTV2LvV625JWrA6uElcvh6LLS4le/yuaetzcRSPj2inWR1MNNUg835bUN5B6qYcKARO6/bgKnj05VANvNudoZv1NYERi9E9fi+9MSYimsrMPrtUJyEfqJJVnUe7zcrmyrhJkCWRERCYlA47H8sloKKuo6vdGTSEe4nIaahs4tLbYsi8eXZPHgx9uZl5nKgjFplNU0UFrdQFlNA2U19aR5Y/nNheM4e1y6AlgBfDONofVANlA2nNpCsyfwZWQ9XoviqnpSW8nadpYDZTW8tGofl08doKMaEnYKZEVEJCQCGdkNuWVA1zR6EgmWy9G5Z2S9XovfffANzyzbw6VT+vPgtydrbqYE5fAZ2VYCWX8jp/Q2MrLgC3i7OpB9bPEuLMvS2VeJCPoJKyIiIREYv7MxtxSA8RlqKCbh43Q4Ou2MbIPHy8//uYFnlu3hulOH8tB3piiIlaC5HG2P3ykIlBa3kpEN3N/VnYtzSqp5fXUO35k+iEEp8V36tUSCoYysiIiEhMtfWrz9YAUDknuQFO8O84qkO3N3Utfi2gYP//HKWhZ+U8CdZ2Xyk/kjVTIsHeJs54xsfnktLochJT6mxfcHzs52defiRxbtxBjDf8wf2aVfRyRYCmRFRCQkAqXFjV5LZcUSdk6HaTUDFqztByv41VsbWZdTygOXTuCak4d00uqkO2kvkC2oqCM1IbbVRk6BcuKuzMjmlFTz5tr9/OCUIWQk9eiyryPSEQpkRUQkJJqXWqrRk4Sb23n8XYtLqup56NPtvLIqm4Q4N49eNY0LJmV08gqluwgmkG1t9A5AnNtJcryb/C7MyD6/fC8G+PG8EV32NUQ6SoGsiIiExBGBrDKyEmZOh6HR07GMbH2jlxdX7OUvn+2kut7DNScP4adnZtK7Z8slnyLBCBy7aPWMbHktA3u3fSY1LSG2yzKyFbUNvL46hwsmZdAvqeWGUyLhoEBWRERCIlBaDMrISvi5nS2XFlfUNrAlr5y6Ri+1DR5qGzzUNXqprG3kpZX72F1UxbzMVH5zwVhGpSeEYeUSbfxxbJsZ2ZOG9G7zc6QlxJFf0TWB7Btrcqmsa+SHs4d1yecXOV4KZEVEJCQCc2QT41wM7K0zVhJevozskaXF67IPccvLazlQ1nKJ5vDUnjx33QxOH52qhk7SaQIZ2ZYC2fpGLyVV9U0NnVqTlhjL7qzKTl+bx2vx/PK9nDSkN1MGJXf65xc5EQpkRUQkJAIZ2XH9ExUESNi5HI6mjKxlWby8Kpv73ttCv6Q4/nbNSfTpFUOsy0mc20msy0Gc20mfnjGtNtwROV7OpvE7x57ZLqpse/ROQFpCHIWVdXi9VtDP0V0FlcS5HW2WLX/2TT7ZJdXcdd6YoD6nSCgpkBURkZBwOQwuh2F8f82PlfBzO31nZGsbPNzz9mbeXJvL6aNTefjKKSS3MuZEpCu42mj2lF/uqw5oq9kTQHpiLA0ei0PV9fTp1fZjwVdCf8WTy3E7Hfz7tjmtZnyfWbaHAck9OHtcerufUyTUNK1bRERCwhjDU9dO58enDQ/3UkRwOhzUe7xc/vhy3lqXy+0LRvHstTMUxErItdW1uMB/7jU9sZ3S4qZZssGdk336iz2UVjdQVtPA7a+uP6bMHmDz/jJW7Snh2lOH4HIqZJDIEzHPSmPM9caYfcaYA8aYu8O9HhER6XxnjE5r96yXSCi4nQaP1yL3UDXPXjuDO87KVNmwhEUwgWx7GdlA6XEgg9uWkqp6nlm2h/Mm9OP/XjaRFbuL+fPCHcc87rkv9xIf4+TKGYPb/Zwi4RARpcXGmGHAU8DTQCnwO2PMMsuyloZ1YSIiIhKVZgxN4bTMVB64ZAKD+7Q92kSkK7mazsi2EMiW1+IwtFsunN6BjOyTn2dRVd/InWdlMio9gTV7S3hscRYnDenN/DHp/s9Ty3sb8rhq5iCSerg7+i2JhESkZGTPwLeWe4F7gDpgQVhXJCIiIlFrXmYqL1w/U0GshF2gEsBrtRTI1tG3V2xT1rY1gYxsYTuBbH55LS8s38tlUwc0jY/67cXjGZeRyB2vbyD3UDUAL63Mpt7j5TqN3JEIFimBbD//bZFlWY1ACZBx9IOMMT8yxqwxxqwpLCwM6QJFRERERDpbU0bW01JpcW27HYsB4txOEuJc7ZYWP7JoJx6vxU8XZB7xsY9fPQ2v1+LWl9dSUdvAyyv3sWBMGsP69uzgdyMSOpESyB59manFidCWZf3NsqzplmVNT01NDcGyRERERES6TltnZPPL64LuK5CeGEdBeesZ2ezial77KocrZww6phJhaN+ePPjtSWzILeNbTyynuKqe6+coGyuRLVIC2Tz/bV9jjAvoAxwI43pERERERLpcUyDbUmlxRV27jZ4C0hJiya9oPSP78Gc7cDoMP5k/qsX3nzshgxvmDGNHfiVj+iVw6og+QX1dkXCJiGZPwGLAA9yHr9lTLPBpOBckIiIiItLVWsvINnq8FFfVkdbO6J2A9MQ4vtpT0uL7duZX8K91+7lhzjD6JbX++e46bwwer8W5E/phjLp4S2SLiEDWsqy9xpgbgPvxBbF3W5a1LMzLEhERERHpUi6Hr0DyuS/38unWfHrFuugV68LtcmBZ7Y/eCUhLiCW/vJaHF+5gXmYqkwcmNwXJD326gx5uJ//n9JFtfg6308FvLx5/Yt+QSIhERCALYFnWC8AL4V6HiIiIiEioOB2Gn5+dyZa8cirrGqmsa6SgopaqOg/9EuOYMig5qM9zwaQMVu4u5i+f7eThhTtJ6uFmzsi+jOufyIebD3LbglGk9Izp2m9GJISM1UI9vh1Mnz7dWrNmTbiXISIiIiISMUqq6lm2q4ilOwr5Ymch+eV1JMe7WfqLM0iM00xYsRdjzNeWZU1v6X0Rk5EVEREREZETk9Izhosn9+fiyf2xLIvt+RXEuZwKYiXqKJAVEREREYlCxhjG9EsM9zJEukSkjN8RERERERERCYoCWREREREREbEVBbIiIiIiIiJiKwpkRURERERExFYUyIqIiIiIiIitKJAVERERERERW1EgKyIiIiIiIraiQFZERERERERsRYGsiIiIiIiI2IoCWREREREREbEVBbIiIiIiIiJiKwpkRURERERExFYUyIqIiIiIiIitKJAVERERERERW1EgKyIiIiIiIraiQFZERERERERsRYGsiIiIiIiI2IoCWREREREREbEVBbIiIiIiIiJiKwpkRURERERExFaMZVnhXsNxMcYUAvvCvY529AWKwr0I6VTa0+ii/Yw+2tPooz2NPtrT6KL9jD6RtKdDLMtKbekdtg1k7cAYs8ayrOnhXod0Hu1pdNF+Rh/tafTRnkYf7Wl00X5GH7vsqUqLRURERERExFYUyIqIiIiIiIitKJDtWn8L9wKk02lPo4v2M/poT6OP9jT6aE+ji/Yz+thiT3VGVkRERERERGxFGVkRERERERGxFQWyXcAYc70xZp8x5oAx5u5wr0eOjzHmSmPMfmNMiTHmUWOMwxgz3RizwRhTaox52RgTH+51SscYY5KNMUXGGMv/tvbUpowxc4wxm40x1caYd40xPbWf9maM+ZkxpsAYc8gY84jx0Z7aiDEmyRhzvjGm1hhzrf++FvfQGNPXGPOhMabcGPOlMWZ4eFcvLWllTycYYzYaYyqNMR8YY/r579ee2kBLe9rsfQuNMZYx5jT/2xG7pwpkO5kxZhjwFPAR8CLwO2PMvPCuSjrKGNMbeA74N/AH4Fbgh8DrQDnwS+BbwM/DtUY5br8GYpq9rT21IWOMC9/eFePbuwuBm9B+2pYxZiTw/4A3gN8D/wGcg/bUbtbj+90Z2+y+1vbwj8BU4CdAGvB0yFYpHbGeY/f0KaAMuAU4BXjQf7/21B7Wc+yeYoy5EJh51GMjdk8VyHa+M/D9u94L3APUAQvCuiI5HkOBfcB/WZb1B+AQcAUwHHjMsqy/Al+ivbUV/1XEq4Fnm72tPbWn6UB/4FfAY8BgYCnaTzvz+G9XAF/5/16O9tRuvu3/A7T7c/ZM4F+WZb2A7+L/PGOMO8TrlfYdvacGiAcetCzrRWAJMM3/bu2pPRyxp9B0gfhBfBcUm4vYPVUg2/n6+W+LLMtqBEqAjDCuR46DZVnrLMsaa1nWQWPMmUBvfC+uAIr8t/lob+3mj8BD+C5MQLP/r/5b7al9DPLf/h7fBcM3gB7++7SfNmRZ1h7gXeDvwCJgIxB4saQ9tQnLstYAq5vd1dbP2X5H3e8EUrt6jdIxR++p5TPZsqx3jTEZwGxgu//d2lMbaOH/KcDNwG7g86Puj9g9VSDb+cxRb6sttI0ZY67E98JqJfDZUe/W3tqIMWY2MAt4pPndRz1Me2ofgd9f64BrgYnAfx/1GO2njRhjzgMuxlf+fyswCTj9qIdpT+0n2J+z2lubMcZMxHeR3wJa6gmjPbUJY0wi8F/4qpzaElF76gr3AqJQnv+2rzGmCOgDHAjjeuQ4GWN+iO8cwMvAjzl8Vbmv/zYd7a2dTAcGAjXN7gsEPtpT+znov33SsqxvjDG3A5X++7Sf9jTRf/sny7JqjTG/B07236c9ta+m10X+2+Z7eOCo+xuBwtAtTY6XMWYqvgv8u4HLLcvK9r9Le2pPw/BlWTc0u28JvgtREbunCmQ732J853zuA0rxHaL+NJwLko4zxgwAHgfWAv8A5gO5QBZwq//K1RyOzQBJ5HoZ3w9l8JXP3AzcCHyM9tSOVuL7GXuvMWYRvkYUvwXGov20q03+2/uNMeVAAvAaMArtqW1ZlrXHGNPa786FwKXGmOX4Kis+tyyrIUxLlY55wX/7R2CiMWakZVmL0J7a1XZgiv/v0/Elcm70vx2xe6pAtpNZlrXXGHMDcD++IPZuy7KWhXlZ0nGzgTh8/5nf89/3PPAdfN2M/wj8E/hTOBYnHWdZVhH+Mx7GmIP++7KMMdpTG7Isq84Y8318peIX4Dsj+zC+jvHaTxuyLOtDY8xv8V1kcuJrOPISvgBXe2pvrf2c/QW+87KP4tvnm8KyOukQY0wahysoXvff7sWX1dOe2pBlWbX4s7HGmGT/3bv8txG7p8ayIqrUWURERERERKRNavYkIiIiIiIitqJAVkRERERERGxFgayIiIiIiIjYigJZERERERERsRUFsiIiImFkjBlijLGa/akxxrxnjOnX7DHT/e8rMMY4m92/+KiPDfy5NjzfjYiISGgokBUREYkMDwMXAXcDZ+MbVxJwJb4h9KnAac3u/xVwof9jAW7wv/1Z1y5VREQkvDRHVkREJDKstyzrfQBjzDjgBv+8xkLg2/hmql7s//siAMuyVvof39f/OT6zLGtfqBcuIiISasrIioiIRJ6NgAGGAicDQ4A3gQ+Ay5uXF4uIiHRHCmRFREQiVzW+suJaYD2wFEgD5oVxTSIiImGn0mIREZHIcwpQA+wBrgDigJxm7/82sDgM6xIREYkICmRFREQiwxRjTDFwEvBd4Fn/3wcA9wJf+h93N77y4v+wLMsblpWKiIiEmQJZERGRyPBT/58q4BXgDuB/8HUr/l/LskoBjDHDgKfwlRcvCf0yRUREws9YlhXuNYiIiIiIiIgETc2eRERERERExFYUyIqIiIiIiIitKJAVERERERERW1EgKyIiIiIiIraiQFZERERERERsRYGsiIiIiIiI2IoCWREREREREbGV/w9Glz/aGPT8QAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 예측값 그래프 그리기\n",
    "plt.figure(figsize=(16,9))\n",
    "sns.lineplot(data = mean_df, x=mean_df.index, y='predicted_weight_g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 모델의 예측 값을 28일 단위로 나누어 list에 append\n",
    "\n",
    "testResults = []\n",
    "\n",
    "for i in range(5):\n",
    "    testResults.append(mean_df.iloc[i*28:(i+1)*28,:].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 최적 모델의 예측 값들을 28일 단위로 총 5개의 csv에 저장. (결과)\n",
    "\n",
    "for i, df in enumerate(testResults):\n",
    "    df.index += 1\n",
    "    df.index.name = 'DAT'\n",
    "    \n",
    "    df.to_csv(f'./test_target/TEST_0{i+1}.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <정성평가>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shap을 통해 가장 가중치가 높게 작용된 부분을 찾아 해당 부분의 값을 높게 적용하는 생육환경을 추천할 생각..\n",
    "# Shap으로 이미지파일에서 \n",
    "\n",
    "# from omnixai.data.image import Image\n",
    "# from omnixai.explainers.vision import ShapImage\n",
    "\n",
    "# preprocess_func = lambda x: x\n",
    "# explainer = ShapImage(model=selected_model, preprocess_function=preprocess_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select backgroud for shap\n",
    "background = [np.random.choice(.shape[0], 1000, replace=False)]\n",
    "# DeepExplainer to explain predictions of the model\n",
    "explainer = shap.DeepExplainer(selected_model, background)\n",
    "# compute shap values\n",
    "shap_values = explainer.shap_values(x_test_each_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
